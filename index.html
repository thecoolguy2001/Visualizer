<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
  <meta charset="UTF-8">
  <title>Visualizer</title>
  <!-- Standard favicon -->
  <link rel="icon" type="image/png" href="images/favicon.png">
    
  <!-- PNG favicon for browsers that prefer PNG -->
  <link rel="icon" type="image/png" sizes="32x32" href="images/faivcon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
    
  <!-- Apple Touch Icon -->
  <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
  <script src="https://js-cdn.music.apple.com/musickit/v1/musickit.js"></script>
  <script>
    window.onSpotifyWebPlaybackSDKReady = function() {
      console.log('Spotify Web Playback SDK loaded');
    };
  </script>
  <script src="https://sdk.scdn.co/spotify-player.js"></script>
  <script src="https://connect.soundcloud.com/sdk/sdk-3.3.2.js"></script>
  <style>
  /* Password overlay styling */
  #passwordOverlay {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    width: 300px;
    background-color: rgba(0, 0, 0, 0.9);
    color: white;
    font-family: Arial, sans-serif;
    border: 2px solid grey;
    border-radius: 8px;
    padding: 20px;
    text-align: center;
    display: none;
    z-index: 10001;
  }
  #passwordOverlay.show {
    display: block;
  }
  #passwordOverlay input {
    width: 100%;
    padding: 8px;
    margin: 10px 0;
    box-sizing: border-box;
  }
  #passwordOverlay button {
    display: block;
    width: 100%;
    padding: 10px;
    margin-top: 10px;
    background-color: rgba(0,0,0,0.8);
    border: 2px solid grey;
    border-radius: 8px;
    color: white;
    cursor: pointer;
    font-family: Arial, sans-serif;
  }
  #passwordOverlay #passwordError {
    color: red;
    margin-top: 10px;
    display: none;
  }
  /* Hide restricted entries until after password */
.restricted {
  display: none !important;
}
body.authorized .restricted {
  display: list-item !important;
}
  /* Ensure the background is black for iOS Safari */
  html, body {
    background-color: black;
    margin: 0;
    padding: 0;
  }
  
  #info {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -40%); /* start slightly lower */
  color: grey;
  text-align: center;
  font-family: Arial, sans-serif;
  opacity: 0;
  transition: opacity 0.5s ease, transform 0.5s ease;
}

/* When you want to show the message, add the "show" class */
#info.show {
  transform: translate(-50%, -50%); /* final centered position */
  opacity: 1;
}

  #modeIndicator {
    position: absolute; bottom: 10px; left: 10px;
    color: grey; text-align: left;
    font-family: Arial, sans-serif;
    opacity: 0;
    transition: opacity 1s;
  }
  /* File input now is a 1x1 pixel element, visible (opacity: 0) so it can be clicked on mobile */
  #fileInput {
    position: fixed;
    width: 44px;            /* A standard touch-target size */
    height: 44px;
    opacity: 0;             /* Visually hidden */
    z-index: 10000;
    top: 10px;
    left: 10px;
    pointer-events: auto;   /* Must allow user interaction */
    /* Do NOT use display:none or transform that removes it from layout */
  }
  
  #loadedMessage {
    position: absolute; bottom: 10px; left: 10px;
    color: grey; text-align: left;
    font-family: Arial, sans-serif; display: none;
  } 
  #actionMessage {
  position: absolute; bottom: 10px; left: 10px;
  color: grey; text-align: left;
  font-family: Arial, sans-serif;
  opacity: 0;
  transition: opacity 1.5s ease-in-out;
}


  
  #songInfo {
    position: absolute; 
    bottom: 10px; 
    right: 10px; 
    color: grey; 
    text-align: right; 
    font-family: Arial, sans-serif; 
    opacity: 0; 
    transition: opacity 1s;
  }   
  
  #helpOverlay {  
  position: absolute;
  top: 50%;
  left: 50%;
  /* Initial transform offset: starts 10px lower than centered */
  transform: translate(-50%, -40%);
  width: 300px; /* or auto if you prefer */
  background-color: rgba(0, 0, 0, 0.8);
  color: white;
  font-family: Arial, sans-serif;
  border: 2px solid grey;
  border-radius: 8px;
  padding: 20px;
  opacity: 0;  /* start hidden */
  transition: opacity 0.5s ease, transform 0.5s ease;
  z-index: 9999; /* on top of other overlays */
  display: none;  /* keep hidden by default */
}

/* When the overlay should be visible, add the "show" class */
#helpOverlay.show {
  display: block;   /* ensure it's in the document flow */
  opacity: 1;
  /* Raise up to centered position */
  transform: translate(-50%, -50%);
}
  
  #helpOverlay h2,
  #helpOverlay ul {
    margin: 0;
    padding: 0;
  }  
  
  #helpOverlay ul {
    list-style-type: none;
    margin-top: 10px;
  }   
  
  #helpOverlay li {
    margin-bottom: 8px;
  } 
  #adBanner {
  position: fixed;
  bottom: 0;
  left: 0;
  width: 100%;
  height: 90px; /* You may adjust this height if needed */
  display: none; /* Hidden by default */
  text-align: center;
  z-index: 10000;
}

#adBanner.show {
  display: block;
  opacity: 0;
  animation: fadeInUp 0.5s forwards;
}
#dspOverlay {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -40%);
  width: 300px;
  background-color: rgba(0,0,0,0.9);
  color: white;
  font-family: Arial, sans-serif;
  border: 2px solid grey;
  border-radius: 8px;
  padding: 20px;
  opacity: 0;
  transition: opacity 0.5s ease, transform 0.5s ease;
  z-index: 10000;
  display: none;
  font-size: 1em;
}
#dspOverlay.show {
  display: block;
  opacity: 1;
  transform: translate(-50%, -50%);
  pointer-events: auto;
}
#dspOverlay label {
  display: block;
  margin-bottom: 10px;
}
#dspOverlay input {
  width: 100%;
  padding: 5px;
  margin-top: 4px;
  box-sizing: border-box;
}
  #dspOverlay button {
    display: block;
    width: 100%;
    padding: 10px 20px;
    margin: 8px 0;
    background-color: rgba(0, 0, 0, 0.8);
    border: 2px solid grey;
    border-radius: 8px;
    color: white;
    font-family: Arial, sans-serif;
    font-size: 16px;
    cursor: pointer;
  }

  /* Ensure cancel is on top of the Apple Music button */
  #dspOverlay.show #dspCancel {
    position: relative;
    z-index: 2;
  }
  #dspOverlay.show #connectApple {
    position: relative;
    z-index: 1;
    width: 100%;
    min-height: 44px;
    margin: 8px 0;
  }

  /* Re-enable taps only on the connect & cancel buttons */
  #dspOverlay.show #connectApple,
  #dspOverlay.show #dspCancel {
    pointer-events: auto;
  }

/* Creator Modal animation */
  #creatorModal {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(0%, 0%);
    opacity: 0;
    transition: opacity 0.5s ease, transform 0.5s ease;
    display: none;
    z-index: 10000;
    overflow: auto;
  }
  #creatorModal.show {
    display: block;
    opacity: 1;
    transform: translate(0%, -3%);
  }


@keyframes fadeInUp {
  0% {
    opacity: 0;
    transform: translateY(10px);
  }
  100% {
    opacity: 1;
    transform: translateY(0);
  }
}
  
  @media only screen and (max-width: 768px) {
    #info {
    font-size: 18px; /* Increase font size for mobile devices */
  }
}
</style>
</head>
<body>
  <div id="passwordOverlay">
    <h2>Enter Password</h2>
    <input type="password" id="passwordInput" placeholder="Password">
    <button id="passwordSubmit">Submit</button>
    <div id="passwordError">Incorrect password</div>
  </div>
  <div id="info">press spacebar to start</div>
  <div id="modeIndicator"></div>
  <audio id="audio" preload="auto"></audio>
  <div id="loadedMessage">loaded</div>
  <div id="actionMessage"></div>
  <div id="songInfo"></div>
  <input type="file" id="fileInput" accept="audio/*,.mp3,.wav,.ogg" onchange="handleFileSelect(event)">

  <div id="helpOverlay">
    <h2>Controls</h2>
    <ul>
      <li><b>Spacebar:</b> Play/Pause</li>
      <li><b>Arrow Up/Down:</b> Switch Mode</li>
      <li><b>Arrow Left/Right:</b> Switch Effect Style</li>
      <li><b>1–9:</b> Set Effect Intensity Level</li>
      <li><b>N:</b> Next Song</li>
      <li><b>B:</b> Previous Song</li>
      <li><b>M:</b> Toggle Mute</li>
      <li><b>O:</b> Toggle Effect Shuffle Mode</li>
      <li><b>P:</b> Toggle Player Mode</li>
      <li><b>V:</b> Toggle Visual Mode</li>
      <li><b>I:</b> Show Info (Mode & Song Name)</li>
      <li><b>H:</b> Show/Hide Help</li>
    </ul>
  </div>
  <div id="adBanner">
    <p style="color: white; margin: 0; line-height: 90px;">Ad Banner Placeholder</p>
  </div>
  <div id="adBanner">
    <!-- Google AdSense code snippet - update the data-ad-client and data-ad-slot values -->
    <ins class="adsbygoogle"
         style="display:inline-block;width:728px;height:90px;"
         data-ad-client="ca-pub-xxxxxxxxxxxxxxxx"
         data-ad-slot="1234567890"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
  </div>
  <div id="dspOverlay">
    <h2>Connect Service</h2>
    <button id="connectApple" type="button">Connect to Apple Music</button>
    <!-- <button id="connectSpotify" type="button">Connect to Spotify</button> -->
    <!-- <button id="connectSoundCloud" type="button">Connect to SoundCloud</button> -->

    <div style="text-align:right; margin-top:15px;">
      <button type="button" id="dspCancel">Cancel</button>
    </div>
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script>
    // Password protection
    let isAuthorized = false;
    function showPasswordOverlay() {
      document.getElementById('passwordError').style.display = 'none';
      document.getElementById('passwordOverlay').classList.add('show');
    }
    function hidePasswordOverlay() {
      document.getElementById('passwordOverlay').classList.remove('show');
      document.getElementById('passwordInput').value = '';
    }
    document.addEventListener('DOMContentLoaded', function() {
      document.getElementById('passwordSubmit').addEventListener('click', async () => {
        const pw = document.getElementById('passwordInput').value;
        try {
          const res = await fetch('/api/verify-password', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ password: pw })
          });
          if (res.ok) {
            isAuthorized = true;
            hidePasswordOverlay();
            document.body.classList.add('authorized');
          } else {
            document.getElementById('passwordError').style.display = 'block';
          }
        } catch (err) {
          console.error('Password verification failed:', err);
          document.getElementById('passwordError').style.display = 'block';
        }
      });
      // Show overlay on initial load
      
    });
    // Initialize Apple MusicKit safely
    async function initAppleMusic() {
      try {
        const res = await fetch(`${window.location.origin}/api/apple-music-token`);
        if (!res.ok) {
          console.warn('Apple Music token fetch failed:', res.status);
          return;
        }
        const { token } = await res.json();
        MusicKit.configure({
          developerToken: token,
          app: { name: 'Visualizer Website', build: '1.0.0' }
        });
      } catch (err) {
        console.warn('initAppleMusic error:', err);
      }
    }
    initAppleMusic();

    // Initialize SoundCloud SDK safely
    (async () => {
      try {
        const res = await fetch(`${window.location.origin}/api/soundcloud-client-id`);
        if (!res.ok) {
          console.warn('SoundCloud client ID fetch failed:', res.status);
          return;
        }
        const { clientId } = await res.json();
        SC.initialize({ client_id: clientId });
      } catch (err) {
        console.warn('SoundCloud init error:', err);
      }
    })();

    // Helper to fetch Spotify access token from backend
    async function fetchSpotifyToken() {
      const { token } = await fetch(`${window.location.origin}/api/spotify-token`).then(res => res.json());
      return token;
    }
  </script>
  <script>
    // Track hide fallback timeout for DSP overlay
    let dspHideFallbackTimeout = null;
    const clock = new THREE.Clock();
    let audioElement = document.getElementById('audio');
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let audioSrc;
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 1024;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
          
    let camera, scene, renderer, intensityLevel = 1;
    let currentStyleIndex = Math.floor(Math.random() * 4); // Randomly select an initial style
    let visualElements = [];
    let isPlaying = false;
    let isUsingDefaultAudio = true; // Flag to track audio source status
    let currentMode = 'playlist'; // Start in playlist mode
    let isCameraMode = false;
    let userCameraStream = null;
    let userCameraVideo = null;
    let userCameraTexture = null;
    let userMicrophoneStream = null; // To store the microphone stream
    let shuffleMode = false;
    let shuffleInterval = null;
    let fileSelectTriggered = false;
    let augmentInterval = null;
    let isCameraFeedInEffects = false;
    let userPlaylist = [];               // Array of {src, title} objects for user songs
let userPlaylistActive = false;      // Flag indicating that the user has activated the mode by pressing 'P'
const MAX_USER_PLAYLIST = 15;        // Maximum songs allowed
let currentUserSongIndex = 0;   

    // If true, each effect uses the camera feed as input
    
    
function hideDspOverlay() {
  const dsp = document.getElementById('dspOverlay');
  if (dsp) {
    // Handler for transitionend, also used by fallback
    const setDisplayNoneAndCleanup = () => {
      dsp.style.display = 'none';
      dsp.removeEventListener('transitionend', setDisplayNoneAndCleanup); // Ensure removal
    };

    if (dsp.classList.contains('show')) {
      dsp.classList.remove('show'); // Start transition
      
      dsp.addEventListener('transitionend', setDisplayNoneAndCleanup, { once: true });

      // Fallback timeout: hide if transitionend doesn't fire
      dspHideFallbackTimeout = setTimeout(() => {
        if (!dsp.classList.contains('show') && dsp.style.display !== 'none') {
          setDisplayNoneAndCleanup();
        }
      }, 550);
    } else {
      // If 'show' class is not present, but it's somehow not display:none, fix it.
      if (dsp.style.display !== 'none') {
         dsp.style.display = 'none';
      }
    }
  }
}
        
    const modes = ['fileSelect', 'audioDevice', 'playlist', 'dsp'];
    let currentModeIndex = modes.indexOf(currentMode);
          
    let selectedFileName = '';
      let playlist = [
        'music/aphex twin - xtal.mp3', 
        'music/daft punk - pheonix.mp3', 
        'music/future - i serve the base.mp3',
        'music/nirvana - radio friendly unit shifter.mp3',
        'music/prince -  i wanna be your lover.mp3',
      ]; // playlist
          
      let currentSongIndex = Math.floor(Math.random() * playlist.length); // Random start
          
      function init() {
        // Determine if the user is on a mobile device
        const isMobile = /Mobi|Android/i.test(navigator.userAgent);
            
        // Initialize the scene, camera, etc.
        scene = new THREE.Scene(); 
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 500;
            
        renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
            
        attachAudioElementEventListeners();
        createVisualElements();
        window.addEventListener('resize', onWindowResize, false);
        document.body.addEventListener('keydown', onKeyDown, false);
            
        // Update the info message text based on whether it's mobile or not
        const info = document.getElementById('info');
  if (info) {
    // Set the starting text based on device.
    info.textContent = /Mobi|Android/i.test(navigator.userAgent) ? "tap to start" : "press spacebar to start";
    
    // Force a reflow and then add the "show" class to trigger the animation.
    void info.offsetWidth;
    // Add a slight delay if desired (e.g., 100ms) so it animates after the page renders:
    setTimeout(() => {
      info.classList.add('show');
    }, 500);
  }
            
        // Use mobile-specific info messages in your interval
        let infoMessages = isMobile 
        ? ["tap to start", "hold for help"]
        : ["press spacebar to start", "press h for help"];
        let currentInfoIndex = 0;
        setInterval(() => {
          
          if (!isPlaying) {
            currentInfoIndex = (currentInfoIndex + 1) % infoMessages.length;
            fadeSwapInfoMessage(infoMessages[currentInfoIndex]);
          }
            
        }, 5000);
        if (currentMode === 'playlist') {
          shufflePlaylist(); 
              loadCurrentSong(); 
            }
            animate();
          }
          
          function fadeSwapInfoMessage(newText) {
            const info = document.getElementById('info');
            if (!info) return;
            
            // Step 1: Fade out from current opacity (assumed 1) to 0
            info.style.opacity = '0';
            
            // Step 2: After the fade-out duration, swap text & fade back in
            // We match the CSS transition duration (1.5s)
            setTimeout(() => {
              info.textContent = newText;
              
              // Force reflow so setting opacity=1 triggers the fade-in
              void info.offsetWidth;
              info.style.opacity = '1';
            }, 1500); // 1.5s to match our CSS .transition: opacity 1.5s
          }
            
          function shufflePlaylist() {
            for (let i = playlist.length - 1; i > 0; i--) {
              const j = Math.floor(Math.random() * (i + 1));
              [playlist[i], playlist[j]] = [playlist[j], playlist[i]];
            }
          }
            
            async function ensureAudioContextResumed() {
              if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }
        }
            
        function loadCurrentSong() {
          return new Promise((resolve) => {
            // Set the new song URL and update the displayed song name.
            audioElement.src = playlist[currentSongIndex];
            selectedFileName = playlist[currentSongIndex]
            .replace(/^music\//, "")  // Remove "music/" at the start, if it exists
            .replace(/\.[^/.]+$/, ""); // Remove the extension (.mp3, etc.)
            audioElement.load();
            
            // This function will build the chain if it hasn't been built yet.
            function setupChain() {
              ensureAudioContextResumed().then(() => {
                // Create the MediaElementSource node only once for this audio element.
                if (!audioSrc) {
                  audioSrc = audioContext.createMediaElementSource(audioElement);
                  const gainNode = audioContext.createGain();
                  gainNode.gain.value = 2.0; // Adjust gain as needed
                  
                  // Build the connection chain: audioElement -> gainNode -> analyser -> destination
                  audioSrc.connect(gainNode);
                  gainNode.connect(analyser);
                  analyser.connect(audioContext.destination);
                }
                
                resolve(); // Resolve once the chain is set up
              });
            }
            
            // If metadata is already available, set up immediately; otherwise, wait for onloadedmetadata.
            if (audioElement.readyState >= 1) { // HAVE_METADATA
            setupChain();
          } else {
            
            audioElement.onloadedmetadata = setupChain;
          }
        });
      }
            
      function playNextSongInPlaylist() {
        currentSongIndex = (currentSongIndex + 1) % playlist.length;
                
          loadCurrentSong().then(() => {
            if (isPlaying) {
              audioElement.play();
            }
          });
      }
            
      function playPreviousSongInPlaylist() {
        currentSongIndex = (currentSongIndex - 1 + playlist.length) % playlist.length;
                 
          loadCurrentSong().then(() => {
            if (isPlaying) {
              audioElement.play();
            }
          });
      }
            
      function attachAudioElementEventListeners() {
        // Add the 'ended' event listener
        audioElement.addEventListener('ended', () => {
          if (currentMode === 'playlist') {
            playNextSongInPlaylist();
          }
        });
      }     

      function switchMode(mode) {
      // Restrict file-select playlist, DSP mode, and Creator mode until authorized
      if (!isAuthorized && (
          (mode === 'fileSelect' && userPlaylistActive) ||
          mode === 'dsp' ||
          mode === 'creatorMode'
        )) {
        showPasswordOverlay();
        return;
      }
      const dsp = document.getElementById('dspOverlay');
  if (dsp && mode !== 'dsp') {
    hideDspOverlay();
  }
      // If switching away from DSP, pause Apple Music playback and suspend the AudioContext
      if (currentMode === 'dsp' && mode !== 'dsp') {
        MusicKit.getInstance().pause();
        audioContext.suspend().catch(err => console.warn('AudioContext.suspend() failed:', err));
      }

  // Stop microphone stream if switching away from audioDevice mode
  if (currentMode === 'audioDevice' && userMicrophoneStream) {
    userMicrophoneStream.getTracks().forEach(track => track.stop());
    userMicrophoneStream = null;
    console.log('Microphone stream stopped.');
  }
        
      if (mode !== 'fileSelect') {
        userPlaylist = [];
        userPlaylistActive = false;
        currentUserSongIndex = 0;
        console.log('User playlist reset because mode changed to', mode);
      }
      currentMode = mode;
      currentModeIndex = modes.indexOf(mode);
      displayMode();
            
        // Reset any existing audio source connections
        if (audioSrc) {
          audioSrc.disconnect();
          audioSrc = null;
        }
            
        switch (mode) {
          case 'fileSelect': {
            // Reset user playlist for file-select mode
            userPlaylist = [];
            userPlaylistActive = true;
            currentUserSongIndex = 0;
            // Reset loaded message for single-file selection to clear any previous playlist count
            const loadedMessage = document.getElementById('loadedMessage');
            if (loadedMessage) {
              loadedMessage.textContent = 'loaded';
              loadedMessage.style.display = 'none';
            }
            if (/Mobi|Android/i.test(navigator.userAgent)) {
              // On mobile, reset the trigger flag so that one tap will open the file browser.
              fileSelectTriggered = false;
              // (You can also optionally show an instruction message here.)
              } else {
                // Desktop: use your dynamic file input creation method.
                let input = document.createElement('input');
                input.type = 'file';
                input.accept = 'audio/*';
                input.style.position = 'fixed';
                input.style.top = '0px';
                input.style.left = '0px';
                input.style.width = '44px';
                input.style.height = '44px';
                input.style.opacity = '0';
                input.style.pointerEvents = 'auto';
                input.style.zIndex = '10000';
                document.body.appendChild(input);
                input.addEventListener('change', function(e) {
                  const file = input.files[0];
                  if (!file) {
                    document.body.removeChild(input);
                    return;
                  }
                  
                  const newAudio = new Audio();
                  newAudio.src = URL.createObjectURL(file);
                  newAudio.load();
                  selectedFileName = file.name.replace(/\.[^/.]+$/, "");
                  
                  newAudio.onloadedmetadata = async () => {
                    if (audioSrc) {
                      audioSrc.disconnect();
                      audioSrc = null;
                    }
                    
                    await ensureAudioContextResumed();
                    audioSrc = audioContext.createMediaElementSource(newAudio);
                    audioSrc.connect(analyser);
                    analyser.connect(audioContext.destination);
                    audioElement.pause();
                    audioElement = newAudio;
                    const loadedMessage = document.getElementById('loadedMessage');
                    if (loadedMessage) {
                      loadedMessage.style.display = 'block';
                      setTimeout(() => {
                        loadedMessage.style.display = 'none';
                      }, 3000);
                    }
                  };
                  newAudio.onerror = function(e) {
                    console.error('Error loading audio file:', e);
                  };
                  document.body.removeChild(input);
                });
                input.click();
              }
            }
            
          break;
          
          case 'audioDevice': {
            if (audioContext.state === 'suspended') {
              audioContext.resume().catch(err => console.warn('AudioContext.resume() failed for audioDevice mode:', err));
            }
            // Disconnect any existing audio source and clear previous connections
            if (audioSrc) {
              audioSrc.disconnect();
              audioSrc = null;
            }
            // Pause any currently playing audio (from playlist mode)
            audioElement.pause();
            // Mute the audio element to ensure no sound is played
            audioElement.muted = true;
            // IMPORTANT: Disconnect the analyser from any destination.
            // This prevents any previously connected mic/playlist signal from going to the speakers.
            try {
              analyser.disconnect();
            } catch(e) {
              // Some browsers may throw if nothing is connected
            }
            // Request microphone access
            navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
              // Create a MediaStreamSource from the mic stream
              audioSrc = audioContext.createMediaStreamSource(stream);
              // Connect the mic input ONLY to the analyser (do not connect to destination)
              audioSrc.connect(analyser);
              // Double-check no audio is sent to speakers
              try { analyser.disconnect(audioContext.destination); } catch(e) { }
              // Store the microphone stream so it can be stopped later
              userMicrophoneStream = stream;
            })
            .catch(error => {
              console.error('Error accessing audio device:', error);
            });
            }
          break;
          case 'playlist': {
            // Disconnect any existing audio source.
            if (audioSrc) {
              audioSrc.disconnect();
              audioSrc = null;
            }
            // Create a new Audio element for playlist mode.
            // This ensures any chain from fileSelect mode is discarded.
            const playlistAudio = new Audio();
            playlistAudio.volume = 1.0;
            playlistAudio.muted = false;  // Make sure it's unmuted
            playlistAudio.src = playlist[currentSongIndex];
            playlistAudio.load();
            
            // Replace the global audioElement with this new one.
            audioElement.pause();
            audioElement = playlistAudio;
            
            async function setupPlaylistChain() {
              await ensureAudioContextResumed();
              // Create the MediaElementSource node from the new audio element.
              audioSrc = audioContext.createMediaElementSource(audioElement);
              const gainNode = audioContext.createGain();
              gainNode.gain.value = 2.0; // Adjust as needed
              // Build the connection chain: audioElement -> gainNode -> analyser -> destination
              audioSrc.connect(gainNode);
              gainNode.connect(analyser);
              analyser.connect(audioContext.destination);
              if (isPlaying) {
                audioElement.play();
              }
            }
            
            if (audioElement.readyState >= 1) {
              setupPlaylistChain();
            } else {
              audioElement.onloadedmetadata = setupPlaylistChain;
            }
          }
          break;
          case 'dsp': {
  // show the DSP overlay
  const dsp = document.getElementById('dspOverlay');
  if (dsp) {
    // Clear any pending hide fallback to prevent overlay disappearing
    if (dspHideFallbackTimeout) {
      clearTimeout(dspHideFallbackTimeout);
      dspHideFallbackTimeout = null;
    }
    dsp.style.display = 'block';
    // Disable fileInput taps while DSP overlay is visible
    const fileInputEl = document.getElementById('fileInput');
    if (fileInputEl) fileInputEl.style.pointerEvents = 'none';
    // trigger reflow so transition runs
    requestAnimationFrame(() => dsp.classList.add('show'));
  }

  // pause any existing playback
  audioElement.pause();
  if (audioSrc) audioSrc.disconnect();

  

  // wire up the Connect/Cancel buttons
  document.getElementById('connectApple').onclick = async () => {
    try {
      const music = MusicKit.getInstance();
      await music.authorize();
      // Search the Apple Music catalog for a playlist to queue
      const searchResults = await music.api.search('New Music Daily', {
        types: ['playlists'],
        limit: 1
      });
      const playlistId = searchResults.playlists.data[0]?.id;
      if (!playlistId) {
        throw new Error('No playlist found in catalog');
      }
      await music.setQueue({ playlist: playlistId });

      // Hook analyser once playback actually starts
      // Once playback truly starts, capture the media stream for analysis
      music.addEventListener('playbackStateDidChange', event => {
        if (event.state === MusicKit.PlaybackStates.playing) {
          const audioEl = music.player.audioElement;
          audioEl.crossOrigin = 'anonymous';
          audioElement = audioEl;
          // Capture the same audio stream for visualizer
          const mediaStream = audioEl.captureStream();
          if (audioSrc) audioSrc.disconnect();
          audioSrc = audioContext.createMediaStreamSource(mediaStream);
          audioSrc.connect(analyser);
          analyser.connect(audioContext.destination);
        }
      });

      // Start playback
     
      hideDspOverlay(); // Replaced dsp.classList.remove('show');
      // Reset play state so the next spacebar press starts playback
      isPlaying = false;
      const info = document.getElementById('info');
      info.textContent = /Mobi|Android/i.test(navigator.userAgent)
        ? 'tap to start'
        : 'press spacebar to start';
      info.style.display = 'block';
      info.style.opacity = '1';
    } catch(err) {
      console.error('Apple Music authorization failed:', err);
      hideDspOverlay(); // Replaced dsp.classList.remove('show');
      isPlaying = true;
      startVisualizerWithDummyData();
    }
  };
    
  /* 
  // Spotify integration
  document.getElementById('connectSpotify').onclick = async () => {
    try {
      // Ensure we have a valid user token, otherwise start OAuth flow
      const tokenRes = await fetch(`${window.location.origin}/api/spotify-token`);
      if (tokenRes.status === 401) {
        // Not authenticated: redirect to Spotify login
        window.location.href = `${window.location.origin}/api/spotify-login`;
        return;
      }
      const { token } = await tokenRes.json();

      const initSpotifyPlayer = () => {
        const player = new Spotify.Player({
          name: 'Visualizer Web Playback',
          getOAuthToken: cb => cb(token)
        });

        player.addListener('ready', async ({ device_id }) => {
          console.log('Spotify Web Playback ready on device', device_id);
          // Transfer playback to this device without auto-start
          await fetch('https://api.spotify.com/v1/me/player', {
            method: 'PUT',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': 'Bearer ' + token
            },
            body: JSON.stringify({ device_ids: [device_id], play: false })
          });

          // Fetch user's top tracks
          const topRes = await fetch('https://api.spotify.com/v1/me/top/tracks?limit=25', {
            headers: { 'Authorization': 'Bearer ' + token }
          });
          const topData = await topRes.json();
          const uris = topData.items.map(t => t.uri);

          // Start playback of top tracks
          await fetch('https://api.spotify.com/v1/me/player/play', {
            method: 'PUT',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': 'Bearer ' + token
            },
            body: JSON.stringify({ uris })
          });

          // Hook analyser to the SDK's audio element
          const audioEl = document.querySelector('audio');
          if (audioEl) {
            if (audioSrc) audioSrc.disconnect();
            audioSrc = audioContext.createMediaElementSource(audioEl);
            audioSrc.connect(analyser);
            analyser.connect(audioContext.destination);
          }

          hideDspOverlay(); // Replaced dsp.classList.remove('show');
          isPlaying = true;
        });

        player.connect().catch(err => {
          console.error('Spotify player.connect() failed:', err);
          hideDspOverlay(); // Added call here for connect error
        });
      };

      if (window.Spotify && Spotify.Player) {
        initSpotifyPlayer();
      } else {
        window.onSpotifyWebPlaybackSDKReady = initSpotifyPlayer;
      }
    } catch (err) {
      console.error('Spotify connection failed:', err);
      hideDspOverlay(); // Replaced dsp.classList.remove('show');
      isPlaying = true;
      startVisualizerWithDummyData();
    }
  };
  */
    
  /* 
  // SoundCloud integration
  document.getElementById('connectSoundCloud').onclick = async () => {
    try {
      const track = await SC.stream('/tracks/YOUR_SOUNDCLOUD_TRACK_ID');
      const audioEl = track._player; 
      if (audioSrc) audioSrc.disconnect();
      audioSrc = audioContext.createMediaElementSource(audioEl);
      audioSrc.connect(analyser);
      analyser.connect(audioContext.destination);
      audioEl.play();
      hideDspOverlay(); // Replaced dsp.classList.remove('show');
      isPlaying = true;
    } catch (err) {
      console.error('SoundCloud connection failed:', err);
      hideDspOverlay(); // Replaced dsp.classList.remove('show');
      isPlaying = true;
      startVisualizerWithDummyData();
    }
  };
  */
  // Intercept raw touch events on Cancel to prevent Safari's hit-area re-targeting
  const cancelBtn = document.getElementById('dspCancel');
  cancelBtn.addEventListener('touchstart', event => event.stopPropagation());
  cancelBtn.addEventListener('touchend', event => event.stopPropagation());
  document.getElementById('dspCancel').onclick = () => {
    // Re-enable fileInput taps when closing DSP overlay
    const fileInputEl = document.getElementById('fileInput');
    if (fileInputEl) fileInputEl.style.pointerEvents = 'auto';
    // Immediately hide DSP overlay without transition or leftover timers
    const dspEl = document.getElementById('dspOverlay');
    dspEl.classList.remove('show');
    dspEl.style.display = 'none';
    switchMode('playlist');
  };
}
break;
        default:
            console.log('Unknown mode');
        }
      }
      
      function handleFileSelect(event) {
        const file = event.target.files[0];
        if (!file) return;
        
        const newAudio = new Audio();
        newAudio.src = URL.createObjectURL(file);
        newAudio.load();
        selectedFileName = file.name.replace(/\.[^/.]+$/, "");
        
        newAudio.onloadedmetadata = async () => {
          if (audioSrc) {
            audioSrc.disconnect();
            audioSrc = null;
          }
          // Inside handleFileSelect(event), after newAudio is loaded:
if (currentMode === 'fileSelect' && userPlaylistActive) {
  if (userPlaylist.length < MAX_USER_PLAYLIST) {
    // Build an object containing the song's source and title
    let userSong = {
      src: newAudio.src,
      title: selectedFileName,
    };
    userPlaylist.push(userSong);
    console.log('Song added:', selectedFileName, '(' + userPlaylist.length + '/' + MAX_USER_PLAYLIST + ')');

    // Display "loaded" message (if more than one song, show the count)
    const loadedMessage = document.getElementById('loadedMessage');
    if (loadedMessage) {
      if (userPlaylist.length > 1) {
        loadedMessage.textContent = `loaded (${userPlaylist.length}/${MAX_USER_PLAYLIST})`;
      } else {
        loadedMessage.textContent = 'loaded';
      }
      loadedMessage.style.display = 'block';
      setTimeout(() => {
        loadedMessage.style.display = 'none';
      }, 3000);
    }
    // Update the current user song index to the latest
    currentUserSongIndex = userPlaylist.length - 1;
  } else {
    console.warn('User playlist is at maximum capacity of 15 songs.');
  }
}
          
          await ensureAudioContextResumed();
          audioSrc = audioContext.createMediaElementSource(newAudio);
          audioSrc.connect(analyser);
          analyser.connect(audioContext.destination);
          audioElement.pause();
          audioElement = newAudio;
          
          const loadedMessage = document.getElementById('loadedMessage');
          if (loadedMessage) {
            loadedMessage.style.display = 'block';
            setTimeout(() => {
              loadedMessage.style.display = 'none';
            }, 3000);
          }
          // Reset our fileSelect flag and switch mode to playlist so that normal gestures work.
          fileSelectTriggered = false;
        };
        
        audioElement.onerror = function(e) {
          console.error('Error loading audio file:', e);
        };
      }
      
      function createParticles() {
  const particleCount = 5000;
  const positions = new Float32Array(particleCount * 3);
  const colors = new Float32Array(particleCount * 3);

  // Fill positions and colors with random data.
  for (let i = 0; i < particleCount; i++) {
    positions[i * 3 + 0] = (Math.random() - 0.5) * 1000;
    positions[i * 3 + 1] = (Math.random() - 0.5) * 1000;
    positions[i * 3 + 2] = (Math.random() - 0.5) * 1000;

    colors[i * 3 + 0] = Math.random();
    colors[i * 3 + 1] = Math.random();
    colors[i * 3 + 2] = Math.random();
  }

  const geometry = new THREE.BufferGeometry();
  geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
  geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));

  // Full vertex shader code.
  const vertexShaderCode = `
    uniform float time;
    uniform float effectIntensity;
    uniform float audioIntensity;
    uniform vec3 objectOffset;
    attribute vec3 color;
    varying vec3 vColor;
    varying float vExplosion;

    // Simple pseudo-random function based on the particle's position.
    float rand(vec2 co) {
      return fract(sin(dot(co, vec2(12.9898, 78.233))) * 43758.5453);
    }

    void main() {
      vColor = color;
      
      // Base oscillatory movement (unchanged from before).
      float offsetX = sin(time + position.y * 0.01) * 30.0 * effectIntensity;
      float offsetY = cos(time + position.x * 0.01) * 30.0 * effectIntensity;
      // Base Z-offset (can be less affected by audioIntensity for stability).
      float offsetZ = sin(time * 0.5 + position.x * 0.005) * 30.0;
      vec3 baseOffset = vec3(offsetX, offsetY, offsetZ);
      
      // --- Additional random motion for dramatic explosions ---
      // Apply extra movement only when audioIntensity is above a threshold.
      float audioThreshold = 0.3;
      vec3 randomOffset = vec3(0.0);
      float explosionFactor = 0.0;
      if (audioIntensity > audioThreshold) {
        // Normalize the excess audio level to 0..1.
        explosionFactor = (audioIntensity - audioThreshold) / (1.0 - audioThreshold);
        float rnd = rand(position.xy);
        randomOffset = vec3(
          sin(time + position.x * 0.02 + rnd),
          cos(time + position.y * 0.02 + rnd),
          sin(time * 0.5 + position.z * 0.01 + rnd)
        ) * audioIntensity * 20.0 * explosionFactor;
      }
      // Pass the magnitude of the extra offset for potential alpha modulation.
      vExplosion = length(randomOffset);
      
      // Final vertex position is the sum of the base offset, the random extra offset, and any object offset.
      vec3 displacedPosition = position + baseOffset + randomOffset + objectOffset;
      gl_Position = projectionMatrix * modelViewMatrix * vec4(displacedPosition, 1.0);
      
      // Dynamic particle size (base behavior remains unchanged).
      float dynamicSize = 4.0 + 8.0 * abs(sin(time * 5.0 + position.x * 0.01)) * audioIntensity;
      gl_PointSize = dynamicSize;
    }
  `;

  // Full fragment shader code.
  const fragmentShaderCode = `
    precision mediump float; // Ensure precision is specified

    uniform sampler2D cameraTexture;
    uniform vec2 resolution;
    uniform float time;
    uniform float effectIntensity;
    uniform float visualMode; // Added uniform for visual mode
    uniform float cameraActive; // New uniform: 1.0 if camera feed is active, 0.0 if not
    varying vec3 vColor;
    varying float vExplosion;

    void main() {
      // Create a circular point by discarding fragments outside a circle.
      vec2 coord = gl_PointCoord - vec2(0.5);
      float dist = length(coord);
      if (dist > 0.5) discard;

      // Base alpha based on explosion effect (remains unchanged)
      float alphaFactor = 1.0 - smoothstep(0.0, 50.0, vExplosion);
      vec3 finalColor;
      float finalAlpha;

      // Determine base particle color (always brightened)
      vec3 brightParticleColor = clamp(vColor * 1.5, 0.0, 1.0);

      if (visualMode > 0.5 && cameraActive > 0.5) {
        // Visual mode is active, determine style
        vec2 screenUV = gl_FragCoord.xy / resolution.xy;
        vec4 cameraColor = texture2D(cameraTexture, screenUV);

        if (abs(visualMode - 1.0) < 0.1) {
          // Style 1: Luminance controls alpha, particle color is brightened
          float cameraLuminance = dot(cameraColor.rgb, vec3(0.299, 0.587, 0.114));
          // Invert alpha logic: brighter camera areas -> more transparent particles
          finalAlpha = alphaFactor * (1.0 - cameraLuminance);
          finalColor = brightParticleColor; // Use the pre-brightened particle color
        } else if (abs(visualMode - 2.0) < 0.1) {
          // Style 2: Render particles normally (camera background is handled in animate())
          finalColor = brightParticleColor; // Use brightened particle color
          finalAlpha = alphaFactor; // Use original alpha
        } else {
          // Fallback if visualMode is an unexpected value > 0.5 (render like Style 1)
          float cameraLuminance = dot(cameraColor.rgb, vec3(0.299, 0.587, 0.114));
          finalAlpha = alphaFactor * cameraLuminance;
          finalColor = brightParticleColor;
        }
      } else {
        // Visual mode OFF: Use brightened particle color and original alpha
        finalColor = brightParticleColor;
        finalAlpha = alphaFactor;
      }

      // Set the final fragment color and alpha
      gl_FragColor = vec4(finalColor, finalAlpha);
    }
  `;

  const particleMaterial = new THREE.ShaderMaterial({
    uniforms: {
      cameraTexture: { value: null }, // Will be assigned by toggleCameraBackground()
      resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
      time: { value: 0.0 },
      effectIntensity: { value: 4.0 },
      audioIntensity: { value: 0.0 },
      objectOffset: { value: new THREE.Vector3(0.0, 0.0, 0.0) },
      visualMode: { value: 0.0 }, // Initialize visual mode off
      cameraActive: { value: 0.0 } // NEW: Indicates if the camera feed is active
    },
    vertexShader: vertexShaderCode,
    fragmentShader: fragmentShaderCode,
    transparent: true,
    depthWrite: false,
    blending: THREE.AdditiveBlending
  });

  const particleSystem = new THREE.Points(geometry, particleMaterial);
  particleSystem.userData.rotationSpeed = 0.005;
  particleSystem.name = 'CameraParticles';
  scene.add(particleSystem);
  visualElements.push(particleSystem);
}
        
function createWaves() {
  // Create a full-screen plane based on camera FOV to avoid borders
  const fovRad = camera.fov * Math.PI / 180;
  const heightWorld = 2 * Math.tan(fovRad * 0.5) * camera.position.z;
  const widthWorld = heightWorld * camera.aspect;
  // Recalculate geometry size with a larger safety margin for fullscreen
  const geometry = new THREE.PlaneBufferGeometry(widthWorld * 1.5, heightWorld * 1.5, 800, 400);

  const material = new THREE.ShaderMaterial({
    uniforms: {
      time:            { value: 0.0 },
      bass:            { value: 0.0 }, // Keep for thickness/other effects if needed
      mid:             { value: 0.0 }, // Keep for waveTime/other effects if needed
      treble:          { value: 0.0 }, // Keep for other effects if needed
      // Add new uniforms for frequency segments
      audioSeg1:       { value: 0.0 }, // e.g., Low Bass
      audioSeg2:       { value: 0.0 }, // e.g., High Bass
      audioSeg3:       { value: 0.0 }, // e.g., Low Mid
      audioSeg4:       { value: 0.0 }, // e.g., High Mid
      audioSeg5:       { value: 0.0 }, // e.g., Low Treble
      audioSeg6:       { value: 0.0 }, // e.g., High Treble
      effectIntensity: { value: 1.0 },
      lineThickness:   { value: 0.02 },
      uSeed:           { value: Math.random() * 100.0 }, // random seed for unique behavior
      // Add uniforms for visual mode
      cameraTexture:   { value: null },
      visualMode:      { value: 0.0 }, // 0: off, 1: Waves show camera feed, 2: Background shows camera feed
      cameraActive:    { value: 0.0 }
    },
    // Vertex Shader: Minimal displacement for a mostly flat plane;
    // we're mostly doing our work in the fragment shader.
    vertexShader: `
      precision mediump float;
      
      uniform float time;
      uniform float bass;
      uniform float mid;
      uniform float treble;
      uniform float effectIntensity;
      
      varying vec2 vUv;
      varying float vSmallDisp; // small displacement info (if needed)
      
      // A simple hash and noise for subtle motion
      float hash(vec2 p) {
        return fract(sin(dot(p, vec2(127.1, 311.7))) * 43758.5453123);
      }
      float noise(vec2 p) {
        vec2 i = floor(p);
        vec2 f = fract(p);
        vec2 u = f * f * (3.0 - 2.0 * f);
        return mix(
          mix(hash(i), hash(i + vec2(1.0, 0.0)), u.x),
          mix(hash(i + vec2(0.0, 1.0)), hash(i + vec2(1.0, 1.0)), u.x),
          u.y
        );
      }
      
      void main() {
        vUv = uv;
        vec3 pos = position;
        
        // Optional: a very subtle "breathing" displacement
        float disp = noise(pos.xy * 0.02 + time * 0.5) * 5.0;
        disp += (bass * 5.0 + mid * 3.0 + treble * 5.0) * sin(pos.x * 0.05 + time * 2.0);
        pos.z += disp;
        
        // Smoother audio-driven bending using bass and mid
        float bendStrength = (bass * 0.8 + mid * 0.4) * 8.0; // Reduced magnitude, blended frequencies
        pos.y += sin(pos.x * 0.12 + time * 0.8) * bendStrength; // Slightly adjusted wave shape/speed
         
         vSmallDisp = disp;
         gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
      }
    `,
    // Fragment Shader: Draws multiple translucent ribbons (the base ribbons)
    // plus three additional front ripple layers with improved, complex movement.
    fragmentShader: `
      precision mediump float;
      
      uniform float time;
      uniform float bass;
      uniform float mid;
      uniform float treble;
      uniform float effectIntensity;
      uniform float lineThickness;
      // uniform vec2 resolution; -- removed
      // Add camera aspect uniform
      uniform float cameraAspect;
      // Add uniforms for visual mode
      uniform sampler2D cameraTexture;
      uniform float visualMode; // 0: off, 1: Waves show camera feed, 2: Background shows camera feed
      uniform float cameraActive;
      
      varying vec2 vUv;
      
      // Helper: creates a smooth band (ribbon) given a center and half-width.
      float ribbonAlpha(float y, float centerY, float halfWidth) {
        float d = abs(y - centerY);
        return smoothstep(halfWidth, 0.0, d);
      }
      
      // Helper: linear blend between two colors.
      vec3 blendColors(vec3 colorA, vec3 colorB, float factor) {
        return mix(colorA, colorB, clamp(factor, 0.0, 1.0));
      }
      
      void main() {
        // Use vUv for all positioning, with aspect ratio adjustment
        vec2 st = vUv;
        st.x *= cameraAspect;

        float waveTime = time * (1.0 + mid * 2.0);
        // Increase thickness reactivity slightly
        float thickness = lineThickness * (3.0 + bass * 12.0);
        
        vec3 accColor = vec3(0.0);
        float accAlpha = 0.0;
        
        // --- Base Ribbons Calculation (regardless of visual mode) ---
        // RIBBON 1: Pink -> Purple
        {
          float centerY = 0.45 + 0.08 * sin((st.x * 3.0) + waveTime * 1.1);
          centerY += bass * 0.1 * sin(st.x * 10.0 + waveTime * 1.5);
          
          float alpha = ribbonAlpha(st.y, centerY, thickness);
          vec3 c1 = vec3(1.0, 0.2, 0.8);  // neon pink
          vec3 c2 = vec3(0.6, 0.0, 0.8);  // purple
          float mixF = 0.5 + 0.5 * sin(waveTime + treble * 3.0);
          vec3 ribbonColor = blendColors(c1, c2, mixF);
          
          accColor += ribbonColor * alpha;
          accAlpha = max(accAlpha, alpha);
        }
        
        // RIBBON 2: Purple -> Blue
        {
          float centerY = 0.5 + 0.08 * sin((st.x * 2.0) + waveTime * 1.2);
          centerY += mid * 0.1 * sin(st.x * 12.0 + waveTime * 0.7);
          
          float alpha = ribbonAlpha(st.y, centerY, thickness * 0.8);
          vec3 c1 = vec3(0.6, 0.0, 0.8);  // purple
          vec3 c2 = vec3(0.0, 0.7, 1.0);  // cyan/blue
          float mixF = 0.5 + 0.5 * cos(waveTime * 0.9 + bass * 2.0);
          vec3 ribbonColor = blendColors(c1, c2, mixF);
          
          accColor += ribbonColor * alpha;
          accAlpha = max(accAlpha, alpha);
        }
        
        // RIBBON 3: Pink -> Cyan
        {
          float centerY = 0.55 + 0.1 * sin((st.x * 4.0) - waveTime * 1.5);
          centerY += treble * 0.1 * sin(st.x * 15.0 + waveTime * 2.0);
          
          float alpha = ribbonAlpha(st.y, centerY, thickness * 0.7);
          vec3 c1 = vec3(1.0, 0.2, 0.8);  // pink
          vec3 c2 = vec3(0.0, 1.0, 1.0);  // neon cyan
          float mixF = 0.5 + 0.5 * sin(waveTime * 1.4 + mid * 3.0);
          vec3 ribbonColor = blendColors(c1, c2, mixF);
          
          accColor += ribbonColor * alpha;
          accAlpha = max(accAlpha, alpha);
        }
        
        // RIBBON 4: Blue->Green
        {
          float centerY = 0.4 + 0.08 * cos(st.x * 5.0 + waveTime * 1.7);
          centerY += bass * 0.12 * sin(st.x * 8.0 + waveTime * 2.2);
          float alpha2 = ribbonAlpha(st.y, centerY, thickness * 0.6);
          vec3 c3 = vec3(0.0, 0.7, 1.0);
          vec3 c4 = vec3(0.0, 1.0, 0.5);
          float mixF2 = 0.5 + 0.5 * sin(waveTime * 1.3 + treble * 2.0);
          vec3 ribbonColor4 = blendColors(c3, c4, mixF2);
          accColor += ribbonColor4 * alpha2;
          accAlpha = max(accAlpha, alpha2);
        }
        
        // RIBBON 5: Yellow->Orange (extra layer)
        {
          float centerY = 0.35 + 0.09 * sin(st.x * 6.0 + waveTime * 2.1);
          centerY += bass * 0.08 * cos(st.x * 10.0 + waveTime * 1.8); // Added cos term
          float alpha5 = ribbonAlpha(st.y, centerY, thickness * 0.5);
          vec3 c5 = vec3(1.0, 0.8, 0.2);
          vec3 c6 = vec3(1.0, 0.4, 0.0);
          float mixF5 = 0.5 + 0.5 * cos(waveTime * 1.3 + bass * 2.0);
          accColor += blendColors(c5, c6, mixF5) * alpha5;
          accAlpha = max(accAlpha, alpha5);
        }
        // RIBBON 6: Green->Pink (extra layer)
        {
          float centerY = 0.58 + 0.09 * cos(st.x * 4.0 + waveTime * 2.3);
          centerY += mid * 0.08 * sin(st.x * 7.0 + waveTime * 2.0); // Added sin term
          float alpha6 = ribbonAlpha(st.y, centerY, thickness * 0.4);
          vec3 c7 = vec3(0.0, 1.0, 0.5);
          vec3 c8 = vec3(1.0, 0.2, 0.6);
          float mixF6 = 0.5 + 0.5 * sin(waveTime * 1.5 + mid * 2.2);
          accColor += blendColors(c7, c8, mixF6) * alpha6;
          accAlpha = max(accAlpha, alpha6);
        }
        
        // --- Visual Mode Logic ---
        if (visualMode > 0.5 && cameraActive > 0.5) {
           // Use vUv for screenUV, with aspect adjustment for camera feed if needed
           vec2 screenUV = vUv;
           screenUV.x *= cameraAspect;
           vec4 cameraColor = texture2D(cameraTexture, screenUV);

           if (abs(visualMode - 1.0) < 0.1) {
             // Style 1: Multiply original wave color by camera feed within the wave shape
             vec3 waveColor = accColor; // Calculated color of the waves
             float waveAlpha = clamp(accAlpha * 0.85, 0.0, 1.0); // Calculated alpha of waves
             // Multiply wave color by camera color
             vec3 finalColor = waveColor * cameraColor.rgb;
             // Make the result opaque only where the wave exists
             gl_FragColor = vec4(finalColor, waveAlpha > 0.0 ? 1.0 : 0.0);

           } else if (abs(visualMode - 2.0) < 0.1) {
             // Style 2: Waves are unchanged, camera feed replaces the black background.
             vec3 waveColor = accColor;
             float waveAlpha = clamp(accAlpha * 0.85, 0.0, 1.0);
             // Mix camera background and wave color based on wave alpha
             vec3 finalColor = mix(cameraColor.rgb, waveColor, waveAlpha);
             gl_FragColor = vec4(finalColor, 1.0); // Output should be fully opaque

           } else if (abs(visualMode - 3.0) < 0.1) {
             // Style 3: Camera feed directly
             gl_FragColor = cameraColor;

           } else {
             // Fallback (visual mode on but unknown style) - Render like Style 1 (the new multiplied style)
             vec3 waveColor = accColor;
             float waveAlpha = clamp(accAlpha * 0.85, 0.0, 1.0);
             vec3 finalColor = waveColor * cameraColor.rgb;
             gl_FragColor = vec4(finalColor, waveAlpha > 0.0 ? 1.0 : 0.0);
           }
        } else {
           // Visual Mode OFF: Render waves normally
           gl_FragColor = vec4(accColor, clamp(accAlpha * 0.85, 0.0, 1.0));
        }
      }
    `,
    transparent: true, // Ensure transparency is enabled for visual mode 2
    blending: THREE.NormalBlending // Confirm Normal Blending
  });
  
  // After creating the material, add camera.aspect as a uniform
  material.uniforms.cameraAspect = { value: camera.aspect };

  const waves = new THREE.Mesh(geometry, material);
  waves.name = "Waves";
  // Center the plane vertically, keep tilt for depth
  waves.position.set(0, 0, 0);
  waves.rotation.x = -0.3;
  scene.add(waves);
  visualElements.push(waves);
}
        
    function create3DWaves() {
  // Use a highly subdivided plane for high-quality, experimental waves
  const geometry = new THREE.PlaneBufferGeometry(1200, 1200, 300, 300);
  const material = new THREE.ShaderMaterial({
    uniforms: {
      time: { value: 0.0 },
      amplitude: { value: 20.0 },
      frequency: { value: 0.5 },
      speed: { value: 1.0 }
    },
    vertexShader: `
      uniform float time;
      uniform float amplitude;
      uniform float frequency;
      uniform float speed;
      varying vec3 vColor;
      
      void main() {
        vec3 pos = position;
        // Compute three wave patterns with a twist effect for complexity
        float wave1 = sin(pos.x * frequency + time * speed);
        float wave2 = cos(pos.y * frequency * 1.2 + time * speed * 1.1);
        float wave3 = sin((pos.x + pos.y) * frequency * 0.8 + time * speed * 0.8);
        // Apply a twist based on the y position and time to add a 3D dynamic\n
        float twist = sin(time + pos.y * 0.05) * 0.5;
        pos.x += twist;
        // Combine the waves to get a complex displacement\n
        float displacement = (wave1 + wave2 + wave3) / 3.0 * amplitude;
        pos.z += displacement;
        // Generate a vibrant color based on the displacement\n
        vColor = vec3(0.5 + 0.5 * sin(displacement * 0.1),
                      0.5 + 0.5 * cos(displacement * 0.1),
                      0.5 + 0.5 * sin(displacement * 0.2));
        gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
      }
    `,
    fragmentShader: `
      varying vec3 vColor;
      void main() {
        gl_FragColor = vec4(vColor, 1.0);
      }
    `,
    wireframe: false,
    transparent: true,
  });
  
  const mesh = new THREE.Mesh(geometry, material);
  // Tilt the plane for a more engaging perspective (angled view instead of flat)
  mesh.rotation.set(-0.5, 0.3, 0);
  mesh.name = '3DWaves';
  scene.add(mesh);
  visualElements.push(mesh);
}
        
function createTrippyColors() {
  // Keep the same group name so other code references remain correct
  const trippyGroup = new THREE.Group();
  trippyGroup.name = "TrippyColors";

  // Calculate the needed plane size to fill the view at z=0.
  const distance = camera.position.z; // Distance from camera to plane at z=0
  const fovInRadians = (camera.fov * Math.PI) / 180.0;
  const planeHeight = 2 * distance * Math.tan(fovInRadians / 2);
  const planeWidth = planeHeight * camera.aspect;

  // Fullscreen plane
  const geometry = new THREE.PlaneGeometry(planeWidth, planeHeight, 1, 1);

  // Keep the same uniform structure, so your animate code still applies:
  const material = new THREE.ShaderMaterial({
    uniforms: {
      uTime:            { value: 0.0 },
      uAudioLevel:      { value: 0.0 },
      uEffectIntensity: { value: 1.0 },

      // Seeds for random generation
      uSeedA: { value: Math.random() * 1000 },
      uSeedB: { value: Math.random() * 1000 },
      uSeedC: { value: Math.random() * 1000 },
      uRandomShift: { value: 0.0 },

      // Screen resolution
      uResolution: {
        value: new THREE.Vector2(window.innerWidth, window.innerHeight),
      },
    },
    vertexShader: `
      varying vec2 vUv;
      void main(){
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      precision highp float;

      // Uniforms from your code
      uniform float uTime;
      uniform float uAudioLevel;
      uniform float uEffectIntensity;
      uniform float uSeedA;
      uniform float uSeedB;
      uniform float uSeedC;
      uniform float uRandomShift;
      uniform vec2  uResolution;

      varying vec2 vUv;

      // --- Constants ---
      #define PI 3.14159265359
      #define TWO_PI 6.28318530718
      #define NUM_FLOOR_LINES_X 15.0 // Number of points along X on the floor
      #define NUM_FLOOR_LINES_Z 20.0 // Number of points along Z (depth)

      // --- Helper Functions ---
      // HSV to RGB
      vec3 hsv2rgb(vec3 c) {
          vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
          vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
          return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
      }

      // Calculate minimum distance from point p to line segment (a, b)
      float distToSegment(vec2 p, vec2 a, vec2 b) {
          vec2 pa = p - a, ba = b - a;
          float h = clamp(dot(pa, ba) / dot(ba, ba), 0.0, 1.0);
          return length(pa - ba * h);
      }

      // --- Perspective Projection (Simplified) ---
      // Projects a 3D point (world space) onto the 2D screen space (uv)
      // Assumes camera at (0, 0, cameraZ), looking along -Z. Floor is at Y = -floorY.
      vec2 project(vec3 p, float cameraZ, float floorY) {
          // Basic perspective projection formula
          // Adjust focalLength (in cameraZ) as needed for FOV
          float perspectiveFactor = cameraZ / (cameraZ - p.z);
          // Apply perspective scaling
          vec2 projected = p.xy * perspectiveFactor;
          // Map to screen UV (adjust center and scale as needed)
          // This mapping needs tuning based on desired view
          projected.y = mix(-floorY, projected.y, smoothstep(-1.0, 0.9, p.y / floorY)); // Simulate floor perspective
          return projected;
      }


      // --- Main ---
      void main() {
          // Centered and aspect-corrected UVs (-1 to 1 range approx)
          vec2 uv = (vUv - 0.5) * 2.0;
          uv.x *= uResolution.x / uResolution.y;

          // --- Parameters based on Time and Audio ---
          float time = uTime * 0.1; // Slower time
          float audio = uAudioLevel * uEffectIntensity; // Combined audio effect
          audio = pow(audio, 1.5); // Make audio response more pronounced

          // --- Define Scene Elements in 3D (Simplified) ---
          float floorY = 1.0; // How far down the floor is
          float cameraZ = 1.5; // Camera distance from origin (affects perspective)
          float structureDepth = 15.0; // How far the structure extends in Z
          float structureWidth = 2.0; // Width of the floor grid

          // Emitter points (top corners in 3D space)
          vec3 emitterL = vec3(-0.8 * structureWidth, 0.9 * floorY, 0.0);
          vec3 emitterR = vec3( 0.8 * structureWidth, 0.9 * floorY, 0.0);

          // --- Color ---
          vec3 laserColor = vec3(1.0, 0.0, 0.0); // Bright Red
          float baseBrightness = 0.1 + audio * 2.0; // Base brightness tied to audio

          // --- Calculate Laser Lines ---
          float minDistToLaser = 100.0;

          for (float i = 0.0; i <= NUM_FLOOR_LINES_X; i += 1.0) {
              for (float j = 1.0; j <= NUM_FLOOR_LINES_Z; j += 1.0) { // Start j=1 to avoid division by zero in projection?
                  // Calculate floor point position in 3D
                  float x = mix(-structureWidth, structureWidth, i / NUM_FLOOR_LINES_X);
                  // Non-linear Z distribution for perspective
                  float z = -pow(j / NUM_FLOOR_LINES_Z, 1.5) * structureDepth;

                  vec3 floorPoint3D = vec3(x, -floorY, z);

                  // Project points to 2D screen space
                  vec2 screenEmitterL = project(emitterL, cameraZ, floorY);
                  vec2 screenEmitterR = project(emitterR, cameraZ, floorY);
                  vec2 screenFloorPoint = project(floorPoint3D, cameraZ, floorY);

                  // Calculate distance to the projected line segments
                  minDistToLaser = min(minDistToLaser, distToSegment(uv, screenEmitterL, screenFloorPoint));
                  minDistToLaser = min(minDistToLaser, distToSegment(uv, screenEmitterR, screenFloorPoint));
              }
          }

          // --- Draw Lasers with Glow ---
          float laserWidth = (0.002 + audio * 0.004); // / uEffectIntensity; // Adjust base width & audio react
          float laserGlow = (0.02 + audio * 0.05); // / uEffectIntensity;  // Adjust base glow & audio react

          float laserIntensity = smoothstep(laserWidth, laserWidth * 0.5, minDistToLaser);
          float glowIntensity = smoothstep(laserGlow, laserWidth, minDistToLaser);

          vec3 laserContribution = laserColor * baseBrightness * (laserIntensity + glowIntensity * 0.5);


          // --- Calculate Floor Grid ---
          // Use screen-space perspective distortion for the floor grid
          // Inverse project UV to find approximate floor coordinates
          // This is complex; simplify by drawing grid in screen space distorted by Y
          float gridPerspective = smoothstep(0.0, -1.0, uv.y); // Perspective effect for grid lines
          float gridDensity = 20.0 + audio * 10.0;
          vec2 gridUv = uv * gridDensity;

          // Distort grid based on perspective factor (uv.y)
          gridUv.x /= (1.0 + gridPerspective * 2.0); // Stretch horizontally further down
          gridUv.y += time * 5.0; // Animate grid scroll

          float gridFade = smoothstep(-0.1, -0.8, uv.y); // Fade grid towards top

          float gridLineWidth = 0.01 + audio * 0.01;
          float gridX = smoothstep(gridLineWidth, 0.0, abs(fract(gridUv.x) - 0.5));
          float gridY = smoothstep(gridLineWidth, 0.0, abs(fract(gridUv.y) - 0.5));
          float grid = max(gridX, gridY) * gridFade;

          vec3 gridContribution = laserColor * grid * baseBrightness * 0.4; // Dimmer grid

          // --- Final Color ---
          vec3 finalColor = laserContribution + gridContribution;

          // Optional: Add subtle noise/atmosphere
          float noise = fract(sin(dot(uv, vec2(12.9898,78.233)) + uTime) * 43758.5453);
          finalColor += noise * 0.02;

          gl_FragColor = vec4(clamp(finalColor, 0.0, 1.0), 1.0); // Opaque output
      }
    `,
    transparent: true,
  });

  const trippyMesh = new THREE.Mesh(geometry, material);
  trippyMesh.position.set(0, 0, 0);
  trippyGroup.add(trippyMesh);

  trippyGroup.userData = {
    mesh: trippyMesh,
    material: material,
    lastSeedUpdateTime: 0,
    nextSeedInterval: 10.0 + Math.random() * 10.0,
  };

  scene.add(trippyGroup);
  visualElements.push(trippyGroup);
}

        
    function createPortal() {
  // Compute full-screen geometry dimensions.
  const aspect = window.innerWidth / window.innerHeight;
  const baseHeight = 2000;  // Base height (can be adjusted)
  const baseWidth = baseHeight * aspect; // ensures full width coverage

  const geometry = new THREE.PlaneGeometry(baseWidth, baseHeight, 1, 1);
  
  const material = new THREE.ShaderMaterial({
    uniforms: {
      time: { value: 0.0 },
      resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
      // Core portal parameters:
      travelOffset: { value: 0.0 },      // drives inward travel
      spinSpeed: { value: 0.35 },        // single-direction spin (lower for slower animation)
      warpStrength: { value: 0.8 },      // extra fractal warping
      colorCycle: { value: 0.0 },        // continuous hue shift
      unpredictability: { value: 0.5 },   // scales extra fractal noise
      audioReactive: { value: 0.0 },      // audio reactivity influence
      phaseShift: { value: 0.0 },         // for abrupt color/hue jumps
      kaleidoSegments: { value: 6.0 }     // number of mirrored segments (kaleidoscope effect)
    },
    vertexShader: `
      varying vec2 vUv;
      void main() {
        vUv = uv;  
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      precision highp float;
      
      uniform float time;
      uniform vec2 resolution;
      uniform float travelOffset;
      uniform float spinSpeed;
      uniform float warpStrength;
      uniform float colorCycle;
      uniform float unpredictability;
      uniform float audioReactive;
      uniform float phaseShift;
      uniform float kaleidoSegments;
      
      varying vec2 vUv;
      
      // --- Noise functions ---
      float hash(vec2 p) {
        return fract(sin(dot(p, vec2(63.7264,78.233))) * 43758.5453123);
      }
      float noise(vec2 p) {
        vec2 i = floor(p);
        vec2 f = fract(p);
        float a = hash(i);
        float b = hash(i + vec2(1.0, 0.0));
        float c = hash(i + vec2(0.0, 1.0));
        float d = hash(i + vec2(1.0, 1.0));
        vec2 u = f * f * (3.0 - 2.0 * f);
        return mix(a, b, u.x) + (c - a)*u.y*(1.0 - u.x) + (d - b)*u.x*u.y;
      }
      float fbm(vec2 p) {
        float total = 0.0;
        float amp = 0.5;
        for (int i = 0; i < 5; i++){
          total += amp * noise(p);
          p *= 2.0;
          amp *= 0.5;
        }
        return total;
      }
      
      // --- Smooth angle wrap to avoid seams ---
      float smoothAngleWrap(float angle) {
        float modded = mod(angle, 6.28318);
        float blendZone = 0.05;
        if (modded < blendZone) {
          float t = smoothstep(0.0, blendZone, modded);
          modded = mix(6.28318, modded, t);
        }
        return modded;
      }
      
      // --- Base swirl transform (main tunnel) ---
      vec2 swirlTransform(vec2 uv) {
        vec2 centered = uv - 0.5;
        float r = length(centered);
        float theta = atan(centered.y, centered.x);
        float logR = log(r + 0.0001);
        float rMod = fract(-logR + travelOffset);
        // Enforce single-direction spin
        float spinOffset = time * spinSpeed * (1.0 + audioReactive * 1.5);
        // Basic fractal warp
        float basicWarp = warpStrength * fbm(vec2(theta, time * 0.15)) * 0.5;
        float rawTheta = theta + spinOffset + basicWarp;
        float wrappedTheta = smoothAngleWrap(rawTheta);
        float extraWarp = fbm(vec2(wrappedTheta * 1.2, rMod * unpredictability + time * 0.1));
        wrappedTheta += extraWarp * 0.3;
        return vec2(wrappedTheta, rMod);
      }
      
      // --- Kaleidoscopic reflection ---
      vec2 kaleidoWrap(vec2 polar, float segments) {
        float slice = 6.28318 / segments;
        float halfSlice = slice * 0.5;
        float shifted = polar.x + halfSlice;
        float modded = mod(shifted, slice);
        float mirrored = modded > halfSlice ? slice - modded : modded;
        float finalAngle = mirrored - halfSlice;
        return vec2(finalAngle, polar.y);
      }
      
      // --- Convert polar to normalized UV ---
      vec2 polarToUV(vec2 polar) {
        float u = polar.x / 6.28318;
        return vec2(fract(u), polar.y);
      }
      
      // --- Fractal color layering ---
      vec3 fractalColor(vec2 uv, float shift) {
        float n = fbm(uv * 3.5 + shift);
        vec3 col1 = vec3(0.3, 0.0, 0.7);
        vec3 col2 = vec3(0.0, 0.9, 0.8);
        return mix(col1, col2, n);
      }
      
      void main(){
        // Apply main swirl transform.
        vec2 polarCoords = swirlTransform(vUv);
        // Apply kaleidoscopic wrap.
        polarCoords = kaleidoWrap(polarCoords, kaleidoSegments);
        vec2 newUv = polarToUV(polarCoords);
        
        // Create layered fractal colors.
        float phase = time * 0.3 + colorCycle + phaseShift;
        vec3 layer1 = fractalColor(newUv * 2.5, phase);
        vec3 layer2 = fractalColor(newUv * 3.5, phase + 15.0);
        float blendFactor = sin(6.28318 * newUv.y + phase * 0.4) * 0.5 + 0.5;
        vec3 combinedColor = mix(layer1, layer2, blendFactor);
        
        // Additional flicker inversion for abrupt changes.
        float flicker = fbm(newUv * unpredictability * 6.0 + time * 0.3);
        combinedColor = mix(combinedColor, vec3(1.0) - combinedColor, flicker * 0.35);
        
        // Apply radial vignette.
        float vignette = smoothstep(0.85, 0.3, length(vUv - 0.5));
        combinedColor *= vignette;
        
        gl_FragColor = vec4(combinedColor, 1.0);
      }
    `,
    transparent: true,
    blending: THREE.AdditiveBlending
  });
  
  const portal = new THREE.Mesh(geometry, material);
  portal.name = 'Portal';
  scene.add(portal);
  visualElements.push(portal);
}
        
function createSpaceshipEffect() {
  // Geometry: Highly subdivided plane.
  const planeSize = 800;
  const subdivisions = 150;
  const geometry = new THREE.PlaneBufferGeometry(planeSize, planeSize, subdivisions, subdivisions);

  // ShaderMaterial: Wireframe, custom vertex displacement & fragment color
  const material = new THREE.ShaderMaterial({
    uniforms: {
      time:            { value: 0.0 },
      audioBass:       { value: 0.0 },
      audioMid:        { value: 0.0 },
      audioTreble:     { value: 0.0 },
      effectIntensity: { value: 1.0 },
      maxRadius:       { value: planeSize * 0.45 },
      minRadius:       { value: planeSize * 0.1 },
      // Add a uniform for the base color, set randomly on creation
      // Generate a random hue, but force high saturation and moderate lightness
      uBaseColor:      { value: new THREE.Color().setHSL(Math.random(), 0.8 + Math.random() * 0.2, 0.6 + Math.random() * 0.1) } 
    },
    // Vertex Shader: Pass audio values through
    vertexShader: `
      precision mediump float;

      uniform float time;
      uniform float audioBass; // Make uniforms accessible
      uniform float audioMid;
      uniform float audioTreble;
      uniform float effectIntensity;
      uniform float maxRadius;
      uniform float minRadius;

      varying float vAngle;
      varying float vRadiusNorm;
      varying float vAmplitude;
      varying float vRadialSpike;
      // Varyings to pass audio levels to fragment shader
      varying float vAudioBass;
      varying float vAudioMid;
      varying float vAudioTreble;


      // Noise functions...
      float rand(vec2 co){ return fract(sin(dot(co, vec2(12.9898, 78.233))) * 43758.5453); }
      float fbm(vec2 p) {
          float total = 0.0; float amplitude = 0.5;
          for (int i = 0; i < 4; i++) { total += amplitude * rand(p); p *= 2.0; amplitude *= 0.5; }
          return total;
      }

      void main() {
        float worldRadius = length(position.xy);
        float angle = atan(position.y, position.x);
        vAngle = angle;

        // Pass audio levels to fragment shader
        vAudioBass = audioBass;
        vAudioMid = audioMid;
        vAudioTreble = audioTreble;


        vec3 pos = position;
        float displacement = 0.0;
        vAmplitude = 0.0;
        vRadiusNorm = 0.0;
        vRadialSpike = 0.0;

        if (worldRadius >= minRadius && worldRadius <= maxRadius) {
            vRadiusNorm = (worldRadius - minRadius) / (maxRadius - minRadius);

            float waveSpeed = time * (0.6 + audioMid * 1.5);
            // Radial Spike
            float radialAmplitude = (30.0 + audioBass * 150.0) * effectIntensity;
            float angularFreq = 30.0 + audioTreble * 50.0;
            vRadialSpike = radialAmplitude * (0.4 + 0.6 * abs(sin(angle * angularFreq + time * 0.5)));
            displacement += vRadialSpike * smoothstep(0.0, 0.5, vRadiusNorm);

            // Swirl/Wave
            float swirlAmplitude = 15.0 * effectIntensity * (1.0 + audioMid * 1.5);
            float swirlWave1 = sin(vRadiusNorm * 10.0 - waveSpeed * 1.2 + angle * 3.0);
            float swirlWave2 = cos(angle * 8.0 + waveSpeed * 0.7);
            float swirlNoise = fbm(vec2(angle * 2.0, vRadiusNorm * 3.0 + time * 0.1)) * 15.0 * effectIntensity * audioMid;
            displacement += (swirlWave1 * 0.5 + swirlWave2 * 0.3 + swirlNoise * 0.2) * swirlAmplitude;

            // Splash
            // Reduce strength multiplier significantly, tie to intensity more directly
            float splashStrength = pow(audioBass, 3.0) * (60.0 + 20.0 * effectIntensity); // Lower base, add intensity scaling
            // Slow down noise speed
            float splashNoiseFreq = 8.0;
            float splashNoiseSpeed = 1.5; // Slower speed
            float splashNoise = fbm(vec2(angle * splashNoiseFreq + time * splashNoiseSpeed, time * 0.3)); // Slower time factor too
            // Increase threshold for activation
            float splashFactor = smoothstep(0.7, 0.8, splashNoise); // Higher threshold (0.7 to 0.8)
            float radiusFactor = sin(vRadiusNorm * 3.14159);
            float splashDisplacement = splashStrength * splashFactor * radiusFactor;
            displacement += splashDisplacement;

            vAmplitude = abs(displacement);
            pos.z += displacement;
        }

        gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
      }
    `,
    // Fragment Shader: Adjust initial color brightness
    fragmentShader: `
      precision mediump float;

      uniform float time;
      uniform float effectIntensity;
      uniform vec3 uBaseColor; // Use the base color uniform

      varying float vAngle;
      varying float vRadiusNorm;
      varying float vAmplitude;
      varying float vRadialSpike;
      varying float vAudioBass;
      varying float vAudioMid;
      varying float vAudioTreble;


      // HSV function...
      vec3 hsv2rgb(vec3 c){
           vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
           vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
           return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
       }
      // Noise function...
      float rand(vec2 co){ return fract(sin(dot(co, vec2(12.9898, 78.233))) * 43758.5453); }
      float fbm(vec2 p) {
          float total = 0.0; float amplitude = 0.5;
          for (int i = 0; i < 4; i++) { total += amplitude * rand(p); p *= 2.0; amplitude *= 0.5; }
          return total;
      }

      void main() {
        // Clipping...
         if (vRadiusNorm <= 0.001 || vRadiusNorm >= 0.999) {
             if (vAmplitude < 0.1) { discard; }
         }

        // --- Dynamic/Random Audio-Reactive Coloring ---
        // Use audio levels to drive HSV components dynamically
        // Bass drives hue shift speed/range
        float reactiveHue = mod(time * (0.1 + vAudioBass * 0.5) + vAngle * 0.1, 1.0); // Base rotation + bass speed + angle offset
        // Add noise for randomness in hue
        reactiveHue = mod(reactiveHue + fbm(vec2(time * 0.1, vAngle)) * 0.5, 1.0); 

        // Mid drives saturation
        float reactiveSaturation = clamp(0.7 + vAudioMid * 0.5, 0.7, 1.0); 

        // Treble influences brightness spikes within the reactive color itself
        float reactiveValue = clamp(0.6 + vAudioTreble * 0.6, 0.6, 1.0); 

        // Convert the dynamic HSV to RGB for the reactive color
        vec3 reactiveColor = hsv2rgb(vec3(reactiveHue, reactiveSaturation, reactiveValue));


        // Use the uBaseColor uniform passed from JavaScript
        vec3 baseColor = uBaseColor; 
        // Normalize amplitude aggressively for mixFactor
        float mixFactor = clamp(vAmplitude / (25.0 * effectIntensity), 0.0, 1.0); // React even faster
        // Mix directly: when mixFactor is 0, color is baseColor
        vec3 color = mix(baseColor, reactiveColor, mixFactor); 

        // --- Brightness (Value) based on Amplitude/Spikes ---
        float valueBoost = smoothstep(0.0, 70.0 * effectIntensity, vAmplitude) * 0.3; 
        valueBoost += smoothstep(10.0, 40.0 * effectIntensity, vRadialSpike) * 0.2; 
        float finalValue = clamp(0.8 + valueBoost, 0.7, 1.0); 

        vec3 finalColor = color * finalValue; // Apply brightness

        // --- Alpha Modulation ---
        float breakNoise = fbm(vec2(vAngle * 5.0, time * 0.5));
        float breakFrequency = 20.0 + vAudioTreble * 30.0 + breakNoise * 20.0;
        float alphaPattern = fract(vAngle * breakFrequency + time * 2.0 + vRadiusNorm * 3.0);
        float breakThreshold = 0.4 + breakNoise * 0.2;
        float alpha = step(breakThreshold, alphaPattern);

        alpha *= smoothstep(0.0, 0.05, vRadiusNorm);


        gl_FragColor = vec4(finalColor, alpha * 0.9);
      }
    `,
    wireframe: true,
    side: THREE.DoubleSide,
    transparent: true,
    depthWrite: false,
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'SpaceshipEffect';
  // Adjust angle for a steeper perspective
  mesh.rotation.x = -0.8; // Try a larger negative value
  mesh.userData.baseEffectIntensity = 1.0;
  // No rotation needed based on last request
  // mesh.userData.rotationSpeedY = 0.002;

  scene.add(mesh);
  visualElements.push(mesh);
}
    
// 1. createOceanEffect()
function createOceanEffect() {
  // 1) High‑detail icosahedron for a smooth sphere
  const radius = 200;
  const detail = 6;
  const geometry = new THREE.IcosahedronBufferGeometry(radius, detail);

  // 2) ShaderMaterial with no displacement by default
  const material = new THREE.ShaderMaterial({
    uniforms: {
      time:            { value: 0.0 },
      // Replace audioIntensity with specific frequency uniforms
      // audioIntensity:  { value: 0.0 }, 
      uBass:           { value: 0.0 },
      uMid:            { value: 0.0 },
      uTreble:         { value: 0.0 },
      flowSpeed:       { value: 1.0 },
      audioStrength:   { value: 50.0 }, // Controls magnitude of audio reaction
      effectIntensity: { value: 1.0 }, // Controls magnitude of base morphing + scales audio reaction
    },
    vertexShader: `
      uniform float time;
      // uniform float audioIntensity; // Removed
      uniform float uBass;
      uniform float uMid;
      uniform float uTreble;
      uniform float flowSpeed;
      uniform float audioStrength;
      uniform float effectIntensity;
      varying vec3 vNormal;
      varying float vDisplacement; // Pass displacement to fragment shader if needed for color

      // --- Noise Functions (FBM) ---
      // Simple 2D hash
      float hash(vec2 p) { return fract(sin(dot(p, vec2(127.1, 311.7))) * 43758.5453); }
      // 3D hash
      float hash3d(vec3 p) { 
          p = fract(p * 0.1031); 
          p += dot(p, p.yzx + 33.33); 
          return fract((p.x + p.y) * p.z); 
      }
      // Value noise
      float noise(vec3 p) {
          vec3 i = floor(p);
          vec3 f = fract(p);
          f = f * f * (3.0 - 2.0 * f); // Smoothstep interpolation
          
          float v000 = hash3d(i + vec3(0,0,0));
          float v100 = hash3d(i + vec3(1,0,0));
          float v010 = hash3d(i + vec3(0,1,0));
          float v110 = hash3d(i + vec3(1,1,0));
          float v001 = hash3d(i + vec3(0,0,1));
          float v101 = hash3d(i + vec3(1,0,1));
          float v011 = hash3d(i + vec3(0,1,1));
          float v111 = hash3d(i + vec3(1,1,1));
          
          return mix(mix(mix(v000, v100, f.x), mix(v010, v110, f.x), f.y),
                     mix(mix(v001, v101, f.x), mix(v011, v111, f.x), f.y), 
                     f.z);
      }
      // Fractional Brownian Motion (FBM)
      float fbm(vec3 p, int octaves) {
          float total = 0.0;
          float amplitude = 0.5;
          float frequency = 1.0;
          for (int i = 0; i < octaves; i++) {
              total += amplitude * noise(p * frequency);
              frequency *= 2.0;
              amplitude *= 0.5;
          }
          return total;
      }
      // --- End Noise Functions ---

      void main() {
        vNormal = normal;
        vec3 worldPos = position; // Use world position for noise calculation

        // --- Base Morphing (always active) ---
        float baseMorphSpeed = time * flowSpeed * 0.5;
        // Use 4 octaves for FBM to get some detail
        float baseNoise = fbm(worldPos * 0.01 + baseMorphSpeed, 4); 
        // Scale base morphing by effectIntensity
        float baseDisplacement = baseNoise * 25.0 * effectIntensity; 

        // --- Audio Reactive Displacement ---
        // Bass: Larger, slower bulges
        float bassNoiseFreq = 0.005;
        float bassNoiseSpeed = time * flowSpeed * 0.2;
        float bassNoise = noise(worldPos * bassNoiseFreq + bassNoiseSpeed);
        float bassDisp = pow(uBass, 2.0) * bassNoise * audioStrength * 1.5; // Exponential response

        // Mid: Twisting / higher frequency noise
        float midNoiseFreq = 0.02;
        float midNoiseSpeed = time * flowSpeed * 0.8;
        float midNoise = fbm(worldPos * midNoiseFreq + midNoiseSpeed, 3); // 3 octaves
        float midDisp = uMid * midNoise * audioStrength * 0.8;

        // Treble: Sharp, fast spikes
        float trebleNoiseFreq = 0.05;
        float trebleNoiseSpeed = time * flowSpeed * 1.5;
        // Use a simple noise for sharper look, maybe abs()
        float trebleNoise = abs(noise(worldPos * trebleNoiseFreq + trebleNoiseSpeed)); 
        float trebleDisp = pow(uTreble, 1.5) * trebleNoise * audioStrength * 1.2; 

        // Combine displacements (base morph + audio, scaled by overall intensity)
        float totalDisplacement = baseDisplacement + (bassDisp + midDisp + trebleDisp) * effectIntensity;
        
        vDisplacement = totalDisplacement; // Pass total displacement

        vec3 displaced = position + normal * totalDisplacement;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(displaced, 1.0);
      }
    `,
    fragmentShader: `
      varying vec3 vNormal;
      varying float vDisplacement; // Receive displacement
      uniform float time; // Add time uniform for color effects

      // Simple HSV to RGB conversion
      vec3 hsv2rgb(vec3 c) {
        vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
        vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
        return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
      }

      void main() {
        // Rim lighting based on normal
        float rim = pow(1.0 - abs(dot(normalize(vNormal), vec3(0.0,0.0,1.0))), 2.0); // View-dependent rim

        // Base color (blueish)
        vec3 baseColor = vec3(0.0, 0.2, 0.6);

        // Color variation based on displacement magnitude
        // Map displacement range (e.g., -50 to 100) to hue (0 to 0.3)
        float hueShift = smoothstep(-50.0, 100.0, vDisplacement) * 0.3; 
        float hue = mod(0.6 + hueShift + time * 0.05, 1.0); // Base blue/cyan + shift + slow cycle
        float saturation = 0.7 + rim * 0.3; // More saturated at edges
        float value = 0.6 + rim * 0.4;      // Brighter at edges

        vec3 dynamicColor = hsv2rgb(vec3(hue, saturation, value));

        // Mix base color and dynamic color based on rim
        vec3 finalColor = mix(baseColor, dynamicColor, 0.5 + rim * 0.5);

        gl_FragColor = vec4(finalColor, 1.0);
      }
    `,
    wireframe: true,
    transparent: false
  });

  // 3) Add to scene
  const oceanMesh = new THREE.Mesh(geometry, material);
  oceanMesh.name  = 'OceanEffect';
  scene.add(oceanMesh);
  visualElements.push(oceanMesh);
}
    
    

    function createAuroraEffect() {
  // 1) Calculate the needed plane size to fill the view at a given distance.

  // The camera has these properties:
  //   camera.fov (vertical field of view in degrees)
  //   camera.aspect (width / height)
  //   camera.position.z (e.g. 500)

  // We want the plane at z = -500, so the distance from camera to plane is:
  const distance = camera.position.z - (-500); // e.g. 500 - (-500) = 1000

  // Convert FOV from degrees to radians
  const fovInRadians = (camera.fov * Math.PI) / 180.0;

  // The plane height needed to fill the vertical FOV at 'distance':
  const planeHeight = 2 * distance * Math.tan(fovInRadians / 2);

  // The plane width depends on the camera aspect ratio:
  const planeWidth = planeHeight * camera.aspect;

  // 2) Create a plane geometry that exactly fills the camera view at that distance:
  const geometry = new THREE.PlaneBufferGeometry(planeWidth, planeHeight, 1, 1);

  // 3) Build the same ShaderMaterial you already have:
  const material = new THREE.ShaderMaterial({
    uniforms: {
      time: { value: 0.0 },
      audioIntensity: { value: 0.0 },
      effectIntensity: { value: 1.0 },
      resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
      cameraTexture: { value: null },
      visualMode: { value: 0.0 },
      cameraActive: { value: 0.0 }
    },
    vertexShader: `
      varying vec2 vUv;
      void main(){
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      // (Same aurora-smoke shader logic you already have)
      uniform float time;
      uniform float audioIntensity;
      uniform float effectIntensity;
      uniform vec2 resolution;
      varying vec2 vUv;
      uniform sampler2D cameraTexture;
      uniform float visualMode;
      uniform float cameraActive;
      
      float hash(vec2 p) {
          return fract(sin(dot(p, vec2(12.9898,78.233))) * 43758.5453123);
      }
      float noise(vec2 p) {
          vec2 i = floor(p), f = fract(p);
          vec2 u = f * f * (3.0 - 2.0 * f);
          return mix(mix(hash(i), hash(i + vec2(1.0, 0.0)), u.x),
                     mix(hash(i + vec2(0.0, 1.0)), hash(i + vec2(1.0, 1.0)), u.x),
                     u.y);
      }
      float fbm(vec2 p) {
          float total = 0.0;
          float amplitude = 0.5;
          for (int i = 0; i < 5; i++) {
              total += amplitude * noise(p);
              p *= 2.0;
              amplitude *= 0.5;
          }
          return total;
      }
      void main() {
          // Convert vUv to a 'centered' coordinate that accounts for aspect ratio.
          vec2 centeredUv = (vUv - 0.5) * vec2(resolution.x / resolution.y, 1.0);
          
          // Base noise layer
          float baseNoise = fbm(centeredUv * 3.0 + time * 0.2);
          // Audio-driven noise layer
          float audioNoise = fbm(centeredUv * 10.0 + time * 2.0);
          float combinedNoise = baseNoise + audioIntensity * effectIntensity * audioNoise;
          
          // Swirl the UV coords based on the combined noise
          float angle = time * 0.1 + combinedNoise * 6.2831;
          mat2 rot = mat2(cos(angle), -sin(angle), sin(angle), cos(angle));
          vec2 swirledUv = rot * centeredUv;
          
          // Fine detail noise
          float detailNoise = fbm(swirledUv * 4.0 + time * 0.5);
          float smokeValue = mix(combinedNoise, detailNoise, 0.5);
          
          // Aurora color gradient
          vec3 colorA = vec3(0.2, 0.0, 0.3);  // deep purple
          vec3 colorB = vec3(0.0, 0.6, 0.8);  // cyan
          vec3 finalColor = mix(colorA, colorB, smoothstep(0.3, 0.7, smokeValue));
          
          // Glow in bright areas
          float glow = smoothstep(0.4, 0.5, smokeValue) * audioIntensity * effectIntensity;
          finalColor += glow * vec3(0.8, 0.9, 1.0);
          
          // Subtle vignette
          float d = distance(vUv, vec2(0.5));
          finalColor *= smoothstep(0.8, 0.4, d);
          
          vec2 screenUV = gl_FragCoord.xy / resolution.xy;
          vec4 cameraColor = texture2D(cameraTexture, screenUV);
          
          if (visualMode == 0.0 || cameraActive < 0.5) {
            // Off: Normal rendering
            gl_FragColor = vec4(finalColor, 1.0);
          } else if (visualMode == 1.0) {
            // Style 1: Distort camera feed using aurora's swirl logic
            // The 'swirledUv' variable holds the UV coordinates distorted by the aurora logic.
            // We need to map this back to the [0, 1] range for texture sampling.
            // Inverse of: vec2 centeredUv = (vUv - 0.5) * vec2(resolution.x / resolution.y, 1.0);
            vec2 distortedScreenUv = (swirledUv / vec2(resolution.x / resolution.y, 1.0)) + 0.5;
            
            // Clamp UVs to avoid sampling outside the texture borders
            distortedScreenUv = clamp(distortedScreenUv, 0.0, 1.0);

            // Sample camera texture using the distorted UVs
            vec3 distortedCameraColor = texture2D(cameraTexture, distortedScreenUv).rgb;

            // Use the original aurora's alpha/intensity as a mask
            float effectMask = smoothstep(0.1, 0.6, length(finalColor)); // Reuse alpha estimation from original aurora color calculation

            // Output the distorted camera feed, masked by where the aurora would be
            // Mix between original camera feed (background) and distorted feed (foreground)
            vec3 originalCameraColor = texture2D(cameraTexture, vUv).rgb; // Get original camera color at this pixel
            vec3 outputColor = mix(originalCameraColor, distortedCameraColor, effectMask); 

            gl_FragColor = vec4(outputColor, 1.0); // Output is fully opaque
          } else if (visualMode == 2.0) {
            // Style 2: Blend original aurora with camera feed
            // Use smokeValue or estimated alpha for blending factor
            float blendFactor = smoothstep(0.1, 0.6, length(finalColor)); // Reuse alpha estimation
            vec3 blendedColor = mix(cameraColor.rgb, finalColor, blendFactor);
            gl_FragColor = vec4(blendedColor, 1.0);
          } else {
            // Fallback (same as normal)
            gl_FragColor = vec4(finalColor, 1.0);
          }
      }
    `,
    transparent: true,
    blending: THREE.AdditiveBlending
  });

  // 4) Create the mesh, position it at z = -500
  const auroraSmoke = new THREE.Mesh(geometry, material);
  auroraSmoke.name = "AuroraEffect";
  auroraSmoke.position.z = -500; 
  scene.add(auroraSmoke);
  visualElements.push(auroraSmoke);
}
// 1. Replace the existing createScribbleEffect() function with this new version:
function createScribbleEffect() {
  // Calculate the needed plane size to fill the view at z=0.
  const distance = camera.position.z; // Distance from camera to plane at z=0
  const fovInRadians = (camera.fov * Math.PI) / 180.0;
  const planeHeight = 2 * distance * Math.tan(fovInRadians / 2);
  const planeWidth = planeHeight * camera.aspect;

  // Fullscreen plane
  const geometry = new THREE.PlaneBufferGeometry(planeWidth, planeHeight);
  const material = new THREE.ShaderMaterial({
    transparent: true,
    blending: THREE.AdditiveBlending,
    uniforms: {
      resolution:      { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
      time:            { value: 0.0 },
      audioLevel:      { value: 0.0 },
      effectIntensity: { value: 1.0 },
      loopCount:       { value: 6.0 },
      baseRadius:      { value: 0.5 },
      radiusVariation: { value: 0.35 },
      lineThickness:   { value: 0.008 },
      glowIntensity:   { value: 0.5 },
      colorA:          { value: new THREE.Color(0x6aff00) },
      colorB:          { value: new THREE.Color(0x00ffd2) },
      cameraTexture:   { value: null },
      visualMode:      { value: 0.0 },
      cameraActive:    { value: 0.0 }
    },
    vertexShader: `
      varying vec2 vUv;
      void main() {
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      precision highp float;
      varying vec2 vUv;
      uniform vec2 resolution;
      uniform float time;
      uniform float audioLevel;
      uniform float effectIntensity;
      uniform float loopCount;
      uniform float baseRadius;
      uniform float radiusVariation;
      uniform float lineThickness;
      uniform float glowIntensity;
      uniform vec3 colorA;
      uniform vec3 colorB;
      uniform sampler2D cameraTexture;
      uniform float visualMode;
      uniform float cameraActive;

      // 2D noise
      float rand(vec2 co) {
        return fract(sin(dot(co,vec2(12.9898,78.233))) * 43758.5453);
      }
      float noise(vec2 p) {
        vec2 i = floor(p), f = fract(p);
        float a = rand(i), b = rand(i + vec2(1.0,0.0));
        float c = rand(i + vec2(0.0,1.0)), d = rand(i + vec2(1.0,1.0));
        vec2 u = f*f*(3.0-2.0*f);
        return mix(mix(a,b,u.x), mix(c,d,u.x), u.y);
      }

      void main() {
        // normalize coords to -1..1
        vec2 uv = vUv * 2.0 - 1.0;
        uv.x *= resolution.x / resolution.y;

        vec3 accumColor = vec3(0.0);
        float accumAlpha = 0.0;

        for (float i = 0.0; i < loopCount; i += 1.0) {
          float pct = (i + 1.0) / loopCount;

          // fast‑spinning, evolving angle
          float angle = pct * 6.283185 * (2.0 + pct) + time * (4.0 + pct * 5.0);

          // pulsing radius + audio influence
          float r = baseRadius 
                    + radiusVariation * sin(time * (5.0 + pct * 10.0)) 
                    * (0.5 + audioLevel * 0.5);

          // hand‑drawn jitter
          float jitter = noise(vec2(cos(angle), sin(angle)) * 5.0 + time * 3.0) * 0.1;

          // compute center of this loop
          vec2 center = vec2(cos(angle), sin(angle)) * r * effectIntensity;

          // build an oriented, pulsing ellipse ("worm")
          float longA = r * effectIntensity * (1.0 + 0.3 * sin(time * 20.0 + pct * 6.0));
          float shortA = r * effectIntensity * 0.3;
          vec2 dir = uv - center;

          // rotate dir so ellipse is aligned
          float ca = cos(-angle), sa = sin(-angle);
          vec2 rotDir = vec2(
            dir.x * ca - dir.y * sa,
            dir.x * sa + dir.y * ca
          );

          // distance from ellipse boundary
          float d = length(vec2(rotDir.x / longA, rotDir.y / shortA))
                    - (1.0 + jitter);

          // edge+glow
          float glow = smoothstep(lineThickness + glowIntensity, lineThickness, abs(d));

          // per‑ring color
          vec3 ringColor = mix(colorA, colorB, pct);

          accumColor += ringColor * glow;
          accumAlpha = max(accumAlpha, glow);
        }

        vec2 screenUV = gl_FragCoord.xy / resolution.xy;
        vec4 cameraColor = texture2D(cameraTexture, screenUV);

        // Check cameraActive uniform before using camera feed
        if (visualMode == 0.0 || cameraActive < 0.5) { // Also check cameraActive
          // Off: Normal rendering
          gl_FragColor = vec4(accumColor, accumAlpha);
        } else if (visualMode == 1.0) {
          // Style 1: Multiply scribble color by camera feed
          vec3 finalColor = accumColor * cameraColor.rgb;
          gl_FragColor = vec4(finalColor, accumAlpha); // Use original scribble alpha
        } else if (visualMode == 2.0) {
          // Style 2: Scribbles on camera feed background
          vec3 finalColor = mix(cameraColor.rgb, accumColor, accumAlpha);
          gl_FragColor = vec4(finalColor, 1.0); // Make background opaque
        } else if (visualMode == 3.0) {
          // Style 3: Camera feed only
          gl_FragColor = cameraColor;
        } else {
          // Fallback (same as normal)
          gl_FragColor = vec4(accumColor, accumAlpha);
        }
      }
    `
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'Scribble';
  scene.add(mesh);
  visualElements.push(mesh);
}

function createOrangeEffect() {
  // Create a full-screen plane.
  const geometry = new THREE.PlaneBufferGeometry(2000, 2000, 1, 1);

  const material = new THREE.ShaderMaterial({
    uniforms: {
      time: { value: 0.0 },
      // This texture must be assigned when camera mode is enabled.
      cameraTexture: { value: null },
      resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
      effectIntensity: { value: 1.0 },
      audioIntensity: { value: 0.0 },
      // Use HSV to create a dynamic background; baseHue is roughly orange.
      baseHue: { value: 0.05 },
      // When true, we switch to camera–based silhouette.
      visualMode: { value: 0.0 },
      // Pixels with luminance less than brightnessThreshold are considered part of the subject.
      brightnessThreshold: { value: 0.5 },
      // Edge threshold for our Sobel filter; adjust to boost the outline.
      edgeThreshold: { value: 0.2 }
    },
    vertexShader: `
      varying vec2 vUv;
      void main() {
         vUv = uv;
         gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
  precision mediump float;
  uniform float time;
  uniform sampler2D cameraTexture;
  uniform vec2 resolution;
  uniform float effectIntensity;
  uniform float audioIntensity;
  uniform float baseHue;
  uniform float visualMode;
  uniform float brightnessThreshold;
  uniform float edgeThreshold;
  varying vec2 vUv;

  // Convert HSV to RGB.
  vec3 hsv2rgb(vec3 c) {
    vec3 rgb = clamp(abs(mod(c.x * 6.0 + vec3(0.0,4.0,2.0), 6.0) - 3.0) - 1.0, 0.0, 1.0);
    return c.z * mix(vec3(1.0), rgb, c.y);
  }

  // Compute luminance from an RGB color.
  float luminance(vec3 color) {
    return dot(color, vec3(0.299, 0.587, 0.114));
  }

  // Sobel edge detection function to compute edge magnitude at a given UV.
  float edgeSobel(vec2 uv) {
    vec2 onePixel = vec2(1.0) / resolution;
    float tl = luminance(texture2D(cameraTexture, uv + onePixel * vec2(-1.0, -1.0)).rgb);
    float t  = luminance(texture2D(cameraTexture, uv + onePixel * vec2( 0.0, -1.0)).rgb);
    float tr = luminance(texture2D(cameraTexture, uv + onePixel * vec2( 1.0, -1.0)).rgb);
    float l  = luminance(texture2D(cameraTexture, uv + onePixel * vec2(-1.0,  0.0)).rgb);
    float r  = luminance(texture2D(cameraTexture, uv + onePixel * vec2( 1.0,  0.0)).rgb);
    float bl = luminance(texture2D(cameraTexture, uv + onePixel * vec2(-1.0,  1.0)).rgb);
    float b  = luminance(texture2D(cameraTexture, uv + onePixel * vec2( 0.0,  1.0)).rgb);
    float br = luminance(texture2D(cameraTexture, uv + onePixel * vec2( 1.0,  1.0)).rgb);
    float gx = -tl - 2.0 * l - bl + tr + 2.0 * r + br;
    float gy = -tl - 2.0 * t - tr + bl + 2.0 * b + br;
    return length(vec2(gx, gy));
  }

  void main() {
    // Compute a dynamic background color using an HSV cycle.
    float hue = mod(baseHue + 0.1 * sin(time * 0.2 + audioIntensity), 1.0);
    vec3 bgColor = hsv2rgb(vec3(hue, 0.8, 0.95));

    if (visualMode < 0.5) {
      // Mode 0: Normal mode (no overlay).
      gl_FragColor = vec4(bgColor, 1.0);

    } else if (abs(visualMode - 1.0) < 0.1) {
      // Mode 1: Outline only.
      vec3 camSample = texture2D(cameraTexture, vUv).rgb;
      float lum = luminance(camSample);
      float binaryMask = step(lum, brightnessThreshold);
      float edgeMag = edgeSobel(vUv);
      float edgeMask = step(edgeThreshold, edgeMag);
      float outline = binaryMask * edgeMask;
      vec3 finalColor = mix(bgColor, vec3(0.0), outline);
      gl_FragColor = vec4(finalColor, 1.0);

    } else if (abs(visualMode - 2.0) < 0.1) {
      // Mode 2: Filled silhouette only (no separate outline).
      vec3 camSample = texture2D(cameraTexture, vUv).rgb;
      float lum = luminance(camSample);
      float binaryMask = step(lum, brightnessThreshold);
      vec3 finalColor = mix(bgColor, vec3(0.0), binaryMask);
      gl_FragColor = vec4(finalColor, 1.0);

    } else if (abs(visualMode - 3.0) < 0.1) {
      // Mode 3: Clear view mode (user's silhouette in camera feed).
      vec3 camSample = texture2D(cameraTexture, vUv).rgb;
      float lum = luminance(camSample);
      float binaryMask = step(lum, brightnessThreshold);
      vec3 finalColor = mix(bgColor, camSample, binaryMask);
      gl_FragColor = vec4(finalColor, 1.0);

    } 
    /***************
     * NEW MODE 4 *
     ***************/
    else if (abs(visualMode - 4.0) < 0.1) {
      // Mode 4: Outline + Fill
      // 1) We detect the user as in outline mode, but 2) also fill them in with black.
      vec3 camSample = texture2D(cameraTexture, vUv).rgb;
      float lum = luminance(camSample);
      float binaryMask = step(lum, brightnessThreshold);
      float edgeMag = edgeSobel(vUv);
      float edgeMask = step(edgeThreshold, edgeMag);
      float outline = binaryMask * edgeMask;

      // Fill the subject region with black
      vec3 fillColor = mix(bgColor, vec3(0.0), binaryMask);
      // Then ensure the outline remains black as well
      vec3 finalColor = mix(fillColor, vec3(0.0), outline);

      gl_FragColor = vec4(finalColor, 1.0);

    } else {
      // Fallback (same as normal).
      gl_FragColor = vec4(bgColor, 1.0);
    }
  }
`,
    transparent: true,
    blending: THREE.NormalBlending
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'Orange';
  scene.add(mesh);
  visualElements.push(mesh);
}

function createGlitchEffect() {
  const geometry = new THREE.PlaneBufferGeometry(2, 2); // Fullscreen quad
  const material = new THREE.ShaderMaterial({
    uniforms: {
      tDiffuse: { value: null }, // Placeholder for scene texture (if doing post-processing)
      time: { value: 0.0 },
      audioBass: { value: 0.0 },
      audioMid: { value: 0.0 },
      audioTreble: { value: 0.0 },
      effectIntensity: { value: 1.0 },
      resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) }
    },
    vertexShader: `
      varying vec2 vUv;
      void main() {
        vUv = uv;
        gl_Position = vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      precision highp float;
      uniform sampler2D tDiffuse; // Not used in this procedural version, but kept for potential future use
      uniform float time;
      uniform float audioBass;
      uniform float audioMid;
      uniform float audioTreble;
      uniform float effectIntensity;
      uniform vec2 resolution;
      varying vec2 vUv;

      // Random function
      float rand(vec2 co){
        return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
      }

      // Function to generate random vibrant colors
      vec3 randomColor(float seed) {
          float r = rand(vec2(seed * 0.1, seed * 0.2));
          float g = rand(vec2(seed * 0.3, seed * 0.4));
          float b = rand(vec2(seed * 0.5, seed * 0.6));
          // Bias towards brighter, more saturated colors found in the image
          return normalize(vec3(r, g, b)) * 0.8 + 0.2; // Ensure minimum brightness
      }

      void main() {
        vec2 uv = vUv;
          vec3 finalColor = vec3(0.0); // Start with black

          // --- Glitch Parameters (more aggressive) ---
          float timeScaled = time * (1.0 + audioMid * 2.0); // Time scaled by mid freq
          float intensity = effectIntensity * (1.0 + audioBass * 1.5); // Intensity boosted by bass

          // 1. Block Displacement & Color Glitch
          float blockSize = mix(50.0, 5.0, pow(audioBass, 2.0) * intensity); // Smaller blocks with more bass
          vec2 blockUv = floor(uv * blockSize) / blockSize;
          float blockSeed = rand(blockUv + floor(timeScaled * 5.0));
          vec2 blockOffset = vec2(rand(blockUv + 1.0) - 0.5, rand(blockUv + 2.0) - 0.5) * 0.1 * pow(audioMid, 2.0) * intensity;
          vec3 blockColor = randomColor(blockSeed * 10.0) * step(0.3, rand(blockUv + 3.0 + floor(timeScaled * 2.0))); // Random blocks of color appear/disappear

          // 2. Horizontal Line Tearing & Color Shift
          float lineFreq = mix(200.0, 50.0, pow(audioMid, 1.5) * intensity);
          float lineBlock = floor(uv.y * lineFreq);
          float lineSeed = rand(vec2(lineBlock, floor(timeScaled * 15.0)));
          float lineShiftAmount = (lineSeed - 0.5) * 0.2 * pow(audioTreble, 2.0) * intensity;
          vec2 lineShiftUv = uv + vec2(lineShiftAmount, 0.0);
          vec3 lineShiftColor = randomColor(lineSeed * 20.0) * smoothstep(0.6, 0.65, rand(vec2(lineBlock, floor(timeScaled * 8.0 + 1.0)))); // Horizontal color streaks

          // 3. Vertical Streaks / Scanlines
          float vertFreq = mix(300.0, 80.0, pow(audioTreble, 1.5) * intensity);
          float vertLine = floor(uv.x * vertFreq);
          float vertSeed = rand(vec2(vertLine, floor(timeScaled * 12.0)));
          float vertLineIntensity = smoothstep(0.8, 0.85, vertSeed) * 0.8; // Thin vertical lines
          vec3 vertLineColor = vec3(vertLineIntensity * (0.5 + rand(vec2(vertLine + 1.0)) * 0.5)); // Grayscale vertical lines

          // 4. Chromatic Aberration (applied to a base noise pattern)
          float noiseFreq = 5.0 + audioTreble * 15.0 * intensity;
          float baseNoise = rand(uv * noiseFreq + timeScaled * 0.5); // Simple base noise pattern
          float caOffset = pow(audioTreble, 1.5) * 0.02 * intensity;
          float r = rand((uv + vec2(caOffset, 0.0)) * noiseFreq + timeScaled * 0.5);
          float g = baseNoise;
          float b = rand((uv - vec2(caOffset, 0.0)) * noiseFreq + timeScaled * 0.5);
          vec3 noisyColor = vec3(r, g, b);

          // 5. High-Frequency Noise Overlay
          float fineNoise = (rand(uv * 500.0 + timeScaled * 50.0) - 0.5) * 0.15 * intensity;

          // --- Combine Layers ---
          // Start with the noisy, color-aberrated base
          finalColor = noisyColor;

          // Add block color displacement (affecting UV for subsequent layers too)
          vec2 displacedUv = lineShiftUv + blockOffset;
          float displaceFactor = step(0.5, blockSeed); // Only apply displacement for some blocks
          finalColor = mix(finalColor, blockColor, displaceFactor * 0.6); // Mix in block colors

          // Add horizontal line shift colors (using potentially displaced UVs)
          finalColor = mix(finalColor, lineShiftColor, lineShiftColor.r * 0.7); // Mix based on line visibility

          // Add vertical lines
          finalColor += vertLineColor * 0.5;

          // Add fine noise
          finalColor += fineNoise;

          // Final clamping
          gl_FragColor = vec4(clamp(finalColor, 0.0, 1.0), 1.0);
      }
    `,
    // This effect might work better as a post-processing pass,
    // but for simplicity, we'll make it a fullscreen quad for now.
    // If using as post-processing, set depthTest and depthWrite to false.
    depthTest: false,
    depthWrite: false,
    transparent: true, // Can be true if layered
    blending: THREE.NormalBlending
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'GlitchEffect';
  // Ensure it renders last if transparent or on top
  mesh.renderOrder = 999;
  mesh.userData.baseEffectIntensity = 1.0; // Base intensity
  scene.add(mesh);
  visualElements.push(mesh);

  // Custom update functions (optional, but good practice)
  mesh.userData.customAnimateInitial = function() {
    const mat = this.material;
    const time = performance.now() * 0.001;
    mat.uniforms.time.value = time;
    mat.uniforms.audioBass.value = 0.05; // Small baseline activity
    mat.uniforms.audioMid.value = 0.05;
    mat.uniforms.audioTreble.value = 0.05;
    mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
    const mat = this.material;
    const time = performance.now() * 0.001;
    mat.uniforms.time.value = time;
    mat.uniforms.audioBass.value = bassAvg;
    mat.uniforms.audioMid.value = midAvg;
    mat.uniforms.audioTreble.value = trebleAvg;
    mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
    this.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.2; // Map 1-9 -> 0.7 to 2.3
  }.bind(mesh);
}

function createBlobEffect() {
  // Use Icosahedron for a relatively smooth base sphere
  const geometry = new THREE.IcosahedronBufferGeometry(150, 5); // Radius, detail
  const material = new THREE.ShaderMaterial({
      uniforms: {
          time: { value: 0.0 },
          uBass: { value: 0.0 },
          uMid: { value: 0.0 },
          uTreble: { value: 0.0 },
          effectIntensity: { value: 1.0 },
          uColor1: { value: new THREE.Color(0xff00ff) }, // Magenta
          uColor2: { value: new THREE.Color(0x00ffff) }, // Cyan
      },
      vertexShader: `
          uniform float time;
          uniform float uBass;
          uniform float uMid;
          uniform float uTreble;
          uniform float effectIntensity;

          varying vec3 vNormal;
          varying float vDisplacement;

          // Simplex 3D noise function (replace with your preferred noise if needed)
          // Source: https://github.com/ashima/webgl-noise/blob/master/src/noise3D.glsl
          vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
          vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
          vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); }
          vec4 taylorInvSqrt(vec4 r) { return 1.79284291400159 - 0.85373472095314 * r; }
          vec3 fade(vec3 t) { return t*t*t*(t*(t*6.0-15.0)+10.0); }

          float snoise(vec3 v) {
              const vec2 C = vec2(1.0/6.0, 1.0/3.0) ;
              const vec4 D = vec4(0.0, 0.5, 1.0, 2.0);
              vec3 i  = floor(v + dot(v, C.yyy) );
              vec3 x0 =   v - i + dot(i, C.xxx) ;
              vec3 g = step(x0.yzx, x0.xyz);
              vec3 l = 1.0 - g;
              vec3 i1 = min( g.xyz, l.zxy );
              vec3 i2 = max( g.xyz, l.zxy );
              vec3 x1 = x0 - i1 + C.xxx;
              vec3 x2 = x0 - i2 + C.yyy;
              vec3 x3 = x0 - D.yyy;
              i = mod289(i);
              vec4 p = permute( permute( permute(
                         i.z + vec4(0.0, i1.z, i2.z, 1.0 ))
                       + i.y + vec4(0.0, i1.y, i2.y, 1.0 ))
                       + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));
              float n_ = 0.142857142857; // 1.0/7.0
              vec3 ns = n_ * D.wyz - D.xzx;
              vec4 j = p - 49.0 * floor(p * ns.z * ns.z);  //  mod(p,7*7)
              vec4 x_ = floor(j * ns.z);
              vec4 y_ = floor(j - 7.0 * x_ );    // mod(j,N)
              vec4 x = x_ *ns.x + ns.yyyy;
              vec4 y = y_ *ns.x + ns.yyyy;
              vec4 h = 1.0 - abs(x) - abs(y);
              vec4 b0 = vec4( x.xy, y.xy );
              vec4 b1 = vec4( x.zw, y.zw );
              vec4 s0 = floor(b0)*2.0 + 1.0;
              vec4 s1 = floor(b1)*2.0 + 1.0;
              vec4 sh = -step(h, vec4(0.0));
              vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;
              vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;
              vec3 p0 = vec3(a0.xy,h.x);
              vec3 p1 = vec3(a0.zw,h.y);
              vec3 p2 = vec3(a1.xy,h.z);
              vec3 p3 = vec3(a1.zw,h.w);
              vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));
              p0 *= norm.x;
              p1 *= norm.y;
              p2 *= norm.z;
              p3 *= norm.w;
              vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
              m = m * m;
              return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3) ) );
          }

          void main() {
              vNormal = normal;
              vec3 pos = position;

              // Noise parameters
              float noiseFreq = 1.5 * effectIntensity;
              float noiseSpeed = time * 0.3 * effectIntensity;
              float noiseAmp = 60.0 * effectIntensity;

              // Audio influence
              float bassInfluence = pow(uBass, 1.5) * 80.0 * effectIntensity; // Bass makes it bulge more
              float midInfluence = uMid * 0.5 * effectIntensity; // Mid slightly increases frequency
              float trebleInfluence = uTreble * 0.3 * effectIntensity; // Treble slightly increases speed

              // Calculate noise position
              vec3 noisePos = pos * (0.005 + midInfluence * 0.002); // Scale position for noise input

              // Calculate displacement using Simplex noise
              float displacement = snoise(noisePos + noiseSpeed + trebleInfluence) * noiseAmp;
              displacement += snoise(noisePos * 2.1 + noiseSpeed * 0.8) * noiseAmp * 0.5; // Add another layer of noise

              // Add bass bulge
              displacement += bassInfluence * (1.0 + snoise(pos * 0.01 + time * 0.1)); // Smooth bass pulse

              vDisplacement = displacement; // Pass displacement for coloring

              vec3 displacedPosition = pos + normal * displacement;
              gl_Position = projectionMatrix * modelViewMatrix * vec4(displacedPosition, 1.0);
          }
      `,
      fragmentShader: `
          uniform vec3 uColor1;
          uniform vec3 uColor2;
          uniform float time;
          uniform float uMid; // Use mid frequency for color cycling

          varying vec3 vNormal;
          varying float vDisplacement; // Receive displacement

          // Basic lighting calculation
          float calculateLighting(vec3 normal) {
              vec3 lightDir = normalize(vec3(0.5, 0.5, 1.0));
              float diffuse = max(dot(normal, lightDir), 0.0);
              return 0.3 + diffuse * 0.7; // Ambient + Diffuse
          }

          void main() {
              // Color based on displacement and time/audio
              float colorMix = smoothstep(-50.0, 80.0, vDisplacement); // Map displacement to 0-1
              colorMix = fract(colorMix + time * 0.1 + uMid * 0.5); // Add time and audio driven shift

              vec3 mixedColor = mix(uColor1, uColor2, colorMix);

              // Apply basic lighting
              float lighting = calculateLighting(normalize(vNormal));
              vec3 finalColor = mixedColor * lighting;

              // Add a subtle rim light effect based on normal
              float rim = pow(1.0 - abs(dot(normalize(vNormal), vec3(0.0, 0.0, -1.0))), 3.0);
              finalColor += vec3(1.0) * rim * 0.5; // Add white rim light

              gl_FragColor = vec4(finalColor, 1.0);
          }
      `,
      // wireframe: true, // Optional: Set to true to see the mesh structure
      transparent: false // Opaque blob
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'BlobEffect';
  mesh.userData.baseEffectIntensity = 1.0;
  scene.add(mesh);
  visualElements.push(mesh);

  // Custom update functions
  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.uBass.value = 0.0;
      mat.uniforms.uMid.value = 0.0;
      mat.uniforms.uTreble.value = 0.0;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.uBass.value = bassAvg;
      mat.uniforms.uMid.value = midAvg;
      mat.uniforms.uTreble.value = trebleAvg;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
      // Map intensity 1-9 to a range, e.g., 0.5 to 2.5
      this.userData.baseEffectIntensity = 0.5 + (intensityLevel - 1) * 0.25;
  }.bind(mesh);
}

function createPopArtEffect() {
  const geometry = new THREE.PlaneBufferGeometry(2, 2); // Fullscreen quad
  const material = new THREE.ShaderMaterial({
      uniforms: {
          time: { value: 0.0 },
          audioBass: { value: 0.0 },
          audioMid: { value: 0.0 },
          audioTreble: { value: 0.0 },
          effectIntensity: { value: 1.0 },
          resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
          cameraTexture: { value: null }, // For optional camera input
          visualMode: { value: 0.0 } // 0: Procedural, 1: Camera
      },
      vertexShader: `
          varying vec2 vUv;
          void main() {
              vUv = uv;
              gl_Position = vec4(position, 1.0);
          }
      `,
      fragmentShader: `
          precision highp float;
          uniform float time;
          uniform float audioBass;
          uniform float audioMid;
          uniform float audioTreble;
          uniform float effectIntensity;
          uniform vec2 resolution;
          uniform sampler2D cameraTexture;
          uniform float visualMode; // 0 or 1
          varying vec2 vUv;

          // Posterization function
          vec3 posterize(vec3 color, float numColors) {
              return floor(color * numColors) / numColors;
          }

          // Halftone pattern function (simple dots)
          float halftone(vec2 uv, float frequency, float angle, float dotSize) {
              float s = sin(angle);
              float c = cos(angle);
              mat2 rotationMatrix = mat2(c, -s, s, c);
              vec2 rotatedUv = rotationMatrix * uv * frequency;
              vec2 cell = fract(rotatedUv);
              float distToCenter = length(cell - 0.5) * 2.0; // 0 to 1
              return smoothstep(dotSize + 0.05, dotSize - 0.05, distToCenter); // Anti-aliased dot
          }

          // HSV to RGB conversion
          vec3 hsv2rgb(vec3 c) {
              vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
              vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
              return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
          }

          // Simple noise
          float rand(vec2 co){ return fract(sin(dot(co ,vec2(12.9898,78.233))) * 43758.5453); }

          void main() {
              vec2 uv = vUv;
              vec3 finalColor = vec3(0.0);

              // --- Color Palette ---
              // Dynamic palette based on time and audio
              float hueShift = time * 0.1 + audioMid * 0.5;
              vec3 color1 = hsv2rgb(vec3(fract(0.1 + hueShift), 0.9, 0.9)); // Bright Color 1
              vec3 color2 = hsv2rgb(vec3(fract(0.4 + hueShift), 0.9, 0.8)); // Bright Color 2
              vec3 color3 = hsv2rgb(vec3(fract(0.7 + hueShift), 0.8, 0.7)); // Bright Color 3
              vec3 bgColor = hsv2rgb(vec3(fract(0.9 + hueShift), 0.5, 0.6)); // Background Color

              // --- Determine Base Image (Procedural or Camera) ---
              vec3 baseImageColor;
              float baseLuminance;

              if (visualMode > 0.5 && texture2D(cameraTexture, vec2(0.5)).a > 0.0) { // Check if camera texture is valid
                  baseImageColor = texture2D(cameraTexture, uv).rgb;
                  baseLuminance = dot(baseImageColor, vec3(0.299, 0.587, 0.114));
              } else {
                  // Procedural pattern (e.g., swirling noise)
                  float noiseVal = rand(uv * (2.0 + audioBass * 5.0) + time * 0.2);
                  noiseVal += sin(uv.x * 10.0 + time + audioMid * 10.0) * cos(uv.y * 10.0 - time + audioTreble * 10.0) * 0.5;
                  baseLuminance = smoothstep(0.3, 0.7, noiseVal);
                  baseImageColor = vec3(baseLuminance); // Use luminance for procedural pattern coloring
              }

              // --- Apply Effects ---
              // 1. Posterization
              float numPosterColors = floor(3.0 + audioBass * 5.0 * effectIntensity); // 3 to 8 colors based on bass
              vec3 posterizedColor = posterize(baseImageColor, numPosterColors);
              float posterizedLuminance = dot(posterizedColor, vec3(0.299, 0.587, 0.114));

              // 2. Color Mapping based on Luminance Thresholds
              float thresh1 = 0.3;
              float thresh2 = 0.7;
              if (posterizedLuminance < thresh1) {
                  finalColor = color1;
              } else if (posterizedLuminance < thresh2) {
                  finalColor = color2;
              } else {
                  finalColor = color3;
              }

              // 3. Optional Halftone Overlay (driven by treble)
              float halftoneFreq = 50.0 + audioTreble * 150.0 * effectIntensity;
              float halftoneAngle = time * 0.5;
              float halftoneDotSize = 0.5 + audioMid * 0.4; // Mid affects dot size
              float halftoneMask = halftone(uv, halftoneFreq, halftoneAngle, halftoneDotSize);

              // Blend halftone with the mapped color (e.g., darken based on halftone)
              // Only apply halftone to brighter areas maybe?
              if (posterizedLuminance >= thresh1) {
                  finalColor = mix(finalColor, bgColor, halftoneMask * 0.6 * pow(audioTreble, 2.0) * effectIntensity); // Mix with bg based on treble intensity
              }


              gl_FragColor = vec4(finalColor, 1.0);
          }
      `,
      depthTest: false,
      depthWrite: false,
      transparent: true,
      blending: THREE.NormalBlending
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'PopArtEffect';
  mesh.renderOrder = 998; // Render before glitch maybe
  mesh.userData.baseEffectIntensity = 1.0;
  mesh.userData.visualMode = 0.0; // Start with procedural
  scene.add(mesh);
  visualElements.push(mesh);

  // Custom update functions
  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = 0.0;
      mat.uniforms.audioMid.value = 0.0;
      mat.uniforms.audioTreble.value = 0.0;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.visualMode.value = this.userData.visualMode; // Use stored visual mode
      // Check if camera texture should be applied
      if (this.userData.visualMode > 0.5 && window.userCameraTexture) {
          mat.uniforms.cameraTexture.value = window.userCameraTexture;
      } else {
          mat.uniforms.cameraTexture.value = null;
      }
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = bassAvg;
      mat.uniforms.audioMid.value = midAvg;
      mat.uniforms.audioTreble.value = trebleAvg;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.visualMode.value = this.userData.visualMode;
      // Check if camera texture should be applied
      if (this.userData.visualMode > 0.5 && window.userCameraTexture) {
          mat.uniforms.cameraTexture.value = window.userCameraTexture;
      } else {
          mat.uniforms.cameraTexture.value = null;
      }
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
      this.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.15; // Map 1-9 -> 0.65 to 1.7
  }.bind(mesh);

  // Override visual mode toggling for this effect
  mesh.userData.toggleVisualMode = function() {
      this.userData.visualMode = 1.0 - this.userData.visualMode; // Toggle 0 and 1
      showActionMessage("Pop Art Mode: " + (this.userData.visualMode > 0.5 ? "Camera Input" : "Procedural"));
      // Immediately update the uniform for the next frame
      if (this.material) {
          this.material.uniforms.visualMode.value = this.userData.visualMode;
           // Apply/remove camera texture based on the new mode
           if (this.userData.visualMode > 0.5 && window.userCameraTexture) {
               this.material.uniforms.cameraTexture.value = window.userCameraTexture;
               if (!window.isCameraMode) toggleCameraBackground(); // Ensure camera is on if needed
           } else {
               this.material.uniforms.cameraTexture.value = null;
               // Consider turning camera off if nothing else needs it
               // if (window.isCameraMode && !isAnyEffectUsingCamera()) toggleCameraBackground();
           }
      }
  }.bind(mesh);
}

function createNeonGridEffect() {
  // Use a large plane with many subdivisions
  const gridSize = 1500;
  const divisions = 100;
  const geometry = new THREE.PlaneBufferGeometry(gridSize, gridSize, divisions, divisions);

  const material = new THREE.ShaderMaterial({
      uniforms: {
          time: { value: 0.0 },
          audioBass: { value: 0.0 },
          audioMid: { value: 0.0 },
          audioTreble: { value: 0.0 },
          effectIntensity: { value: 1.0 },
          lineWidth: { value: 0.05 }, // Relative line width
          glowPower: { value: 3.0 }, // Power for glow calculation
          gridColor: { value: new THREE.Color(0x00ffff) } // Cyan color
      },
      vertexShader: `
          uniform float time;
          uniform float audioBass;
          uniform float audioMid;
          uniform float audioTreble;
          uniform float effectIntensity;

          varying vec2 vUv;
          varying float vDisplacement;

          // Noise function (e.g., Simplex or Perlin)
          // Using a simple periodic one for now
          float noise(vec2 p) {
              return sin(p.x * 5.0 + time * 0.5 + audioMid * 2.0) * cos(p.y * 5.0 + time * 0.3 + audioTreble * 2.0);
          }

          void main() {
              vUv = uv;
              vec3 pos = position;

              // Displacement based on noise and bass
              float noiseVal = noise(uv * 3.0);
              float displacement = noiseVal * 30.0 * effectIntensity; // Base wave
              displacement += pow(audioBass, 2.0) * 100.0 * effectIntensity * sin(uv.x * 10.0 + time); // Bass pulse

              vDisplacement = abs(displacement); // Pass absolute displacement

              pos.z += displacement;

              gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
          }
      `,
      fragmentShader: `
          uniform float time;
          uniform float audioBass; // Use bass for pulsing intensity
          uniform float effectIntensity;
          uniform float lineWidth;
          uniform float glowPower;
          uniform vec3 gridColor;

          varying vec2 vUv;
          varying float vDisplacement; // Use displacement for color variation

          void main() {
              // Calculate distance to the nearest grid line in both x and y
              vec2 gridPos = fract(vUv * 20.0 * effectIntensity); // Control grid density with intensity
              vec2 distToLine = min(gridPos, 1.0 - gridPos);
              float dist = min(distToLine.x, distToLine.y);

              // Calculate grid line intensity with glow
              float halfLineWidth = lineWidth / 2.0;
              // Sharper line, intense glow falloff
              float lineIntensity = smoothstep(halfLineWidth + 0.05, halfLineWidth - 0.05, dist);
              float glow = pow(smoothstep(halfLineWidth + 0.2, halfLineWidth, dist), glowPower);

              // Combine line and glow, modulate with bass pulse
              float totalIntensity = (lineIntensity * 0.8 + glow * 0.5) * (0.5 + audioBass * 1.5);

              // Color variation based on displacement
              vec3 color = mix(gridColor, vec3(1.0, 0.0, 1.0), smoothstep(0.0, 50.0, vDisplacement)); // Cyan to Magenta

              gl_FragColor = vec4(color * totalIntensity, totalIntensity); // Use intensity for alpha for additive blending
          }
      `,
      transparent: true,
      blending: THREE.AdditiveBlending, // Glow effect works well with additive
      depthWrite: false,
      side: THREE.DoubleSide // See grid from below if camera moves
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'NeonGridEffect';
  mesh.rotation.x = -Math.PI / 2.5; // Tilt the grid for perspective
  mesh.position.y = -100; // Lower the grid slightly
  mesh.userData.baseEffectIntensity = 1.0;
  scene.add(mesh);
  visualElements.push(mesh);

   // Custom update functions
  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = 0.0;
      mat.uniforms.audioMid.value = 0.0;
      mat.uniforms.audioTreble.value = 0.0;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = bassAvg;
      mat.uniforms.audioMid.value = midAvg;
      mat.uniforms.audioTreble.value = trebleAvg;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
      this.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.1; // Controls grid density, wave amplitude
      this.material.uniforms.lineWidth.value = 0.02 + intensityLevel * 0.005; // Thicker lines with intensity
      this.material.uniforms.glowPower.value = 2.0 + intensityLevel * 0.3; // More intense glow
  }.bind(mesh);
}

function createStarfieldWarpEffect() {
  // Fullscreen Quad Geometry
  const geometry = new THREE.PlaneBufferGeometry(2, 2);

  // Shader Material
  const material = new THREE.ShaderMaterial({
      uniforms: {
          uTime: { value: 0.0 },
          uResolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
          uAudioBass: { value: 0.0 },
          uAudioMid: { value: 0.0 },
          uAudioTreble: { value: 0.0 },
          uEffectIntensity: { value: 1.0 },
          uSeed: { value: Math.random() * 100.0 },
          // Visual Controls - Tuned for Molten Flow/Glitch Core
          uColorCore1: { value: new THREE.Color(0x2020ff) },    // Blue core
          uColorCore2: { value: new THREE.Color(0xff2020) },    // Red core
          uColorCoreMix: { value: 0.6 },                       // Mix factor for core colors
          uColorFlow1: { value: new THREE.Color(0x005020) },   // Dark Green flow base
          uColorFlow2: { value: new THREE.Color(0x00ff80) },   // Bright Green flow highlight
          uColorFlow3: { value: new THREE.Color(0xff4040) },   // Red flow highlight
          uColorFlow4: { value: new THREE.Color(0x00d0ff) },   // Cyan flow highlight
          uFlowSpeed: { value: 0.2 },         // Base speed of outer flow
          uFlowNoiseScale: { value: 1.5 },     // Scale of outer flow noise pattern
          uCoreWidth: { value: 0.15 },        // Width of the central glitchy band (relative to screen width)
          uCoreNoiseScaleX: { value: 5.0 },    // Horizontal noise scale in core
          uCoreNoiseScaleY: { value: 45.0 },   // Vertical noise scale in core (creates streaks)
          uCoreJaggedness: { value: 0.8 },     // Controls the sharpness/contrast of core noise
          uGlowIntensity: { value: 1.5 },       // Overall glow/brightness factor
          // CORRECTED: Added uNoiseAmount here
          uNoiseAmount: { value: 0.03 }         // Final static/noise overlay intensity 
      },
      vertexShader: `
          varying vec2 vUv;
          void main() {
              vUv = uv;
              gl_Position = vec4(position, 1.0);
          }
      `,
      fragmentShader: `
          precision highp float;
          uniform float uTime;
          uniform vec2 uResolution;
          uniform float uAudioBass;
          uniform float uAudioMid;
          uniform float uAudioTreble;
          uniform float uEffectIntensity;
          uniform float uSeed;
          // Visual Uniforms
          uniform vec3 uColorCore1;
          uniform vec3 uColorCore2;
          uniform float uColorCoreMix;
          uniform vec3 uColorFlow1;
          uniform vec3 uColorFlow2;
          uniform vec3 uColorFlow3;
          uniform vec3 uColorFlow4;
          uniform float uFlowSpeed;
          uniform float uFlowNoiseScale;
          uniform float uCoreWidth;
          uniform float uCoreNoiseScaleX;
          uniform float uCoreNoiseScaleY;
          uniform float uCoreJaggedness;
          uniform float uGlowIntensity;
          // CORRECTED: Added uNoiseAmount declaration
          uniform float uNoiseAmount;

          varying vec2 vUv;

          // --- Noise Functions (hash, noise, fbm) ---
           float hash(vec2 p) { return fract(sin(dot(p + uSeed, vec2(127.1, 311.7))) * 43758.5453123); }
           float noise(vec2 p) {
               vec2 i = floor(p); vec2 f = fract(p); f = f*f*(3.0-2.0*f);
               return mix(mix(hash(i + vec2(0.,0.)), hash(i + vec2(1.,0.)),f.x),
                          mix(hash(i + vec2(0.,1.)), hash(i + vec2(1.,1.)),f.x),f.y);
           }
           float fbm(vec2 p, int octaves) {
               float v = 0.0; float a = 0.5;
               mat2 m = mat2(cos(0.5), -sin(0.5), sin(0.5), cos(0.5));
               for (int i = 0; i < octaves; ++i) { v += a * noise(p); p = m * p * 2.0; a *= 0.5; }
               return v;
           }
          // --- End Noise ---

           // HSV to RGB (useful for color cycling if needed later)
           vec3 hsv2rgb(vec3 c) {
               vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
               vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
               return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
           }


          void main() {
              vec2 uv = vUv;
              float aspect = uResolution.x / uResolution.y;
              vec2 centeredUv = (uv - 0.5) * vec2(aspect, 1.0); // Centered, aspect-corrected

              // --- Dynamic Parameters ---
              float timeScaled = uTime * (1.0 + uAudioMid * 0.3);
              float coreNoiseSpeed = 1.5 + uAudioMid * 2.0;
              float flowSpeed = uFlowSpeed * (1.0 + uAudioMid * 1.0) * uEffectIntensity;
              float flowNoiseScale = uFlowNoiseScale * (1.0 + uAudioMid * 0.4) * uEffectIntensity;
              float coreJaggedness = uCoreJaggedness * (1.0 + uAudioTreble * 1.5); // Treble makes core sharper
              float overallGlow = uGlowIntensity * (1.0 + uAudioBass * 1.5); // Bass boosts overall glow

              // --- Central Core Mask ---
              // Smooth mask based on horizontal distance from center
              float coreMask = 1.0 - smoothstep(uCoreWidth * 0.45, uCoreWidth * 0.55, abs(uv.x - 0.5));

              // --- Generate Core Pattern ---
              vec3 coreColor = vec3(0.0);
              if (coreMask > 0.01) {
                  // High-frequency, vertically biased noise
                  float coreNoiseX = uv.x * uCoreNoiseScaleX + timeScaled * 0.1;
                  float coreNoiseY = uv.y * uCoreNoiseScaleY + timeScaled * coreNoiseSpeed;
                  float coreNoiseVal = fbm(vec2(coreNoiseX, coreNoiseY), 6); // Detailed noise

                  // Sharpen the noise based on jaggedness factor
                  coreNoiseVal = pow(coreNoiseVal * 1.2, coreJaggedness);

                  // Mix core colors based on noise and audio
                  float coreMix = uColorCoreMix + (noise(vec2(coreNoiseX * 0.5, coreNoiseY * 0.1)) - 0.5) * 0.4;
                  coreMix = mix(coreMix, hash(uv + uTime * 5.0), uAudioTreble * 0.3); // Treble adds color noise
                  vec3 baseCoreColor = mix(uColorCore1, uColorCore2, clamp(coreMix, 0.0, 1.0));

                  // Intensity based on noise value, boosted by bass
                  float coreIntensity = smoothstep(0.1, 0.6, coreNoiseVal) * (1.0 + uAudioBass * 1.5);
                  coreColor = baseCoreColor * coreIntensity;
              }


              // --- Generate Outer Flow Pattern ---
              vec3 flowColor = vec3(0.0);
              if (coreMask < 0.99) { // Calculate only outside the core full influence
                  // UV manipulation for flow - use time and audio mid
                  vec2 flowUv = uv * flowNoiseScale;
                  flowUv += vec2(timeScaled * flowSpeed, sin(uv.x * 5.0 + timeScaled * 0.1)); // Horizontal flow + sine warp

                  // Multiple layers of noise for complexity
                  float flowNoise1 = fbm(flowUv + vec2(10.0, 0.0), 5);
                  float flowNoise2 = fbm(flowUv * 0.8 - vec2(0.0, timeScaled * 0.3), 4);

                  // Combine noise layers
                  float combinedNoise = flowNoise1 * 0.6 + flowNoise2 * 0.4;
                  combinedNoise = pow(combinedNoise, 1.8); // Increase contrast

                  // Color mapping for flow - blend multiple colors based on noise
                  vec3 colorA = mix(uColorFlow1, uColorFlow2, smoothstep(0.2, 0.5, combinedNoise)); // Dark to bright green
                  vec3 colorB = mix(uColorFlow3, uColorFlow4, smoothstep(0.4, 0.7, combinedNoise)); // Red to cyan highlights
                  flowColor = mix(colorA, colorB, smoothstep(0.5, 0.8, combinedNoise)); // Blend the two mixes

                  // Add sheen/highlight based on noise gradient approximation (using noise itself)
                  float sheen = pow(max(0.0, combinedNoise - 0.4), 3.0);
                  flowColor += vec3(0.8, 1.0, 0.9) * sheen * (1.0 + uAudioBass * 1.0) * 1.5 * uEffectIntensity; // Bass boosts sheen
              }


              // --- Combine Core and Flow ---
              vec3 finalColor = mix(flowColor, coreColor, coreMask);

              // --- Apply Overall Glow ---
              finalColor *= overallGlow;

              // --- Final Noise Overlay ---
              // CORRECTED: Using declared uNoiseAmount
              finalColor += (hash(vUv * 400.0 + uTime * 10.0) - 0.5) * uNoiseAmount * (1.0 + uAudioTreble * 0.5); 

              gl_FragColor = vec4(clamp(finalColor, 0.0, 1.0), 1.0); // Clamp final result
          }
      `,
      depthTest: false,
      depthWrite: false,
      transparent: false
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'StarfieldWarpEffect'; // Apply to this effect slot
  mesh.userData.isFeedbackEffect = false; // Not a feedback effect

  // Store base parameters for intensity adjustments
  mesh.userData.baseEffectIntensity = 1.0;
  mesh.userData.baseFlowSpeed = 0.2;
  mesh.userData.baseFlowNoiseScale = 1.5;
  mesh.userData.baseCoreWidth = 0.15;
  mesh.userData.baseCoreNoiseScaleY = 45.0;
  mesh.userData.baseCoreJaggedness = 0.8;
  mesh.userData.baseGlowIntensity = 1.5;
  // CORRECTED: Added baseNoiseAmount here
  mesh.userData.baseNoiseAmount = 0.03; 

  scene.add(mesh);
  visualElements.push(mesh);

  // --- Custom JavaScript Functions ---

  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.uTime.value = time;
      mat.uniforms.uAudioBass.value = 0.0;
      mat.uniforms.uAudioMid.value = 0.0;
      mat.uniforms.uAudioTreble.value = 0.0;
      mat.uniforms.uEffectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.uResolution.value.set(window.innerWidth, window.innerHeight);

      // Apply base params
      mat.uniforms.uFlowSpeed.value = this.userData.baseFlowSpeed || 0.2;
      mat.uniforms.uFlowNoiseScale.value = this.userData.baseFlowNoiseScale || 1.5;
      mat.uniforms.uCoreWidth.value = this.userData.baseCoreWidth || 0.15;
      mat.uniforms.uCoreNoiseScaleY.value = this.userData.baseCoreNoiseScaleY || 45.0;
      mat.uniforms.uCoreJaggedness.value = this.userData.baseCoreJaggedness || 0.8;
      mat.uniforms.uGlowIntensity.value = this.userData.baseGlowIntensity || 1.5;
      // CORRECTED: Apply baseNoiseAmount
      mat.uniforms.uNoiseAmount.value = this.userData.baseNoiseAmount || 0.03; 
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;

      // Update core uniforms
      mat.uniforms.uTime.value = time;
      mat.uniforms.uResolution.value.set(window.innerWidth, window.innerHeight);
      mat.uniforms.uEffectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.uAudioBass.value = bassAvg;
      mat.uniforms.uAudioMid.value = midAvg;
      mat.uniforms.uAudioTreble.value = trebleAvg;

      // Apply base params
      mat.uniforms.uFlowSpeed.value = this.userData.baseFlowSpeed || 0.2;
      mat.uniforms.uFlowNoiseScale.value = this.userData.baseFlowNoiseScale || 1.5;
      mat.uniforms.uCoreWidth.value = this.userData.baseCoreWidth || 0.15;
      mat.uniforms.uCoreNoiseScaleY.value = this.userData.baseCoreNoiseScaleY || 45.0;
      mat.uniforms.uCoreJaggedness.value = this.userData.baseCoreJaggedness || 0.8;
      mat.uniforms.uGlowIntensity.value = this.userData.baseGlowIntensity || 1.5;
      // CORRECTED: Apply baseNoiseAmount
      mat.uniforms.uNoiseAmount.value = this.userData.baseNoiseAmount || 0.03; 
      
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
       // Map intensityLevel (1-9) to parameters
      this.userData.baseEffectIntensity = 0.7 + intensityLevel * 0.13; // 0.83 to 1.87

      // Adjust parameters affecting complexity and reactivity
      this.userData.baseFlowSpeed = 0.1 + intensityLevel * 0.03;        // 0.13 to 0.37
      this.userData.baseFlowNoiseScale = 1.0 + intensityLevel * 0.15;   // 1.15 to 2.35
      this.userData.baseCoreWidth = 0.08 + intensityLevel * 0.015;      // 0.095 to 0.215
      this.userData.baseCoreNoiseScaleY = 30.0 + intensityLevel * 4.0;   // 34.0 to 66.0
      this.userData.baseCoreJaggedness = 0.5 + intensityLevel * 0.1;      // 0.6 to 1.4
      this.userData.baseGlowIntensity = 1.0 + intensityLevel * 0.15;    // 1.15 to 2.35
      // CORRECTED: Adjust baseNoiseAmount
      this.userData.baseNoiseAmount = 0.01 + intensityLevel * 0.003;      // 0.013 to 0.037


       // Apply immediately
       if(this.material && this.material.uniforms) {
           this.material.uniforms.uEffectIntensity.value = this.userData.baseEffectIntensity;
           this.material.uniforms.uFlowSpeed.value = this.userData.baseFlowSpeed;
           this.material.uniforms.uFlowNoiseScale.value = this.userData.baseFlowNoiseScale;
           this.material.uniforms.uCoreWidth.value = this.userData.baseCoreWidth;
           this.material.uniforms.uCoreNoiseScaleY.value = this.userData.baseCoreNoiseScaleY;
           this.material.uniforms.uCoreJaggedness.value = this.userData.baseCoreJaggedness;
           this.material.uniforms.uGlowIntensity.value = this.userData.baseGlowIntensity;
           // CORRECTED: Apply uNoiseAmount
           this.material.uniforms.uNoiseAmount.value = this.userData.baseNoiseAmount; 
       }
  }.bind(mesh);
} // End createStarfieldWarpEffect

function createLiquidCrystalEffect() {
  const geometry = new THREE.PlaneBufferGeometry(2, 2); // Fullscreen quad
  const material = new THREE.ShaderMaterial({
      uniforms: {
          time: { value: 0.0 },
          resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
          audioBass: { value: 0.0 },
          audioMid: { value: 0.0 },
          audioTreble: { value: 0.0 },
          effectIntensity: { value: 1.0 },
          uSeed: { value: Math.random() * 100.0 },
          uColor1: { value: new THREE.Color(0xff4081) }, // Reddish-pink base
          uColor2: { value: new THREE.Color(0xcdf0ff) }, // Luminous blue-white glow (slightly less harsh blue)
          uScanlineDensity: { value: window.innerHeight * 1.5 }, // Adjust based on screen height
          uScanlineIntensity: { value: 0.1 }, // Base intensity
          uGlowPower: { value: 4.0 }       // Controls the falloff of the glow
      },
      vertexShader: `
          varying vec2 vUv;
          void main() {
              vUv = uv;
              gl_Position = vec4(position, 1.0);
          }
      `,
      fragmentShader: `
          precision highp float;
          uniform float time;
          uniform vec2 resolution;
          uniform float audioBass;
          uniform float audioMid;
          uniform float audioTreble;
          uniform float effectIntensity;
          uniform float uSeed;
          uniform vec3 uColor1; // Base color
          uniform vec3 uColor2; // Luminous color
          uniform float uScanlineDensity;
          uniform float uScanlineIntensity; // Modulated by treble in JS
          uniform float uGlowPower;

          varying vec2 vUv;

          // Noise functions (hash, noise, fbm) - Assuming they are defined correctly elsewhere or reuse from previous
          float hash(vec2 p) { return fract(sin(dot(p + uSeed, vec2(127.1, 311.7))) * 43758.5453123); }
          float noise(vec2 p) {
              vec2 i = floor(p); vec2 f = fract(p); f = f*f*(3.0-2.0*f);
              return mix(mix(hash(i + vec2(0.,0.)), hash(i + vec2(1.,0.)),f.x),
                         mix(hash(i + vec2(0.,1.)), hash(i + vec2(1.,1.)),f.x),f.y);
          }
          float fbm(vec2 p, int octaves) {
              float v = 0.0; float a = 0.5;
              mat2 m = mat2(cos(0.5), -sin(0.5), sin(0.5), cos(0.5));
              for (int i = 0; i < octaves; ++i) { v += a * noise(p); p = m * p * 2.0; a *= 0.5; }
              return v;
          }

          void main() {
              vec2 uv = vUv;

              // --- Base Wave Parameters ---
              float waveSpeed = 0.3 + audioMid * 0.8 * effectIntensity;
              float waveFreq = 4.0 + audioMid * 8.0 * effectIntensity; // Mids control base frequency
              // Bass controls base amplitude significantly
              float waveAmplitude = 0.15 + pow(audioBass, 1.5) * 0.3 * effectIntensity; 

              // --- Wave Distortion (Analog Feel) ---
              float distortFreq = 2.0 * effectIntensity;
              float distortSpeed = 0.15 * effectIntensity;
              float distortAmount = 0.05 + audioMid * 0.1 * effectIntensity; // Mids add more warp
              // Use FBM for more organic distortion
              float distortion = fbm(uv * distortFreq + vec2(time * distortSpeed, 0.0), 3) * distortAmount;

              // --- Combined Wave Calculation ---
              float yPos = uv.y + distortion; // Apply distortion to coordinate
              float mainWave = sin(yPos * waveFreq + time * waveSpeed) * waveAmplitude;

              // --- Color Banding ---
              // Make bands thicker and softer
              float bandCenter = 0.0;
              float bandWidth = 0.1 + audioBass * 0.15; // Bass widens the luminous band
              float edgeSoftness = 0.05 + (1.0 - effectIntensity) * 0.1; // More intensity = sharper edges

              float bandValue = mainWave;
              float luminousMix = smoothstep(bandCenter - bandWidth - edgeSoftness, bandCenter - bandWidth, bandValue) -
                                  smoothstep(bandCenter + bandWidth, bandCenter + bandWidth + edgeSoftness, bandValue);
              luminousMix = clamp(luminousMix, 0.0, 1.0);

              // --- Color Calculation ---
              vec3 baseColor = mix(uColor1, uColor2, luminousMix);

              // --- Glow ---
              // Bass boosts glow intensity significantly
              float glowAmount = pow(luminousMix, uGlowPower) * (2.0 + audioBass * 5.0) * effectIntensity;
              // Add glow coloritively (can also try additively)
              vec3 glowColor = uColor2 * glowAmount;

              // Combine base color and glow
              vec3 colorWithGlow = baseColor + glowColor;

              // --- Scanlines ---
              // Create horizontal lines, intensity modulated by treble
              float scanline = mod(vUv.y * uScanlineDensity, 2.0); // Creates lines with thickness
              float scanlineFactor = smoothstep(0.9, 1.0, scanline) * uScanlineIntensity;
              scanlineFactor = mix(scanlineFactor, scanlineFactor * hash(uv + vec2(time * 5.0, 0.0)), audioTreble * 0.5); // Treble adds flicker

              // Apply scanlines by darkening the color
              vec3 finalColor = colorWithGlow * (1.0 - scanlineFactor);

              // --- Optional: Treble Noise/Static ---
              float staticNoise = hash(uv * 100.0 + time * 10.0) - 0.5; // High frequency noise
              finalColor += staticNoise * audioTreble * 0.1 * effectIntensity; // Add subtle treble static

              gl_FragColor = vec4(clamp(finalColor, 0.0, 1.5), 1.0); // Allow slightly overbright from glow, clamp later if needed
          }
      `,
      depthTest: false,
      depthWrite: false
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'LiquidCrystalEffect';
  mesh.userData.baseEffectIntensity = 1.0;
  // Base parameters for intensity adjustments
  mesh.userData.baseGlowPower = 4.0;
  mesh.userData.baseScanlineIntensity = 0.1;
  mesh.userData.currentScanlineIntensity = 0.1; // For decay
  mesh.userData.scanlineDecay = 0.92;

  scene.add(mesh);
  visualElements.push(mesh);

  // --- Custom JavaScript Functions for this Effect ---

  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = 0.0;
      mat.uniforms.audioMid.value = 0.0;
      mat.uniforms.audioTreble.value = 0.0;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
      mat.uniforms.uScanlineDensity.value = window.innerHeight * 1.5; // Keep density relative to height
      mat.uniforms.uGlowPower.value = this.userData.baseGlowPower || 4.0;

      // Decay scanline intensity when idle
      this.userData.currentScanlineIntensity *= this.userData.scanlineDecay;
      this.userData.currentScanlineIntensity = Math.max(this.userData.baseScanlineIntensity * 0.5, this.userData.currentScanlineIntensity - 0.005); // Ensure minimum visibility and decay
      mat.uniforms.uScanlineIntensity.value = this.userData.currentScanlineIntensity;

  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = bassAvg;
      mat.uniforms.audioMid.value = midAvg;
      mat.uniforms.audioTreble.value = trebleAvg;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
      mat.uniforms.uScanlineDensity.value = window.innerHeight * 1.5;
      mat.uniforms.uGlowPower.value = this.userData.baseGlowPower || 4.0;

      // Update Scanline Intensity based on Treble & Decay
      this.userData.currentScanlineIntensity = Math.max(this.userData.currentScanlineIntensity, this.userData.baseScanlineIntensity + trebleAvg * 0.4); // Treble boosts intensity
      this.userData.currentScanlineIntensity *= this.userData.scanlineDecay; // Decay
      this.userData.currentScanlineIntensity = Math.max(this.userData.baseScanlineIntensity * 0.5, this.userData.currentScanlineIntensity - 0.005); // Ensure minimum visibility and decay
      mat.uniforms.uScanlineIntensity.value = this.userData.currentScanlineIntensity;

  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
      // Map intensityLevel (1-9) to overall effect strength
      this.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.15; // Range: 0.65 to 1.85

      // Adjust other base parameters
      this.userData.baseGlowPower = 3.0 + intensityLevel * 0.3; // Range: 3.3 to 5.7 (higher = sharper falloff)
      this.userData.baseScanlineIntensity = 0.05 + intensityLevel * 0.02; // Range: 0.07 to 0.23

      // Optional: Adjust decay?
      // this.userData.scanlineDecay = 0.90 + intensityLevel * 0.005; // Range: 0.905 to 0.945 (slower decay at higher intensity)

      // Apply the changes immediately if possible (though they'll be picked up next frame anyway)
      if(this.material) {
         this.material.uniforms.effectIntensity.value = this.userData.baseEffectIntensity;
         this.material.uniforms.uGlowPower.value = this.userData.baseGlowPower;
         // Scanline intensity is handled by the decay logic in animate loops
      }
  }.bind(mesh);
}

function createAbstractFlowEffect() {
  const geometry = new THREE.PlaneBufferGeometry(2, 2); // Fullscreen quad
  const material = new THREE.ShaderMaterial({
      uniforms: {
          time: { value: 0.0 },
          audioBass: { value: 0.0 }, // Bass influences distortion/turbulence
          audioMid: { value: 0.0 },  // Mid influences flow speed
          audioTreble: { value: 0.0 },// Treble influences color complexity/shifting
          effectIntensity: { value: 1.0 },
          resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
          uSeed: { value: Math.random() * 100.0 } // Random seed for variation
      },
      vertexShader: `
          varying vec2 vUv;
          void main() {
              vUv = uv;
              gl_Position = vec4(position, 1.0);
          }
      `,
      fragmentShader: `
          precision highp float;
          uniform float time;
          uniform float audioBass;
          uniform float audioMid;
          uniform float audioTreble;
          uniform float effectIntensity;
          uniform vec2 resolution;
          uniform float uSeed;
          varying vec2 vUv;

          // Noise functions (e.g., FBM - Fractional Brownian Motion)
          // Using simple hash noise for brevity, replace with FBM for better quality
           float hash(vec2 p) { return fract(sin(dot(p+uSeed, vec2(127.1, 311.7))) * 43758.5453); }

            float noise(vec2 p) {
                vec2 i = floor(p);
                vec2 f = fract(p);
                f = f*f*(3.0-2.0*f); // smoothstep
                float a = hash(i + vec2(0.0,0.0));
                float b = hash(i + vec2(1.0,0.0));
                float c = hash(i + vec2(0.0,1.0));
                float d = hash(i + vec2(1.0,1.0));
                return mix(mix(a, b, f.x), mix(c, d, f.x), f.y);
            }

            float fbm(vec2 p, int octaves) {
                float total = 0.0;
                float amplitude = 0.5;
                for (int i = 0; i < octaves; ++i) {
                    total += amplitude * noise(p);
                    p *= 2.0;
                    amplitude *= 0.5;
                }
                return total;
            }

           // HSV to RGB
            vec3 hsv2rgb(vec3 c) {
                vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
                vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
                return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
            }


          void main() {
              vec2 uv = vUv;
              float aspectRatio = resolution.x / resolution.y;
              vec2 centeredUv = (uv - 0.5) * vec2(aspectRatio, 1.0); // Correct for aspect ratio

              // --- Flow / Distortion ---
              float flowSpeed = 0.1 + audioMid * 0.3 * effectIntensity;
              float turbulence = pow(audioBass, 1.5) * 0.5 * effectIntensity;

              // Create a noise-based flow field
              vec2 flowField = vec2(
                  fbm(centeredUv * 2.0 + time * flowSpeed * 0.5, 3) - 0.5,
                  fbm(centeredUv * 2.0 + time * flowSpeed * 0.7 + 5.0, 3) - 0.5
              ) * 2.0; // Noise ranges roughly -1 to 1

              // Add turbulence based on bass
              flowField += (fbm(centeredUv * 5.0 + time * 0.3, 4) - 0.5) * turbulence;

              // Apply flow field to UVs iteratively (more iterations = more complex flow)
              vec2 flowedUv = centeredUv;
              for(int i=0; i < 3; ++i) { // 3 iterations
                   flowedUv += flowField * 0.05; // Adjust displacement scale
                   // Recalculate flow field at new position for more complex interaction
                    flowField = vec2(
                      fbm(flowedUv * 2.0 + time * flowSpeed * 0.5 + float(i)*0.1, 3) - 0.5,
                      fbm(flowedUv * 2.0 + time * flowSpeed * 0.7 + 5.0 + float(i)*0.1, 3) - 0.5
                     ) * 2.0;
                    flowField += (fbm(flowedUv * 5.0 + time * 0.3, 4) - 0.5) * turbulence;
              }


              // --- Color Calculation ---
              // Use the final flowed UVs to sample noise for color
              float colorNoise = fbm(flowedUv * 1.5 + time * 0.05, 5); // Base color noise

              // Color shifting based on treble and time
              float hue = fract(colorNoise + time * 0.02 + audioTreble * 0.2 * effectIntensity);
              float saturation = 0.6 + fbm(flowedUv * 3.0 - time * 0.1, 2) * 0.4; // Vary saturation
              float value = 0.5 + fbm(flowedUv * 2.5 + time * 0.15, 3) * 0.5; // Vary brightness

              // Add audio reactivity to brightness/value
              value *= (0.8 + (audioBass + audioMid + audioTreble) * 0.5 * effectIntensity);

              vec3 color = hsv2rgb(vec3(hue, clamp(saturation, 0.5, 1.0), clamp(value, 0.3, 1.0)));

              // Optional: Add some edge darkening/vignette
              float vignette = 1.0 - smoothstep(0.7, 1.5, length(centeredUv));
              color *= vignette;

              gl_FragColor = vec4(clamp(color, 0.0, 1.0), 1.0);
          }
      `,
      depthTest: false,
      depthWrite: false
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'AbstractFlowEffect';
  mesh.userData.baseEffectIntensity = 1.0;
  scene.add(mesh);
  visualElements.push(mesh);

  // Custom update functions
  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = 0.0;
      mat.uniforms.audioMid.value = 0.0;
      mat.uniforms.audioTreble.value = 0.0;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = bassAvg;
      mat.uniforms.audioMid.value = midAvg;
      mat.uniforms.audioTreble.value = trebleAvg;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
      // Controls flow speed, turbulence amount, color complexity
      this.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.15;
  }.bind(mesh);
}

function createGeometricPulseEffect() {
  // Create a group to hold multiple geometric objects
  const group = new THREE.Group();
  group.name = 'GeometricPulseEffect';

  // Add more 80s-style geometries
  const geometryTypes = [
      new THREE.BoxBufferGeometry(50, 50, 50),
      new THREE.SphereBufferGeometry(30, 16, 16),
      new THREE.TorusBufferGeometry(40, 10, 8, 20),
      new THREE.ConeBufferGeometry(30, 60, 16),
      new THREE.TorusKnotBufferGeometry(35, 8, 48, 6, 2, 3), // Added TorusKnot
      new THREE.OctahedronBufferGeometry(40, 0), // Added Octahedron
  ];

  const numObjects = 30; // Increased object count slightly
  const baseColors = [0xff00ff, 0x00ffff, 0xffff00, 0xff8800, 0x00ff00, 0xff4040]; // Added Green, Red

  for (let i = 0; i < numObjects; i++) {
      const geoIndex = i % geometryTypes.length;
      const geo = geometryTypes[geoIndex];
      const useWireframe = Math.random() < 0.15; // Randomly make some wireframe

      const material = new THREE.MeshStandardMaterial({
          color: baseColors[i % baseColors.length],
          metalness: 0.4, // Slightly more metallic
          roughness: 0.5,
          wireframe: useWireframe,
          emissive: 0x000000, // Start with no emission
          // side: THREE.DoubleSide // Ensure wireframes render correctly if needed
      });

      const mesh = new THREE.Mesh(geo, material);

      // --- Initial Position & State ---
      const initialPos = new THREE.Vector3(
          (Math.random() - 0.5) * 800,
          (Math.random() - 0.5) * 600,
          (Math.random() - 0.5) * 800
      );
      mesh.position.copy(initialPos);

      mesh.rotation.set(
          Math.random() * Math.PI * 2,
          Math.random() * Math.PI * 2,
          Math.random() * Math.PI * 2
      );

      // --- Store UserData ---
      mesh.userData = {
          initialPosition: initialPos.clone(),
          initialScale: 0.4 + Math.random() * 0.8, // Slightly smaller base size range
          rotationSpeed: new THREE.Vector3(
              (Math.random() - 0.5) * 0.025, // Slightly faster base rotation
              (Math.random() - 0.5) * 0.025,
              (Math.random() - 0.5) * 0.025
          ),
          baseColor: new THREE.Color(baseColors[i % baseColors.length]),
          phaseOffset: Math.random() * Math.PI * 2,
          velocity: new THREE.Vector3(), // Initialize velocity
          // Parameters for movement types
          orbitRadius: 30 + Math.random() * 50,
          orbitSpeed: 0.5 + Math.random() * 1.0,
          orbitAxis: new THREE.Vector3(Math.random() - 0.5, Math.random() - 0.5, Math.random() - 0.5).normalize()
      };

      mesh.scale.setScalar(mesh.userData.initialScale);
      group.add(mesh);

       // --- Optional Outlines --- (Can impact performance)
       // if (!useWireframe && Math.random() < 0.2) { // Add outlines to some non-wireframe shapes
       //     const edgesGeo = new THREE.EdgesGeometry(geo);
       //     const edgesMat = new THREE.LineBasicMaterial({ color: 0xffffff, linewidth: 2 });
       //     const wireframe = new THREE.LineSegments(edgesGeo, edgesMat);
       //     mesh.add(wireframe); // Add outline as child
       // }
  }

  // --- Lights --- (Ensure they exist)
  if (!scene.getObjectByName("PulseAmbientLight")) {
      const ambientLight = new THREE.AmbientLight(0x505050); // Slightly brighter ambient
      ambientLight.name = "PulseAmbientLight";
      scene.add(ambientLight);
  }
  if (!scene.getObjectByName("PulseDirectionalLight")) {
      const directionalLight = new THREE.DirectionalLight(0xffffff, 1.0); // Brighter directional
      directionalLight.name = "PulseDirectionalLight";
      directionalLight.position.set(0.8, 1, 0.5);
      scene.add(directionalLight);
  }

  // --- Group UserData ---
  group.userData.baseEffectIntensity = 1.0;
  group.userData.velocityDamping = 0.96;     // Damping factor for velocity
  group.userData.returnForce = 0.005;      // Strength pulling shapes back to origin
  group.userData.bassPushStrength = 3.0;    // Force multiplier for bass push
  group.userData.midOrbitStrength = 0.8;    // Influence of mids on orbit speed/force
  group.userData.trebleZapStrength = 15.0;  // Velocity magnitude for treble zaps

  scene.add(group);
  visualElements.push(group);

   // --- Custom JavaScript Functions (Applied to the GROUP) ---

   group.userData.customAnimateInitial = function() {
      const intensity = this.userData.baseEffectIntensity || 1.0;
      const damping = this.userData.velocityDamping || 0.96;
      const returnForce = this.userData.returnForce || 0.005;

      this.children.forEach(mesh => {
          if (mesh.isMesh && mesh.userData) {
              // --- Rotation ---
              mesh.rotation.x += mesh.userData.rotationSpeed.x * intensity * 0.5;
              mesh.rotation.y += mesh.userData.rotationSpeed.y * intensity * 0.5;
              mesh.rotation.z += mesh.userData.rotationSpeed.z * intensity * 0.5;

              // --- Scale & Color Reset ---
              mesh.scale.lerp(new THREE.Vector3().setScalar(mesh.userData.initialScale), 0.1); // Smoothly return scale
              mesh.material.color.lerp(mesh.userData.baseColor, 0.1); // Smoothly return color
              mesh.material.emissive.lerp(new THREE.Color(0x000000), 0.1); // Fade out emission

              // --- Movement ---
              // Apply damping
              mesh.userData.velocity.multiplyScalar(damping);
              // Apply return force towards initial position
              const directionToHome = mesh.userData.initialPosition.clone().sub(mesh.position);
              const distToHome = directionToHome.length();
              if (distToHome > 1.0) { // Only apply if reasonably far
                 directionToHome.normalize();
                 // Force increases slightly with distance
                 mesh.userData.velocity.addScaledVector(directionToHome, distToHome * returnForce * intensity);
              }
              // Stop velocity if very slow and near home to prevent oscillation
              if (mesh.userData.velocity.lengthSq() < 0.01 && distToHome < 5.0) {
                  mesh.userData.velocity.set(0, 0, 0);
              }

              // Update position
              mesh.position.add(mesh.userData.velocity);
          }
      });
   }.bind(group);

   group.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
       const intensity = this.userData.baseEffectIntensity || 1.0;
       const time = performance.now() * 0.001;
       const damping = this.userData.velocityDamping || 0.96;
       const returnForce = this.userData.returnForce || 0.005;
       const bassPushStrength = this.userData.bassPushStrength || 3.0;
       const midOrbitStrength = this.userData.midOrbitStrength || 0.8;
       const trebleZapStrength = this.userData.trebleZapStrength || 15.0;

       this.children.forEach((mesh, index) => {
           if (mesh.isMesh && mesh.userData) {
               // --- Rotation (more reactive) ---
               const rotSpeedFactor = 1.0 + midAvg * 1.5 * intensity; // Mids have stronger effect
               const trebleRotKick = Math.pow(trebleAvg, 2.5) * 0.1 * intensity; // Sharper treble kick
               mesh.rotation.x += mesh.userData.rotationSpeed.x * rotSpeedFactor + Math.sin(time * 5 + mesh.userData.phaseOffset) * trebleRotKick;
               mesh.rotation.y += mesh.userData.rotationSpeed.y * rotSpeedFactor + Math.cos(time * 5 + mesh.userData.phaseOffset) * trebleRotKick;
               mesh.rotation.z += mesh.userData.rotationSpeed.z * rotSpeedFactor;

               // --- Scale (remains similar) ---
               const scalePulse = Math.pow(bassAvg, 1.8) * 1.2 * intensity;
               const timeBasedVariation = 0.5 + Math.sin(time * 5.0 + mesh.userData.phaseOffset) * 0.5;
               const currentScale = mesh.userData.initialScale * (1.0 + scalePulse * timeBasedVariation);
               mesh.scale.setScalar(Math.max(0.1, currentScale));

               // --- Color/Emissive (remains similar) ---
               const emissivePulse = Math.pow(trebleAvg, 1.8) * intensity;
               mesh.material.color.lerpColors(mesh.userData.baseColor, new THREE.Color(0xffffff), emissivePulse * 0.6);
               mesh.material.emissive.copy(mesh.userData.baseColor).multiplyScalar(emissivePulse * 1.2);

               // --- Velocity / Force Calculation ---
               const currentVelocity = mesh.userData.velocity;

               // 1. Damping
               currentVelocity.multiplyScalar(damping);

               // 2. Return Force (gentle pull towards initial position)
               const directionToHome = mesh.userData.initialPosition.clone().sub(mesh.position);
               const distToHome = directionToHome.length();
               if (distToHome > 1.0) { // Don't apply if already close
                  directionToHome.normalize();
                  currentVelocity.addScaledVector(directionToHome, distToHome * returnForce * intensity);
               }

               // 3. Bass Push Force (pushes away from origin)
               const pushForce = mesh.position.clone().normalize();
                if (pushForce.lengthSq() < 0.001) { // Handle case where object is at origin
                   pushForce.set(Math.random() - 0.5, Math.random() - 0.5, Math.random() - 0.5).normalize();
               }
               pushForce.multiplyScalar(Math.pow(bassAvg, 2.0) * bassPushStrength * intensity);
               currentVelocity.add(pushForce);

               // 4. Mid Orbit/Jitter Force (around initial position)
               const orbitSpeed = time * mesh.userData.orbitSpeed * (1.0 + midAvg * 1.5) * intensity;
               const orbitRadius = mesh.userData.orbitRadius * (1.0 + midAvg * 0.5);
               // Calculate target orbit point relative to initial position
               const orbitOffset = new THREE.Vector3(
                  Math.cos(orbitSpeed + mesh.userData.phaseOffset) * orbitRadius,
                  Math.sin(orbitSpeed + mesh.userData.phaseOffset) * orbitRadius,
                  Math.cos(orbitSpeed * 1.1 + mesh.userData.phaseOffset * 1.2) * orbitRadius * 0.5 // Add some Z wobble
               );
               // Apply orbit axis rotation if needed (can make complex paths)
               // orbitOffset.applyAxisAngle(mesh.userData.orbitAxis, orbitSpeed * 0.1); // Optional complexity

               const targetOrbitPos = mesh.userData.initialPosition.clone().add(orbitOffset);
               const directionToOrbit = targetOrbitPos.sub(mesh.position);
               // Apply force towards orbit position, stronger with mids
               currentVelocity.addScaledVector(directionToOrbit, midAvg * midOrbitStrength * intensity * 0.1); // Scaled down force

               // 5. Treble Zap Force (sudden random direction change)
               if (trebleAvg > 0.5) { // Trigger on high treble
                   const zapChance = Math.random();
                   if (zapChance < trebleAvg * 0.1) { // Low chance per frame, increases with treble
                       const zapDirection = new THREE.Vector3(Math.random() - 0.5, Math.random() - 0.5, Math.random() - 0.5).normalize();
                       const zapMagnitude = (0.5 + Math.random() * 0.5) * trebleZapStrength * intensity; // Random strength
                       currentVelocity.addScaledVector(zapDirection, zapMagnitude);
                   }
               }

               // Limit max velocity to prevent extreme speeds
               const maxSpeed = 20.0 * intensity;
               if (currentVelocity.lengthSq() > maxSpeed * maxSpeed) {
                   currentVelocity.normalize().multiplyScalar(maxSpeed);
               }

               // Update position
               mesh.position.add(currentVelocity);
           }
       });
   }.bind(group);

   group.userData.customAdjustIntensity = function(intensityLevel) {
       // Map intensityLevel (1-9)
       this.userData.baseEffectIntensity = 0.6 + intensityLevel * 0.16; // Range ~0.76 to 2.04

       // Adjust reaction strengths
       this.userData.bassPushStrength = 1.5 + intensityLevel * 0.3;  // Range 1.8 to 4.2
       this.userData.midOrbitStrength = 0.4 + intensityLevel * 0.1;   // Range 0.5 to 1.3
       this.userData.trebleZapStrength = 8.0 + intensityLevel * 2.0; // Range 10 to 26
       // Adjust damping/return
       this.userData.velocityDamping = 0.97 - intensityLevel * 0.004; // Range ~0.966 to 0.934 (more damping at low intensity)
       this.userData.returnForce = 0.002 + intensityLevel * 0.0005; // Range ~0.0025 to 0.0065

   }.bind(group);
}

function createPixelSortEffect() {
  const geometry = new THREE.PlaneBufferGeometry(2, 2); // Fullscreen quad
  const material = new THREE.ShaderMaterial({
      uniforms: {
          time: { value: 0.0 },
          audioBass: { value: 0.0 }, // Bass for sort threshold
          audioMid: { value: 0.0 },  // Mid for sort distance/direction
          audioTreble: { value: 0.0 },// Treble for random glitches/swaps
          effectIntensity: { value: 1.0 },
          resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
          cameraTexture: { value: null }, // Needs camera or a procedural base
          visualMode: { value: 0.0 } // 0: Procedural, 1: Camera
      },
      vertexShader: `
          varying vec2 vUv;
          void main() {
              vUv = uv;
              gl_Position = vec4(position, 1.0);
          }
      `,
      fragmentShader: `
          precision highp float;
          uniform float time;
          uniform float audioBass;
          uniform float audioMid;
          uniform float audioTreble;
          uniform float effectIntensity;
          uniform vec2 resolution;
          uniform sampler2D cameraTexture;
          uniform float visualMode; // 0 or 1
          varying vec2 vUv;

          // Simple noise
          float rand(vec2 co){ return fract(sin(dot(co ,vec2(12.9898,78.233))) * 43758.5453123); }

          // Luminance calculation
          float luminance(vec3 color) {
              return dot(color, vec3(0.299, 0.587, 0.114));
          }

          void main() {
              // Define character cell size - smaller cells for denser text
              float baseCharSize = 10.0;
              float charSizeScale = 1.0 + (1.0 - effectIntensity) * 2.0; // Higher intensity = smaller, more numerous chars
              vec2 cellSize = vec2(baseCharSize * 0.6, baseCharSize) * charSizeScale; // Fixed aspect ratio
              vec2 charGridRes = floor(resolution / cellSize);

              // --- Grid Distortion --- 
              // Apply audio/time based distortion to the main UVs before cell calculation
              float distortAmount = audioMid * 0.05 * effectIntensity;
              float distortAngle = time * 0.5 + audioMid * 2.0;
              vec2 distortOffset = vec2(sin(vUv.y * 15.0 + distortAngle), cos(vUv.x * 10.0 - distortAngle)) * distortAmount;
              vec2 distortedVuv = vUv + distortOffset;

              // Calculate the UV coordinates for the center of the current character cell
              vec2 cellUv = floor(distortedVuv * charGridRes) / charGridRes + (0.5 / charGridRes);

              // Calculate UV coordinates within the current character cell (0.0 to 1.0)
              vec2 intraCellUv = fract(distortedVuv * charGridRes);

              // Use a time-sliced seed for character changes, influenced by treble
              float charChangeRate = 2.0 + audioTreble * 15.0 * effectIntensity;
              float cellRandSeed = rand(cellUv + floor(time * charChangeRate));

              // --- Procedural Character Shape Generation --- 
              // Generate shapes using sin/cos and the cell seed - looks more like glyphs
              float patternComplexity = 2.0 + floor(cellRandSeed * 5.0); // 2-6 based on seed
              float patternFreq = 5.0 + audioBass * 10.0 * effectIntensity; // Bass increases complexity
              float patternPhase = cellRandSeed * 6.28; // Seed determines phase

              float pat1 = sin(intraCellUv.x * patternFreq * 1.1 + patternPhase) * cos(intraCellUv.y * patternFreq * 0.9 + patternPhase);
              float pat2 = cos(intraCellUv.y * patternFreq * 1.3 - patternPhase * 0.5) * sin(intraCellUv.x * patternFreq * 0.7 - patternPhase * 0.5);
              float combinedPattern = pow(abs(pat1 + pat2), 0.7); // Combine and shape
              
              // Use threshold based on pattern and cell seed
              float charThreshold = 0.3 + cellRandSeed * 0.4; // Threshold varies per cell
              float charPixel = smoothstep(charThreshold - 0.1, charThreshold + 0.1, combinedPattern); // Anti-aliased character shape

              // Add Glitch: Randomly turn off some pixels based on treble
              if (rand(cellUv + fract(time * 5.0)) < audioTreble * 0.1 * effectIntensity) {
                  if (rand(intraCellUv + cellRandSeed) > 0.7) {
                      charPixel = 0.0; // Randomly erase parts
                  }
              }

              // --- Color the character --- 
              // Monochrome color with brightness influenced by cell seed and audio flicker
              float baseBrightness = 0.7 + cellRandSeed * 0.3; // Base brightness varies per char
              float brightnessFlicker = (rand(cellUv + time * 30.0) - 0.5) * 0.4 * audioTreble; // Treble flicker
              float finalBrightness = clamp(baseBrightness + brightnessFlicker, 0.0, 1.0);
              vec3 finalColor = vec3(finalBrightness * charPixel); // Apply shape mask

              // Output the final color
              gl_FragColor = vec4(finalColor, 1.0);
          }
      `,
      depthTest: false,
      depthWrite: false
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'PixelSortEffect';
  mesh.userData.baseEffectIntensity = 1.0;
  mesh.userData.visualMode = 0.0; // Start procedural
  scene.add(mesh);
  visualElements.push(mesh);

  // Custom update functions
  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = 0.0;
      mat.uniforms.audioMid.value = 0.0;
      mat.uniforms.audioTreble.value = 0.0;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
      mat.uniforms.visualMode.value = this.userData.visualMode;
      if (this.userData.visualMode > 0.5 && window.userCameraTexture) {
          mat.uniforms.cameraTexture.value = window.userCameraTexture;
              } else {
          mat.uniforms.cameraTexture.value = null;
      }
  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.time.value = time;
      mat.uniforms.audioBass.value = bassAvg;
      mat.uniforms.audioMid.value = midAvg;
      mat.uniforms.audioTreble.value = trebleAvg;
      mat.uniforms.effectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
      mat.uniforms.visualMode.value = this.userData.visualMode;
       if (this.userData.visualMode > 0.5 && window.userCameraTexture) {
          mat.uniforms.cameraTexture.value = window.userCameraTexture;
      } else {
          mat.uniforms.cameraTexture.value = null;
      }
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
      // Controls sort threshold sensitivity, sort distance, glitch chance
      this.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.2;
  }.bind(mesh);

  // Override visual mode toggling
   mesh.userData.toggleVisualMode = function() {
      this.userData.visualMode = 1.0 - this.userData.visualMode;
      showActionMessage("Pixel Sort Mode: " + (this.userData.visualMode > 0.5 ? "Camera Input" : "Procedural"));
      if (this.material) {
          this.material.uniforms.visualMode.value = this.userData.visualMode;
           if (this.userData.visualMode > 0.5 && window.userCameraTexture) {
               this.material.uniforms.cameraTexture.value = window.userCameraTexture;
                if (!window.isCameraMode) toggleCameraBackground();
           } else {
               this.material.uniforms.cameraTexture.value = null;
               // if (window.isCameraMode && !isAnyEffectUsingCamera()) toggleCameraBackground();
           }
      }
  }.bind(mesh);
}

function createKaleidoTunnelEffect() {
  // Audio Spectrum Texture (Used for core brightness/highlights)
  const audioDataArray = new Float32Array(analyser.frequencyBinCount);
  const audioTexture = new THREE.DataTexture(audioDataArray, analyser.frequencyBinCount, 1, THREE.RedFormat, THREE.FloatType);
  audioTexture.needsUpdate = true;

  // Fullscreen Quad Geometry
  const geometry = new THREE.PlaneBufferGeometry(2, 2);

  // Shader Material
  const material = new THREE.ShaderMaterial({
      uniforms: {
          uTime: { value: 0.0 },
          uResolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
          uAudioTexture: { value: audioTexture }, // Pass audio data
          uAudioBass: { value: 0.0 },
          uAudioMid: { value: 0.0 },
          uAudioTreble: { value: 0.0 },
          uEffectIntensity: { value: 1.0 },
          uSeed: { value: Math.random() * 100.0 },
          // Visual Controls - Tuned for iTunes Look v4
          uColorBg: { value: new THREE.Color(0x00040a) },      // Very dark blue/near black
          uColorWave1: { value: new THREE.Color(0x005070) },   // Darker Cyan/Blue for wave texture
          uColorWave2: { value: new THREE.Color(0x00f0ff) },   // Bright Cyan for wave crests/glow
          uHighlightColor1: { value: new THREE.Color(0xdd00ff) }, // Purple/Magenta core highlight
          uHighlightColor2: { value: new THREE.Color(0xd0ff00) }, // Lime/Yellow Green core highlight
          uAngleWarpAmount: { value: 2.5 },    // How much noise warps the angle (higher = more swirl/distortion)
          uAngleWarpFreq: { value: 1.5 },      // Scale of the angle warping noise
          uRadiusWarpAmount: { value: 0.15 },   // How much noise warps the radius measurement
          uTextureNoiseScale: { value: 8.0 },  // Scale for the internal texture noise on waves
          uTextureNoiseSpeed: { value: 0.2 },  // Speed of internal texture evolution
          uWaveFrequency: { value: 4.0 },      // Base radial frequency of waves
          uWaveSpeed: { value: 0.6 },          // Base speed of waves outwards
          uCentralRadius: { value: 0.1 },      // Smaller, more intense core radius
          uCentralNoiseScale: { value: 25.0},   // Frequency/scale of noise in the center
          uCentralVerticalBias: { value: 6.0},  // Stronger vertical bias for streaks
          uBarrelDistortion: { value: 0.22 },   // Fisheye distortion amount
          uGlowFactor: { value: 1.8 },         // Multiplier for wave glow
          uNoiseAmount: { value: 0.02 }         // Final static/noise overlay intensity
      },
      vertexShader: `
          varying vec2 vUv;
          void main() {
              vUv = uv;
              gl_Position = vec4(position, 1.0);
          }
      `,
      fragmentShader: `
          precision highp float;
          uniform float uTime;
          uniform vec2 uResolution;
          uniform sampler2D uAudioTexture; // Using this for overall energy maybe
          uniform float uAudioBass;
          uniform float uAudioMid;
          uniform float uAudioTreble;
          uniform float uEffectIntensity;
          uniform float uSeed;
          // Visual Uniforms
          uniform vec3 uColorBg;
          uniform vec3 uColorWave1;
          uniform vec3 uColorWave2;
          uniform vec3 uHighlightColor1;
          uniform vec3 uHighlightColor2;
          uniform float uAngleWarpAmount;
          uniform float uAngleWarpFreq;
          uniform float uRadiusWarpAmount;
          uniform float uTextureNoiseScale;
          uniform float uTextureNoiseSpeed;
          uniform float uWaveFrequency;
          uniform float uWaveSpeed;
          uniform float uCentralRadius;
          uniform float uCentralNoiseScale;
          uniform float uCentralVerticalBias;
          uniform float uBarrelDistortion;
          uniform float uGlowFactor;
          uniform float uNoiseAmount;

          varying vec2 vUv;

          // --- Noise Functions (hash, noise, fbm) ---
           float hash(vec2 p) { return fract(sin(dot(p + uSeed, vec2(127.1, 311.7))) * 43758.5453123); }
           float noise(vec2 p) {
               vec2 i = floor(p); vec2 f = fract(p); f = f*f*(3.0-2.0*f);
               return mix(mix(hash(i + vec2(0.,0.)), hash(i + vec2(1.,0.)),f.x),
                          mix(hash(i + vec2(0.,1.)), hash(i + vec2(1.,1.)),f.x),f.y);
           }
           float fbm(vec2 p, int octaves) {
                float v = 0.0; float a = 0.5;
               mat2 m = mat2(cos(0.5), -sin(0.5), sin(0.5), cos(0.5));
               for (int i = 0; i < octaves; ++i) { v += a * noise(p); p = m * p * 2.0; a *= 0.5; }
                return v;
           }
          // --- End Noise ---

          // Barrel Distortion for UVs
           vec2 barrelDistort(vec2 uv, float amount) {
               vec2 center = vec2(0.5);
               vec2 offset = uv - center;
               float distSq = dot(offset, offset);
               float distortionFactor = 1.0 + distSq * amount * 2.5;
               return center + offset * distortionFactor;
          }

          void main() {
              // Apply barrel distortion first
              vec2 distortedUv = barrelDistort(vUv, uBarrelDistortion * uEffectIntensity);

              vec2 center = vec2(0.5);
              vec2 uvFromCenter = distortedUv - center;
              // Correct aspect ratio
              float aspect = uResolution.x / uResolution.y;
              vec2 aspectCorrectedUv = uvFromCenter * vec2(aspect, 1.0);
              float radius = length(aspectCorrectedUv);
              float angle = atan(uvFromCenter.y, uvFromCenter.x);

              // --- Dynamic Parameters ---
              float timeScaled = uTime * (1.0 + uAudioMid * 0.3);
              // Bass heavily drives angle warp for swirling distortion
              float currentAngleWarp = uAngleWarpAmount * pow(uAudioBass + 0.1, 1.5) * uEffectIntensity; 
              // Mids drive frequency and speed
              float currentFreq = uWaveFrequency * (1.0 + uAudioMid * 1.5) * uEffectIntensity;
              float currentSpeed = uWaveSpeed * (1.0 + uAudioMid * 0.8) * uEffectIntensity;
              // Bass also warps radius
              float currentRadiusWarp = uRadiusWarpAmount * uAudioBass * uEffectIntensity;

              // --- Warped Coordinates for Pattern ---
              // 1. Warp Angle
              float angleWarpNoise = fbm(vec2(radius * uAngleWarpFreq, timeScaled * 0.2), 4);
              float effectiveAngle = angle + angleWarpNoise * currentAngleWarp;
              // 2. Warp Radius
              float radiusWarpNoise = fbm(vec2(effectiveAngle * 2.0, timeScaled * 0.15), 3); // Use warped angle
              float effectiveRadius = radius + radiusWarpNoise * currentRadiusWarp;
              effectiveRadius = max(0.0, effectiveRadius); // Ensure radius doesn't go negative


              // --- Outer Wave Generation ---
              // Generate base wave pattern using warped coordinates
              float wavePattern = sin(effectiveAngle * 5.0 + effectiveRadius * currentFreq - timeScaled * currentSpeed);
              // Shape the wave pattern
              wavePattern = pow(wavePattern * 0.5 + 0.5, 2.0); // Shape to 0..1 range, enhance peaks

              // --- Internal Texture for Waves ---
              // Use another layer of noise based on warped coords
              float textureNoiseSpeed = uTextureNoiseSpeed * (1.0 + uAudioMid * 0.5);
              float textureNoise = fbm(vec2(effectiveAngle * 2.0, effectiveRadius * uTextureNoiseScale) + timeScaled * textureNoiseSpeed, 5);
              textureNoise = pow(textureNoise, 1.5); // Increase texture contrast

              // --- Outer Color Calculation ---
              float waveIntensity = clamp(wavePattern, 0.0, 1.0);
              waveIntensity *= (1.0 - smoothstep(0.4, 0.8, radius)); // Fade waves further out
              // Blend between dark/bright cyan based on wave intensity, modulate by texture
              vec3 outerColor = mix(uColorWave1, uColorWave2, waveIntensity * (0.5 + textureNoise * 0.5));
              // Add glow based on wave intensity & bass
              float glow = waveIntensity * uGlowFactor * (1.0 + uAudioBass * 3.0) * uEffectIntensity;
              outerColor += uColorWave2 * glow * (0.5 + textureNoise * 0.5); // Glow is also textured

              // --- Central Core Generation ---
              vec3 coreColor = vec3(0.0);
              float coreMask = 1.0 - smoothstep(uCentralRadius * 0.9, uCentralRadius * 1.1, radius); // Slightly tighter blend zone

              if (coreMask > 0.01) {
                  // Vertically stretched high-frequency noise
                  float coreNoiseFreq = uCentralNoiseScale * (1.0 + uAudioMid * 1.2);
                  vec2 coreUv = distortedUv * vec2(1.5, uCentralVerticalBias) * coreNoiseFreq + vec2(0.0, timeScaled * 2.5);
                  float coreNoise = fbm(coreUv, 6); // Detailed noise
                  coreNoise = pow(max(0.0, coreNoise * 1.5 - 0.2), 2.0); // High contrast, sharp noise

                  // Base core color cyan, modulated by noise
                  coreColor = uColorWave2 * coreNoise * 1.3;

                  // Add Treble highlights (Purple) - Sharp streaks
                  float trebleAmount = pow(max(0.0, uAudioTreble - 0.2), 3.5) * 15.0 * uEffectIntensity;
                  coreColor += uHighlightColor1 * clamp(hash(distortedUv * 100.0 + uTime * 25.0) * trebleAmount * coreNoise, 0.0, 1.8); // Allow bright flashes

                  // Add Bass highlights (Yellow-Green) - Glow pulses
                  float bassAmount = pow(max(0.0, uAudioBass - 0.1), 2.5) * 5.0 * uEffectIntensity;
                  coreColor += uHighlightColor2 * clamp(coreNoise * bassAmount, 0.0, 1.2);
              }

              // --- Combine Outer Waves and Central Core ---
              vec3 finalColor = mix(outerColor, coreColor, coreMask);

              // --- Final Noise Overlay ---
              float noiseIntensity = uNoiseAmount * (1.0 + uAudioTreble * 1.0);
              finalColor += (hash(vUv * 500.0 + uTime * 18.0) - 0.5) * noiseIntensity * uEffectIntensity;

              // Final slight contrast boost
              finalColor = pow(finalColor, vec3(0.95));

              gl_FragColor = vec4(clamp(finalColor, 0.0, 1.0), 1.0); // Clamp final color
          }
      `,
      depthTest: false,
      depthWrite: false,
      transparent: false
  });

  const mesh = new THREE.Mesh(geometry, material);
  mesh.name = 'KaleidoTunnelEffect'; // Keep the name slot
  mesh.userData.isFeedbackEffect = false; // Not a feedback effect
  // mesh.userData.audioTexture = audioTexture; // Keep if needed
  // mesh.userData.audioDataArray = audioDataArray;

  // Store base parameters for intensity adjustments
  mesh.userData.baseEffectIntensity = 1.0;
  mesh.userData.baseAngleWarpAmount = 2.5;
  mesh.userData.baseAngleWarpFreq = 1.5;
  mesh.userData.baseRadiusWarpAmount = 0.15;
  mesh.userData.baseTextureNoiseScale = 8.0;
  mesh.userData.baseWaveFrequency = 4.0;
  mesh.userData.baseWaveSpeed = 0.6;
  mesh.userData.baseCentralNoiseScale = 25.0;
  mesh.userData.baseBarrelDistortion = 0.22;
  mesh.userData.baseNoiseAmount = 0.02;

  scene.add(mesh);
  visualElements.push(mesh);

  // --- Custom JavaScript Functions ---

  mesh.userData.customAnimateInitial = function() {
      const mat = this.material;
      const time = performance.now() * 0.001;
      mat.uniforms.uTime.value = time;
      mat.uniforms.uAudioBass.value = 0.0;
      mat.uniforms.uAudioMid.value = 0.0;
      mat.uniforms.uAudioTreble.value = 0.0;
      mat.uniforms.uEffectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.uResolution.value.set(window.innerWidth, window.innerHeight);

      // Apply base params
      mat.uniforms.uAngleWarpAmount.value = this.userData.baseAngleWarpAmount || 2.5;
      mat.uniforms.uAngleWarpFreq.value = this.userData.baseAngleWarpFreq || 1.5;
      mat.uniforms.uRadiusWarpAmount.value = this.userData.baseRadiusWarpAmount || 0.15;
      mat.uniforms.uTextureNoiseScale.value = this.userData.baseTextureNoiseScale || 8.0;
      mat.uniforms.uWaveFrequency.value = this.userData.baseWaveFrequency || 4.0;
      mat.uniforms.uWaveSpeed.value = this.userData.baseWaveSpeed || 0.6;
      mat.uniforms.uCentralNoiseScale.value = this.userData.baseCentralNoiseScale || 25.0;
      mat.uniforms.uBarrelDistortion.value = this.userData.baseBarrelDistortion || 0.22;
      mat.uniforms.uNoiseAmount.value = this.userData.baseNoiseAmount || 0.02;

  }.bind(mesh);

  mesh.userData.customAnimateReactive = function(bassAvg, midAvg, trebleAvg) {
      const mat = this.material;
      const time = performance.now() * 0.001;

      // Update core uniforms
      mat.uniforms.uTime.value = time;
      mat.uniforms.uResolution.value.set(window.innerWidth, window.innerHeight);
      mat.uniforms.uEffectIntensity.value = this.userData.baseEffectIntensity || 1.0;
      mat.uniforms.uAudioBass.value = bassAvg;
      mat.uniforms.uAudioMid.value = midAvg;
      mat.uniforms.uAudioTreble.value = trebleAvg;

      // Apply base params
      mat.uniforms.uAngleWarpAmount.value = this.userData.baseAngleWarpAmount || 2.5;
      mat.uniforms.uAngleWarpFreq.value = this.userData.baseAngleWarpFreq || 1.5;
      mat.uniforms.uRadiusWarpAmount.value = this.userData.baseRadiusWarpAmount || 0.15;
      mat.uniforms.uTextureNoiseScale.value = this.userData.baseTextureNoiseScale || 8.0;
      mat.uniforms.uWaveFrequency.value = this.userData.baseWaveFrequency || 4.0;
      mat.uniforms.uWaveSpeed.value = this.userData.baseWaveSpeed || 0.6;
      mat.uniforms.uCentralNoiseScale.value = this.userData.baseCentralNoiseScale || 25.0;
      mat.uniforms.uBarrelDistortion.value = this.userData.baseBarrelDistortion || 0.22;
      mat.uniforms.uNoiseAmount.value = this.userData.baseNoiseAmount || 0.02;
      
  }.bind(mesh);

  mesh.userData.customAdjustIntensity = function(intensityLevel) {
       // Map intensityLevel (1-9) to parameters
      this.userData.baseEffectIntensity = 0.7 + intensityLevel * 0.13;     // 0.83 to 1.87

      // Make effect more intense/complex/reactive at higher levels
      this.userData.baseAngleWarpAmount = 1.0 + intensityLevel * 0.3;       // 1.3 to 3.7
      this.userData.baseAngleWarpFreq = 1.0 + intensityLevel * 0.1;        // 1.1 to 1.9
      this.userData.baseRadiusWarpAmount = 0.05 + intensityLevel * 0.02;    // 0.07 to 0.23
      this.userData.baseTextureNoiseScale = 5.0 + intensityLevel * 1.0;    // 6.0 to 14.0
      this.userData.baseWaveFrequency = 2.0 + intensityLevel * 0.5;        // 2.5 to 6.5
      this.userData.baseWaveSpeed = 0.3 + intensityLevel * 0.1;          // 0.4 to 1.2
      this.userData.baseCentralNoiseScale = 15.0 + intensityLevel * 2.5;    // 17.5 to 37.5
      this.userData.baseBarrelDistortion = 0.1 + intensityLevel * 0.02;    // 0.12 to 0.28
      this.userData.baseNoiseAmount = 0.01 + intensityLevel * 0.002;      // 0.012 to 0.028


       // Apply immediately
       if(this.material && this.material.uniforms) {
           this.material.uniforms.uEffectIntensity.value = this.userData.baseEffectIntensity;
           this.material.uniforms.uAngleWarpAmount.value = this.userData.baseAngleWarpAmount;
           this.material.uniforms.uAngleWarpFreq.value = this.userData.baseAngleWarpFreq;
           this.material.uniforms.uRadiusWarpAmount.value = this.userData.baseRadiusWarpAmount;
           this.material.uniforms.uTextureNoiseScale.value = this.userData.baseTextureNoiseScale;
           this.material.uniforms.uWaveFrequency.value = this.userData.baseWaveFrequency;
           this.material.uniforms.uWaveSpeed.value = this.userData.baseWaveSpeed;
           this.material.uniforms.uCentralNoiseScale.value = this.userData.baseCentralNoiseScale;
           this.material.uniforms.uBarrelDistortion.value = this.userData.baseBarrelDistortion;
           this.material.uniforms.uNoiseAmount.value = this.userData.baseNoiseAmount;
       }
  }.bind(mesh);
} // End createKaleidoTunnelEffect

    function createVisualElements() {
  createParticles();
  createWaves();
  createScribbleEffect();
  create3DWaves();
  createSpaceshipEffect();
  createOceanEffect();
  createBlobEffect();
  createAuroraEffect();
  createPortal();
  createKaleidoTunnelEffect();
  createStarfieldWarpEffect();
  createLiquidCrystalEffect();
  createAbstractFlowEffect();
  createPopArtEffect();
  createGlitchEffect();
  createPixelSortEffect();
  createTrippyColors();
  createNeonGridEffect();
  createGeometricPulseEffect();
  createOrangeEffect();
  // Additional styles can be added here
  updateVisibility(); // Show only the selected style
}
            
function updateVisibility() {
  // Instead of instantly switching, trigger a fade transition.
  fadeTransition(() => {
    visualElements.forEach((elem, index) => {
      elem.visible = (index === currentStyleIndex);
    });
    // After switching, if global visual mode is active, automatically turn
    // on visual mode for the new active effect.
    const activeEffect = visualElements[currentStyleIndex];
    if (isCameraMode && activeEffect && activeEffect.material && activeEffect.material.uniforms && ("visualMode" in activeEffect.material.uniforms)) {
      // For effects that support only an on/off mode, we set it to 1.
      // (For multi-style effects like Orange, you might choose a default state such as 1.)
      activeEffect.material.uniforms.visualMode.value = 1.0;
    }
  });
}
    
    function fadeTransition(callback) {
      const fadeOverlay = document.getElementById('fadeOverlay');
      if (!fadeOverlay) {
        if (callback) callback();
        return;
      }
      // Fade in overlay
      fadeOverlay.style.opacity = '1';
      setTimeout(() => {
        // Call the callback (which will switch the effect)
        if (callback) callback();
        // Then fade out overlay
        fadeOverlay.style.opacity = '0';
      }, 500); // hold black for 500ms (adjust as desired)
    }
        
    function animate() {
      requestAnimationFrame(animate);
            
      // Determine active effect and its state
      const activeEffect = visualElements[currentStyleIndex];
      let isParticleStyle2Active = false;
      if (activeEffect && activeEffect.name === 'CameraParticles' && 
          activeEffect.material && activeEffect.material.uniforms && 
          'visualMode' in activeEffect.material.uniforms && 
          Math.abs(activeEffect.material.uniforms.visualMode.value - 2.0) < 0.1) {
        isParticleStyle2Active = true;
      }

      // Set scene background based on Particle Style 2 state
      if (isParticleStyle2Active && isCameraMode && userCameraTexture) {
        scene.background = userCameraTexture;
      } else {
        // Ensure background is cleared otherwise
        if (scene.background !== null) {
           scene.background = null;
        }
      }

      if (isPlaying) {
          animateAudioReactiveEffects();
        } else {
          animateInitialEffects();
        }
        // If augmentation is active, smoothly interpolate the uniforms
  if (augmentInterval) {
    smoothAugmentationStep();
  }
            
        renderer.render(scene, camera);
    }
        
    function animateInitialEffects() {
      const delta = clock.getDelta();
      const time = performance.now() * 0.001;
        
      // Trippy Colors
      const trippyGroup = visualElements.find(e => e.name === "TrippyColors");
if (trippyGroup && trippyGroup.userData && trippyGroup.userData.material) {
  const mat = trippyGroup.userData.material;

  // Animate time
  mat.uniforms.uTime.value = time;
  // No audio, so set a small baseline
  mat.uniforms.uAudioLevel.value = 0.0; 
  // Keep effect intensity at 1.0 for a visible swirl
  mat.uniforms.uEffectIntensity.value = 1.0;

  // Periodically shift seeds
  const now = time;
  if (now - trippyGroup.userData.lastSeedUpdateTime > trippyGroup.userData.nextSeedInterval) {
    mat.uniforms.uRandomShift.value = Math.random() * 10.0;
    mat.uniforms.uSeedA.value = Math.random() * 1000.0;
    mat.uniforms.uSeedB.value = Math.random() * 1000.0;
    mat.uniforms.uSeedC.value = Math.random() * 1000.0;

    trippyGroup.userData.lastSeedUpdateTime = now;
    trippyGroup.userData.nextSeedInterval = 10.0 + Math.random() * 10.0;
  }
}



      const particleSystem = visualElements.find(elem => elem.name === 'CameraParticles');
  if (particleSystem && particleSystem.material.uniforms) {
    // Use a default low audioIntensity when no music is playing.
    particleSystem.material.uniforms.audioIntensity.value = 0.2;
    // Update the time uniform.
    particleSystem.material.uniforms.time.value = time;
    // Apply a gentle baseline drift.
    particleSystem.rotation.y += 0.005;
    particleSystem.rotation.x += 0.003;
    // Set a default object offset (no influence)
    particleSystem.material.uniforms.objectOffset.value.set(0.0, 0.0, 0.0);
  }
        
            // Waves (Idle)
            const waveEffect = visualElements.find(elem => elem.name === 'Waves');
  if (waveEffect && waveEffect.material.uniforms) {
    // Continuous idle Waves
    waveEffect.material.uniforms.time.value = time;
    waveEffect.material.uniforms.bass.value = 0.0;
    waveEffect.material.uniforms.mid.value = 0.0;
    waveEffect.material.uniforms.treble.value = 0.0;
    waveEffect.material.uniforms.effectIntensity.value = 1.0;
    waveEffect.material.uniforms.lineThickness.value = 0.02;
  }
        
      // 3D Waves (Initial Animation)
const wave3DEffect = visualElements.find(elem => elem.name === '3DWaves');
if (wave3DEffect && wave3DEffect.material.uniforms) {
  const currentTime = performance.now() * 0.001;
  wave3DEffect.material.uniforms.time.value = currentTime;
  const baseAmp = wave3DEffect.userData?.baseAmplitude ?? 20.0;
  const baseFreq = wave3DEffect.userData?.baseFrequency ?? 0.5;
  const baseSpeed = wave3DEffect.userData?.baseSpeed ?? 1.0;
  wave3DEffect.material.uniforms.amplitude.value = baseAmp;
  wave3DEffect.material.uniforms.frequency.value = baseFreq;
  wave3DEffect.material.uniforms.speed.value = baseSpeed;
  wave3DEffect.geometry.attributes.position.needsUpdate = true;
}
        
      // Portal
      // Portal modifications for idle animation:
      // Portal idle update
const portal = visualElements.find(elem => elem.name === 'Portal');
if (portal && portal.material && portal.material.uniforms) {
  const time = performance.now() * 0.001;

  portal.material.uniforms.time.value = time;
  portal.material.uniforms.travelOffset.value = time * 0.15; // slower inward travel
  portal.material.uniforms.colorCycle.value = 8.0 * Math.cos(time * 0.25);
  portal.material.uniforms.spinSpeed.value = 0.35; // reduced spin speed
  portal.material.uniforms.warpStrength.value = 0.9 + 0.3 * Math.sin(time * 0.4);
  portal.material.uniforms.unpredictability.value = 0.5 + 0.2 * Math.cos(time * 0.6);
  portal.material.uniforms.audioReactive.value = 0.0;
  portal.material.uniforms.phaseShift.value = 0.5 * Math.sin(time * 0.1);
  portal.material.uniforms.kaleidoSegments.value = 6.0;
}
        
      // --- SpaceshipEffect: Non-reactive (initial) state ---
      const spaceshipEffect = visualElements.find(e => e.name === "SpaceshipEffect");
if (spaceshipEffect && spaceshipEffect.material?.uniforms) {
  const now = performance.now() * 0.001;
  spaceshipEffect.material.uniforms.time.value = now;
  // No music => audio levels = 0
  spaceshipEffect.material.uniforms.audioBass.value = 0.0;
  spaceshipEffect.material.uniforms.audioMid.value = 0.0;
  spaceshipEffect.material.uniforms.audioTreble.value = 0.0;
  spaceshipEffect.material.uniforms.effectIntensity.value = spaceshipEffect.userData.baseEffectIntensity || 1.0;
  // Force rotation.y to 0 to prevent spinning
  spaceshipEffect.rotation.y = 0.0; 
}
        
      // --- Ocean Effect: Non-reactive (initial) state ---
      // OceanEffect (Idle): smooth ball shape with gentle flow
       // OceanEffect (Idle): morphing sphere with gentle flow
  const oceanIdle = visualElements.find(elem => elem.name === 'OceanEffect');
  if (oceanIdle && oceanIdle.material.uniforms) {
    const baseIntensity = oceanIdle.userData?.baseEffectIntensity || 1.0; // Get base intensity if set
    oceanIdle.material.uniforms.time.value            = time;
    // Set specific audio uniforms to 0
    oceanIdle.material.uniforms.uBass.value           = 0.0; 
    oceanIdle.material.uniforms.uMid.value            = 0.0;
    oceanIdle.material.uniforms.uTreble.value         = 0.0;
    // Keep flowSpeed and effectIntensity potentially controlled by user/slider
    oceanIdle.material.uniforms.flowSpeed.value       = oceanIdle.userData?.baseFlowSpeed || 1.0;
    oceanIdle.material.uniforms.effectIntensity.value = baseIntensity; 
    oceanIdle.material.uniforms.audioStrength.value   = oceanIdle.userData?.baseAudioStrength || 50.0;
  }

        

      const aurora = visualElements.find(elem => elem.name === 'AuroraEffect');
if (aurora && aurora.material.uniforms) {
  aurora.material.uniforms.time.value = performance.now() * 0.001;
  aurora.material.uniforms.audioIntensity.value = 0.0;
  aurora.material.uniforms.effectIntensity.value = aurora.userData?.baseEffectIntensity ?? 1.0;
}

// --- Scribble (Idle) ---
// --- Scribble (Idle) ---
const scribbleIdle = visualElements.find(e => e.name === 'Scribble');
if (scribbleIdle && scribbleIdle.material.uniforms) {
  const mat = scribbleIdle.material;
  const t = performance.now() * 0.001;
  mat.uniforms.time.value         = t;
  mat.uniforms.audioLevel.value   = 0.0;
  mat.uniforms.effectIntensity.value = 1.0;
}

const t = performance.now() * 0.001;
const orangeEffect = visualElements.find(e => e.name === 'Orange');
if (orangeEffect && orangeEffect.material.uniforms) {
  orangeEffect.material.uniforms.time.value = t;
  orangeEffect.material.uniforms.audioIntensity.value = 0.0;
  const baseEI = orangeEffect.userData?.baseEffectIntensity || 1.0;
  orangeEffect.material.uniforms.effectIntensity.value = baseEI;
  // Set the default brightness threshold (adjust as needed based on your camera conditions)
  orangeEffect.material.uniforms.brightnessThreshold.value = 0.5;
  // Set a default edge detection threshold.
  orangeEffect.material.uniforms.edgeThreshold.value = 0.2;
}

const glitchIdle = visualElements.find(e => e.name === 'GlitchEffect');
if (glitchIdle && glitchIdle.material.uniforms) {
  glitchIdle.material.uniforms.time.value = time;
  glitchIdle.material.uniforms.audioBass.value = 0.05; // Minimal baseline activity
  glitchIdle.material.uniforms.audioMid.value = 0.05;
  glitchIdle.material.uniforms.audioTreble.value = 0.05;
  glitchIdle.material.uniforms.effectIntensity.value = glitchIdle.userData.baseEffectIntensity || 1.0;
}

const blobIdle = visualElements.find(e => e.name === 'BlobEffect');
if (blobIdle && blobIdle.isMesh && blobIdle.material && blobIdle.material.uniforms) {
  const mat = blobIdle.material; // Use a shorter alias
  mat.uniforms.time.value = time;
  mat.uniforms.uBass.value = 0.0; // Renamed from audioBass
  mat.uniforms.uMid.value = 0.0;  // Renamed from audioMid
  mat.uniforms.uTreble.value = 0.0;// Renamed from audioTreble
  mat.uniforms.effectIntensity.value = blobIdle.userData?.baseEffectIntensity || 1.0;
} else if (blobIdle) {
    // Log if the object exists but doesn't have the expected structure
    console.warn('Idle BlobEffect found but is not Mesh or material/uniforms are missing:', blobIdle);
}

const popArtIdle = visualElements.find(e => e.name === 'PopArtEffect');
if (popArtIdle && popArtIdle.material.uniforms) {
  popArtIdle.material.uniforms.time.value = time;
  popArtIdle.material.uniforms.audioBass.value = 0.0;
  popArtIdle.material.uniforms.audioMid.value = 0.0;
}

const neonGridIdle = visualElements.find(e => e.name === 'NeonGridEffect');
if (neonGridIdle && neonGridIdle.material.uniforms) {
  neonGridIdle.material.uniforms.time.value = time;
  neonGridIdle.material.uniforms.audioBass.value = 0.0;
  neonGridIdle.material.uniforms.audioMid.value = 0.0;
}

// --- StarfieldWarpEffect (Molten Flow/Glitch Core - Idle) ---
const starfieldWarpIdle = visualElements.find(e => e.name === 'StarfieldWarpEffect');
if (starfieldWarpIdle && starfieldWarpIdle.userData && starfieldWarpIdle.userData.customAnimateInitial) {
  try {
    starfieldWarpIdle.userData.customAnimateInitial();
  } catch (err) {
    console.error("Error in StarfieldWarpEffect customAnimateInitial:", err);
  }
}

// --- LiquidCrystalEffect (Idle / CRT Wave Feedback) ---
const liquidCrystalIdle = visualElements.find(e => e.name === 'LiquidCrystalEffect');
if (liquidCrystalIdle && liquidCrystalIdle.userData && liquidCrystalIdle.userData.customAnimateInitial) {
  try {
    liquidCrystalIdle.userData.customAnimateInitial();
  } catch (err) {
    console.error("Error in LiquidCrystalEffect customAnimateInitial:", err);
  }
  }

const abstractFlowIdle = visualElements.find(e => e.name === 'AbstractFlowEffect');
if (abstractFlowIdle && abstractFlowIdle.material.uniforms) {
  abstractFlowIdle.material.uniforms.time.value = time;
  abstractFlowIdle.material.uniforms.audioBass.value = 0.0;
  abstractFlowIdle.material.uniforms.audioMid.value = 0.0;
}


const pixelSortIdle = visualElements.find(e => e.name === 'PixelSortEffect');
if (pixelSortIdle && pixelSortIdle.material.uniforms) {
  pixelSortIdle.material.uniforms.time.value = time;
  pixelSortIdle.material.uniforms.audioBass.value = 0.0;
  pixelSortIdle.material.uniforms.audioMid.value = 0.0;
}
// --- KaleidoTunnelEffect (iTunes Sim v4 - Idle) ---
const kaleidoIdle = visualElements.find(e => e.name === 'KaleidoTunnelEffect');
if (kaleidoIdle && kaleidoIdle.userData && kaleidoIdle.userData.customAnimateInitial) {
  try {
    kaleidoIdle.userData.customAnimateInitial();
  } catch (err) {
    console.error("Error in KaleidoTunnelEffect customAnimateInitial:", err);
  }
}
// --- GeometricPulseEffect (Idle) ---
const geometryIdle = visualElements.find(e => e.name === 'GeometricPulseEffect');
if (geometryIdle && geometryIdle.userData && geometryIdle.userData.customAnimateInitial) {
  try {
    geometryIdle.userData.customAnimateInitial();
  } catch (err) {
    console.error("Error in GeometricPulseEffect customAnimateInitial:", err);
  }
}


visualElements.forEach(effect => {
    if (effect.userData.customAnimateInitial) {
      try {
        effect.userData.customAnimateInitial();
      } catch (e) {
        console.error("Error in custom animateInitial:", e);
      }
    }
  });
}

    function getSubrangeAverage(dataArray, startIndex, endIndex) {
      let sum = 0;
      let count = 0;
      for (let i = startIndex; i < endIndex; i++) {
        sum += dataArray[i];
        count++;
      }
      return count > 0 ? (sum / count) : 0;
    }
    function animateAudioReactiveEffects() {
      analyser.getByteFrequencyData(dataArray);
      // We'll define approximate segments:
      const bassEnd = Math.floor(bufferLength / 6);        // e.g. first ~1/6 for bass
      const midEnd = Math.floor(bufferLength * 2/3);       // next up to 2/3 for mids
      // from midEnd to bufferLength for treble
      
      // bass average
      const bassAvg = getSubrangeAverage(dataArray, 0, bassEnd) / 256;    // 0..1
      // mid average
      const midAvg = getSubrangeAverage(dataArray, bassEnd, midEnd) / 256;
      // treble average
      const trebleAvg = getSubrangeAverage(dataArray, midEnd, bufferLength) / 256;
      
      // You can also define a total average if you want a global intensity:
      const globalSum = getSubrangeAverage(dataArray, 0, bufferLength) / 256;
      // Define a unified audio intensity for shaders
      const audioIntensity = globalSum;
      
      // Now apply these subrange intensities to your visuals
      // Example: bass -> amplitude, mid -> color shift, treble -> speed
      
      // Particles
      const particleSystem = visualElements.find(elem => elem.name === 'CameraParticles');
  if (particleSystem && particleSystem.material.uniforms) {
    // Compute combined audio intensity.
    let audioInt = (bassAvg + midAvg + trebleAvg) / 3.0;
    particleSystem.material.uniforms.audioIntensity.value = audioInt;
    // Update time uniform.
    particleSystem.material.uniforms.time.value = performance.now() * 0.001;
    // Apply dynamic rotations based on audio data.
    particleSystem.rotation.y += 0.005 + midAvg * 0.05;
    particleSystem.rotation.x += 0.003 + trebleAvg * 0.05;
    // Update the objectOffset uniform using Math.sin and Math.cos.
    particleSystem.material.uniforms.objectOffset.value.set(
      Math.sin(performance.now() * 0.001 * 1.3) * audioInt * 20.0,
      Math.cos(performance.now() * 0.001 * 1.7) * audioInt * 20.0,
      Math.sin(performance.now() * 0.001 * 1.1) * audioInt * 10.0
    );
  }
      
      // Waves (named 'Waves')
      const waveEffect = visualElements.find(elem => elem.name === 'Waves');
  if (waveEffect && waveEffect.material.uniforms) {
    // STRICTLY only update audio data for bending and time
    waveEffect.material.uniforms.bass.value = bassAvg;
    waveEffect.material.uniforms.mid.value = midAvg;
    waveEffect.material.uniforms.treble.value = trebleAvg;
    waveEffect.material.uniforms.time.value = performance.now() * 0.001;
    // DO NOT modify effectIntensity or lineThickness here.
  }
      
      // 3D Waves (Experimental Audio-Reactive)
const wave3DEffect = visualElements.find(elem => elem.name === '3DWaves');
if (wave3DEffect && wave3DEffect.material.uniforms) {
  const baseAmp = wave3DEffect.userData?.baseAmplitude ?? 20.0;
  // Non-linear modulation: squared bass average for dramatic amplitude effects
  const newAmp = baseAmp * (1.0 + Math.pow(bassAvg, 2.0) * 2.0);
  const baseFreq = wave3DEffect.userData?.baseFrequency ?? 0.5;
  const newFreq = baseFreq + trebleAvg * 1.2;
  const baseSpeed = wave3DEffect.userData?.baseSpeed ?? 1.0;
  const newSpeed = baseSpeed + midAvg * 1.5;
  wave3DEffect.material.uniforms.amplitude.value = newAmp;
  wave3DEffect.material.uniforms.frequency.value = newFreq;
  wave3DEffect.material.uniforms.speed.value = newSpeed;
  wave3DEffect.material.uniforms.time.value = performance.now() * 0.001;
  wave3DEffect.geometry.attributes.position.needsUpdate = true;
}
      
const trippyGroup = visualElements.find(e => e.name === "TrippyColors");
if (trippyGroup && trippyGroup.userData && trippyGroup.userData.material) {
  const mat = trippyGroup.userData.material;
  const time = performance.now() * 0.001;
  mat.uniforms.uTime.value = time;

  // Combine frequencies or weight them
  const overallAudio = (bassAvg + midAvg + trebleAvg) / 3.0; // 0..1-ish
  // Possibly boost bass for dramatic swirl
  const swirlAudio = overallAudio + bassAvg * 0.3;
  mat.uniforms.uAudioLevel.value = THREE.MathUtils.clamp(swirlAudio, 0.0, 2.0);

  // Increase effect intensity with total volume
  const intensity = 1.0 + overallAudio * 1.0; 
  mat.uniforms.uEffectIntensity.value = intensity;

  // Periodic re-randomization
  const now = time;
  if (now - trippyGroup.userData.lastSeedUpdateTime > trippyGroup.userData.nextSeedInterval) {
    mat.uniforms.uRandomShift.value = Math.random() * 10.0;
    mat.uniforms.uSeedA.value = Math.random() * 1000.0;
    mat.uniforms.uSeedB.value = Math.random() * 1000.0;
    mat.uniforms.uSeedC.value = Math.random() * 1000.0;

    trippyGroup.userData.lastSeedUpdateTime = now;
    trippyGroup.userData.nextSeedInterval = 10.0 + Math.random() * 10.0;
  }
}

      
      // Portal'
      
      const timeNow = performance.now() * 0.001;
const portal = visualElements.find(elem => elem.name === 'Portal');
if (portal && portal.material && portal.material.uniforms) {
  let reactiveFactor = trebleAvg; // use your chosen audio metric
  
  // Smooth updates via lerp:
  portal.material.uniforms.travelOffset.value = THREE.MathUtils.lerp(
    portal.material.uniforms.travelOffset.value,
    timeNow * 0.15 + reactiveFactor * 0.35,
    0.1
  );
  portal.material.uniforms.colorCycle.value = THREE.MathUtils.lerp(
    portal.material.uniforms.colorCycle.value,
    8.0 * Math.sin(timeNow * 0.35 * reactiveFactor),
    0.1
  );
  portal.material.uniforms.spinSpeed.value = THREE.MathUtils.lerp(
    portal.material.uniforms.spinSpeed.value,
    0.35 + reactiveFactor * 1.8,
    0.1
  );
  portal.material.uniforms.warpStrength.value = THREE.MathUtils.lerp(
    portal.material.uniforms.warpStrength.value,
    0.9 + reactiveFactor * 1.0,
    0.1
  );
  portal.material.uniforms.unpredictability.value = THREE.MathUtils.lerp(
    portal.material.uniforms.unpredictability.value,
    0.5 + reactiveFactor * 0.25,
    0.1
  );
  // Smoothly update the audioReactive value:
  portal.material.uniforms.audioReactive.value = THREE.MathUtils.lerp(
    portal.material.uniforms.audioReactive.value,
    reactiveFactor,
    0.1
  );
  // Increment time slightly faster when reactive:
  portal.material.uniforms.time.value += 0.04 + reactiveFactor * 0.08;
  
  // Force a phase shift jump if reactive is high:
  if (reactiveFactor > 0.8) {
    portal.material.uniforms.phaseShift.value += (Math.random() - 0.5) * 2.0;
  }
  // Adjust kaleido segments based on reactiveFactor:
  portal.material.uniforms.kaleidoSegments.value = 6.0 + Math.floor(reactiveFactor * 3.0);
}
      
      // --- SpaceshipEffect: Audio-reactive state ---
      // Ensure this block correctly uses audioBass, audioMid, audioTreble
      const spaceshipEffect = visualElements.find(e => e.name === "SpaceshipEffect");
if (spaceshipEffect && spaceshipEffect.material?.uniforms) {
  const now = performance.now() * 0.001;
  spaceshipEffect.material.uniforms.time.value = now;
  // Pass individual frequency averages
  spaceshipEffect.material.uniforms.audioBass.value = bassAvg;
  spaceshipEffect.material.uniforms.audioMid.value = midAvg;
  spaceshipEffect.material.uniforms.audioTreble.value = trebleAvg;
  // Use base intensity set by user
  spaceshipEffect.material.uniforms.effectIntensity.value = spaceshipEffect.userData.baseEffectIntensity || 1.0;
  // Force rotation.y to 0 to prevent spinning
  spaceshipEffect.rotation.y = 0.0;

  // Optional: Pulsate min/max radius slightly
  // const radiusPulse = 1.0 + sin(now * 0.5) * 0.05 * bassAvg;
  // spaceshipEffect.material.uniforms.minRadius.value = (spaceshipEffect.userData.baseMinRadius || 80) * radiusPulse;
  // spaceshipEffect.material.uniforms.maxRadius.value = (spaceshipEffect.userData.baseMaxRadius || 360) * radiusPulse;
  // (You would need to store baseMinRadius/baseMaxRadius in userData in createSpaceshipEffect if using this)
}
      
      // --- Ocean Effect: Audio-reactive state ---
      // OceanEffect (Audio Reactive): pulsating flow
      const time = performance.now() * 0.001;

      const oceanReactive = visualElements.find(elem => elem.name === 'OceanEffect');
  if (oceanReactive && oceanReactive.material.uniforms) {
    const baseIntensity = oceanReactive.userData?.baseEffectIntensity || 1.0; // Get base intensity if set
    oceanReactive.material.uniforms.time.value            = time;
    // Update specific audio uniforms
    oceanReactive.material.uniforms.uBass.value           = bassAvg; 
    oceanReactive.material.uniforms.uMid.value            = midAvg;
    oceanReactive.material.uniforms.uTreble.value         = trebleAvg;
    // Keep flowSpeed, audioStrength, effectIntensity controlled by user/slider
    oceanReactive.material.uniforms.flowSpeed.value       = oceanReactive.userData?.baseFlowSpeed || 1.0;
    oceanReactive.material.uniforms.audioStrength.value   = oceanReactive.userData?.baseAudioStrength || 50.0;
    oceanReactive.material.uniforms.effectIntensity.value = baseIntensity;
  }

      const aurora = visualElements.find(elem => elem.name === 'AuroraEffect');
if (aurora && aurora.material.uniforms) {
  aurora.material.uniforms.time.value = performance.now() * 0.001;
  // Compute overall audio intensity (tweak the multipliers for stronger effect)
  let audioIntensity = (bassAvg * 0.5 + midAvg * 0.3 + trebleAvg * 0.2);
  aurora.material.uniforms.audioIntensity.value = audioIntensity;
  aurora.material.uniforms.effectIntensity.value = aurora.userData?.baseEffectIntensity ?? 1.0;
}

// --- Scribble (Audio-Reactive) ---
const scribbleReact = visualElements.find(e => e.name === 'Scribble');
if (scribbleReact && scribbleReact.material.uniforms) {
  const mat = scribbleReact.material;
  const t = performance.now() * 0.001;
  mat.uniforms.time.value         = t;
  mat.uniforms.audioLevel.value   = audioIntensity;
  mat.uniforms.effectIntensity.value = 1.0 + audioIntensity * 2.0;
}

analyser.getByteFrequencyData(dataArray);

const totalAudio = bassAvg + midAvg + trebleAvg;

const orangeEffect = visualElements.find(e => e.name === 'Orange');
if (orangeEffect && orangeEffect.material.uniforms) {
  const t = performance.now() * 0.001;
  orangeEffect.material.uniforms.time.value = t;
  orangeEffect.material.uniforms.audioIntensity.value = totalAudio;
  // Increase effect intensity slightly based on midAvg.
  const baseEI = orangeEffect.userData?.baseEffectIntensity || 1.0;
  orangeEffect.material.uniforms.effectIntensity.value = baseEI + midAvg * 0.5;
  // Adjust the brightness threshold based on treble for a more defined silhouette.
  orangeEffect.material.uniforms.brightnessThreshold.value = 0.5 + trebleAvg * 0.2;
  // Optionally, you can adjust the edgeThreshold if desired.
  orangeEffect.material.uniforms.edgeThreshold.value = 0.2;
}

const glitchReact = visualElements.find(e => e.name === 'GlitchEffect');
if (glitchReact && glitchReact.material.uniforms) {
  glitchReact.material.uniforms.time.value = time;
  glitchReact.material.uniforms.audioBass.value = bassAvg;
  glitchReact.material.uniforms.audioMid.value = midAvg;
  glitchReact.material.uniforms.audioTreble.value = trebleAvg;
  // Use base intensity set by user slider
  glitchReact.material.uniforms.effectIntensity.value = glitchReact.userData.baseEffectIntensity || 1.0;
}

const blobReact = visualElements.find(e => e.name === 'BlobEffect');
if (blobReact && blobReact.isMesh && blobReact.material && blobReact.material.uniforms) {
  const mat = blobReact.material; // Use alias
  const effectTime = performance.now() * 0.001; // Ensure time is defined in this scope
  mat.uniforms.time.value = effectTime;
  mat.uniforms.uBass.value = bassAvg;
  mat.uniforms.uMid.value = midAvg;
  mat.uniforms.uTreble.value = trebleAvg;
  mat.uniforms.effectIntensity.value = blobReact.userData?.baseEffectIntensity || 1.0;
} else if (blobReact) {
    console.warn('Reactive BlobEffect found but is not Mesh or material/uniforms are missing:', blobReact);
}

  const popArtReact = visualElements.find(e => e.name === 'PopArtEffect');
if (popArtReact && popArtReact.material.uniforms) {
  popArtReact.material.uniforms.time.value = time;
  popArtReact.material.uniforms.audioBass.value = bassAvg;
  popArtReact.material.uniforms.audioMid.value = midAvg;
  popArtReact.material.uniforms.audioTreble.value = trebleAvg;
  }

  const neonGridReact = visualElements.find(e => e.name === 'NeonGridEffect');
if (neonGridReact && neonGridReact.material.uniforms) {
  neonGridReact.material.uniforms.time.value = time;
  neonGridReact.material.uniforms.audioBass.value = bassAvg;
  neonGridReact.material.uniforms.audioMid.value = midAvg;
  neonGridReact.material.uniforms.audioTreble.value = trebleAvg;
}

// --- StarfieldWarpEffect (Molten Flow/Glitch Core - Reactive) ---
const starfieldWarpReact = visualElements.find(e => e.name === 'StarfieldWarpEffect');
if (starfieldWarpReact && starfieldWarpReact.userData && starfieldWarpReact.userData.customAnimateReactive) {
  try {
    starfieldWarpReact.userData.customAnimateReactive(bassAvg, midAvg, trebleAvg);
  } catch (err) {
    console.error("Error in StarfieldWarpEffect customAnimateReactive:", err);
  }
}

  // --- LiquidCrystalEffect (Reactive / CRT Wave Feedback) ---
  const liquidCrystalReact = visualElements.find(e => e.name === 'LiquidCrystalEffect');
if (liquidCrystalReact && liquidCrystalReact.userData && liquidCrystalReact.userData.customAnimateReactive) {
  try {
    // Ensure Math.max is used if copying previous logic parts
    liquidCrystalReact.userData.customAnimateReactive(bassAvg, midAvg, trebleAvg);
  } catch (err) {
    console.error("Error in LiquidCrystalEffect customAnimateReactive:", err);
  }
}

const abstractFlowReact = visualElements.find(e => e.name === 'AbstractFlowEffect');
if (abstractFlowReact && abstractFlowReact.material.uniforms) {
  abstractFlowReact.material.uniforms.time.value = time;
  abstractFlowReact.material.uniforms.audioBass.value = bassAvg;
  abstractFlowReact.material.uniforms.audioMid.value = midAvg;
}



const pixelSortReact = visualElements.find(e => e.name === 'PixelSortEffect');
if (pixelSortReact && pixelSortReact.material.uniforms) {
  pixelSortReact.material.uniforms.time.value = time;
  pixelSortReact.material.uniforms.audioBass.value = bassAvg;
}
// --- KaleidoTunnelEffect (iTunes Sim v4 - Reactive) ---
const kaleidoReact = visualElements.find(e => e.name === 'KaleidoTunnelEffect');
if (kaleidoReact && kaleidoReact.userData && kaleidoReact.userData.customAnimateReactive) {
  try {
    kaleidoReact.userData.customAnimateReactive(bassAvg, midAvg, trebleAvg);
  } catch (err) {
    console.error("Error in KaleidoTunnelEffect customAnimateReactive:", err);
  }
}
// --- GeometricPulseEffect (Reactive) ---
const geometryReact = visualElements.find(e => e.name === 'GeometricPulseEffect');
if (geometryReact && geometryReact.userData && geometryReact.userData.customAnimateReactive) {
  try {
    // Make sure to use Math.pow() here if needed, or it's now inside the function
    geometryReact.userData.customAnimateReactive(bassAvg, midAvg, trebleAvg); 
  } catch (err) {
    console.error("Error in GeometricPulseEffect customAnimateReactive:", err);
  }
}


      renderer.render(scene, camera);
    }
    
    async function toggleCameraBackground() {
  if (!isCameraMode) {
    // Turn camera mode ON
    isCameraMode = true;
    console.log('Enabling camera background...');
    showActionMessage("visual mode: on");

    try {
      // 1) Request user media (video only)
      userCameraStream = await navigator.mediaDevices.getUserMedia({ video: true });
    } catch (err) {
      console.error('Error accessing user camera:', err);
      isCameraMode = false;
      showActionMessage("visual mode: off");
      return;
    }

    // 2) Create a video element for the stream
    userCameraVideo = document.createElement('video');
    userCameraVideo.autoplay = true;
    userCameraVideo.playsInline = true;
    userCameraVideo.srcObject = userCameraStream;

    // 3) Wait for video to start playing
    await userCameraVideo.play().catch(err => console.error('Video play error:', err));

    // 4) Create a texture from the video
    userCameraTexture = new THREE.VideoTexture(userCameraVideo);
    userCameraTexture.minFilter = THREE.LinearFilter;
    userCameraTexture.magFilter = THREE.LinearFilter;

    // 5) "Enable" camera feed within the effects:
    isCameraFeedInEffects = true;
    // Update each effect that supports a cameraTexture uniform
    visualElements.forEach(elem => {
      if (elem.material && elem.material.uniforms && 'cameraTexture' in elem.material.uniforms) {
        elem.material.uniforms.cameraTexture.value = userCameraTexture;
        // NEW: If the effect also has a cameraActive uniform, set it to active (1.0)
        if ('cameraActive' in elem.material.uniforms) {
          elem.material.uniforms.cameraActive.value = 1.0;
        }
        // NEW: If the effect also has a visualMode uniform, set it to 1.0 (Style 1)
        if ('visualMode' in elem.material.uniforms) {
          elem.material.uniforms.visualMode.value = 1.0;
        }
      }
    });
    console.log('Camera feed applied to effects.');

  } else {
    // Turn camera mode OFF
    isCameraMode = false;
    console.log('Disabling camera background...');
    showActionMessage("visual mode: off");

    // Stop referencing the camera in effects
    isCameraFeedInEffects = false;
    visualElements.forEach(elem => {
      if (elem.material && elem.material.uniforms && 'cameraTexture' in elem.material.uniforms) {
        // Set the texture back to null
        elem.material.uniforms.cameraTexture.value = null;
        // NEW: Set cameraActive uniform to 0.0 if available
        if ('cameraActive' in elem.material.uniforms) {
          elem.material.uniforms.cameraActive.value = 0.0;
        }
        // NEW: Set visualMode uniform to 0.0 if available
        if ('visualMode' in elem.material.uniforms) {
          elem.material.uniforms.visualMode.value = 0.0;
        }
      }
    });

    // Stop the camera stream (free resources)
    if (userCameraStream) {
      const tracks = userCameraStream.getTracks();
      tracks.forEach(track => track.stop());
      userCameraStream = null;
    }
    userCameraVideo = null;
    userCameraTexture = null;
    console.log('Camera feed removed from effects.');
  }
}
    function startShuffleInterval() {
      if (shuffleInterval) return; // Already running
      shuffleInterval = setInterval(() => {
        if (isPlaying && shuffleMode) {
          shuffleToRandomEffect();
        }
      }, 7000);
    }
    
    function stopShuffleInterval() {
      if (shuffleInterval) {
        clearInterval(shuffleInterval);
        shuffleInterval = null;
      }
    }
    
    function shuffleToRandomEffect() {
      if (visualElements.length <= 1) return; // No shuffle if only one effect
      
      let newIndex;
      do {
        newIndex = Math.floor(Math.random() * visualElements.length);
      } while (newIndex === currentStyleIndex);
      
      currentStyleIndex = newIndex;
      console.log('Shuffling to effect index:', newIndex);
      updateVisibility();
    }
        
    function onWindowResize() {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);

  // Update effect resolutions
  visualElements.forEach(elem => {
    if (elem.material && elem.material.uniforms && 'resolution' in elem.material.uniforms) {
      elem.material.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
    }
  });
}
        
    function onKeyDown(event) {
      // At the very top of onKeyDown(event):
if (event.key.toLowerCase() === 'q') {
  const overlay = document.getElementById('passwordOverlay');
  if (overlay.classList.contains('show')) {
    hidePasswordOverlay();
  } else {
    showPasswordOverlay();
  }
  return; // stop further key handling
}

// If password menu is visible, ignore all other keys so user can type
if (document.getElementById('passwordOverlay').classList.contains('show')) {
  return;
}
      switch (event.key) {
        case ' ':
  event.preventDefault();
  togglePlayPause();
  break;
        case 'm':
          event.preventDefault();
          console.log('M key pressed, toggling mute at:', performance.now());
          audioElement.muted = !audioElement.muted;
          showActionMessage("mute: " + (audioElement.muted ? "on" : "off"));
        break;
        case 'i':
          displayInfo();
        break;
        case 'ArrowLeft': {
  const total = visualElements.length;
  const allowed = [];
  for (let i = 0; i < total; i++) {
    if (isAuthorized || i < total - 10) allowed.push(i);
  }
  const pos = allowed.indexOf(currentStyleIndex);
  const prevPos = (pos - 1 + allowed.length) % allowed.length;
  currentStyleIndex = allowed[prevPos];
  updateVisibility();
  break;
}
case 'ArrowRight': {
  const total = visualElements.length;
  // Build allowed list: free effects always, premium only if authorized
  const allowed = [];
  for (let i = 0; i < total; i++) {
    if (isAuthorized || i < total - 10) allowed.push(i);
  }
  const pos = allowed.indexOf(currentStyleIndex);
  const nextPos = (pos + 1) % allowed.length;
  currentStyleIndex = allowed[nextPos];
  updateVisibility();
  break;
}
case 'ArrowUp': {
  // Find the previous mode, skipping DSP if unauthorized
  let idx = (currentModeIndex - 1 + modes.length) % modes.length;
  const start = idx;
  while (!isAuthorized && modes[idx] === 'dsp') {
    idx = (idx - 1 + modes.length) % modes.length;
    if (idx === start) break;
  }
  currentModeIndex = idx;
  switchMode(modes[currentModeIndex]);
  break;
}
       case 'ArrowDown': {
  let idx = (currentModeIndex + 1) % modes.length;
  const start = idx;
  while (!isAuthorized && modes[idx] === 'dsp') {
    idx = (idx + 1) % modes.length;
    if (idx === start) break;
  }
  currentModeIndex = idx;
  switchMode(modes[currentModeIndex]);
  break;
}
       case 'n':
       if (currentMode === 'dsp') {
  const music = MusicKit.getInstance();
  // Remember play state
  const wasPlaying = music.player.isPlaying;
  music.player.skipToNextItem()
    .then(() => {
      if (!wasPlaying) {
        music.player.pause();
      }
      displayInfo();
    })
    .catch(err => console.error('Error skipping to next:', err));
  break;
}
         if (currentMode === 'fileSelect' && userPlaylistActive && userPlaylist.length > 1) {
           playNextUserSong();
         } else if (currentMode === 'playlist') {
           playNextSongInPlaylist();
         }
         break;
       case 'b':
       if (currentMode === 'dsp') {
  const music = MusicKit.getInstance();
  const wasPlaying = music.player.isPlaying;
  music.player.skipToPreviousItem()
    .then(() => {
      if (!wasPlaying) {
        music.player.pause();
      }
      displayInfo();
    })
    .catch(err => console.error('Error skipping to previous:', err));
  break;
}
         if (currentMode === 'fileSelect' && userPlaylistActive && userPlaylist.length > 1) {
           playPreviousUserSong();
         } else if (currentMode === 'playlist') {
           playPreviousSongInPlaylist();
         }
         break;
  case 'v':
  event.preventDefault();
  const activeEffect = visualElements[currentStyleIndex];
  if (!activeEffect || !activeEffect.material) break;
  const activeMaterial = activeEffect.material; // Convenience variable

  // Check if the effect supports multiple visual styles
  const supportsMultiVisual = (activeEffect.name === "Orange" || activeEffect.name === "CameraParticles" || activeEffect.name === "Waves" || activeEffect.name === "Scribble" || activeEffect.name === "AuroraEffect");
  const isOrange = (activeEffect.name === "Orange");
  const isParticles = (activeEffect.name === "CameraParticles");
  const isWaves = (activeEffect.name === "Waves");
  const isScribble = (activeEffect.name === "Scribble"); // Add flag for Scribble
  const isAurora = (activeEffect.name === "AuroraEffect");

  if (supportsMultiVisual && activeMaterial.uniforms && "visualMode" in activeMaterial.uniforms) {
    let currentState = Math.round(activeMaterial.uniforms.visualMode.value); // Use Math.round for robustness

    if (isOrange) {
      // --- Orange Effect Logic ---
      if (currentState === 0) {
        toggleCameraBackground();
        activeMaterial.uniforms.visualMode.value = 1.0;
        showActionMessage("orange visual: style 1");
      } else if (currentState < 4) {
        currentState++;
        activeMaterial.uniforms.visualMode.value = currentState;
        showActionMessage("orange visual: style " + currentState);
      } else {
        toggleCameraBackground();
        activeMaterial.uniforms.visualMode.value = 0.0;
        showActionMessage("orange visual: off");
      }
    } else if (isParticles) {
      // --- CameraParticles Logic ---
      if (currentState === 0) {
        toggleCameraBackground();
        activeMaterial.uniforms.visualMode.value = 1.0;
        showActionMessage("particle visual: style 1");
      } else if (currentState === 1) {
        activeMaterial.uniforms.visualMode.value = 2.0;
        showActionMessage("particle visual: style 2");
      } else { // currentState is 2
        toggleCameraBackground();
        activeMaterial.uniforms.visualMode.value = 0.0;
        showActionMessage("particle visual: off");
      }
    } else if (isWaves) {
      // --- Waves Effect Logic ---
      if (currentState === 0) {
        toggleCameraBackground();
        showActionMessage("waves visual: style 1");
      } else if (currentState === 1) {
        activeMaterial.uniforms.visualMode.value = 2.0;
        showActionMessage("waves visual: style 2");
      } else if (currentState === 2) {
        activeMaterial.uniforms.visualMode.value = 3.0;
        showActionMessage("waves visual: style 3");
      } else { // currentState is 3
        toggleCameraBackground();
        showActionMessage("waves visual: off");
      }
    } else if (isScribble) {
      // --- NEW: Scribble Effect Logic --- (Cycle 0, 1, 2, 3)
      if (currentState === 0) {
        // Currently off: Turn camera ON, go to Style 1
        toggleCameraBackground(); // Turns ON camera, sets defaults
        // visualMode is already set to 1 by toggleCameraBackground
        showActionMessage("scribble visual: style 1");
        console.log("Scribble Visual Mode: Style 1");
      } else if (currentState === 1) {
        // Currently Style 1: Go to Style 2
        activeMaterial.uniforms.visualMode.value = 2.0;
        showActionMessage("scribble visual: style 2");
        console.log("Scribble Visual Mode: Style 2");
      } else if (currentState === 2) {
        // Currently Style 2: Go to Style 3
        activeMaterial.uniforms.visualMode.value = 3.0;
        showActionMessage("scribble visual: style 3");
        console.log("Scribble Visual Mode: Style 3");
      } else { // currentState is 3 (or unexpected)
        // Currently Style 3: Turn camera OFF, go to Off state
        toggleCameraBackground(); // Turns OFF camera, resets defaults
        // visualMode is already set to 0 by toggleCameraBackground
        showActionMessage("scribble visual: off");
        console.log("Scribble Visual Mode: Off");
      }
    } else if (isAurora) {
      // --- Aurora Effect Logic ---
      if (currentState === 0) {
        toggleCameraBackground();
        activeMaterial.uniforms.visualMode.value = 1.0;
        showActionMessage("aurora visual: style 1 (manipulate cam)");
      } else if (currentState === 1) {
        activeMaterial.uniforms.visualMode.value = 2.0;
        showActionMessage("aurora visual: style 2 (blend)");
      } else { // currentState is 2
        toggleCameraBackground();
        activeMaterial.uniforms.visualMode.value = 0.0;
        showActionMessage("aurora visual: off");
      }
    } else {
       // Generic toggle for other effects
       toggleCameraBackground();
       showActionMessage("visual mode: " + (isCameraMode ? "on" : "off"));
       console.log(activeEffect.name + " Visual Mode Toggled: " + (isCameraMode ? "On" : "Off"));
    }
  } else {
    // Effect doesn't support visualMode - just toggle camera
    toggleCameraBackground();
    showActionMessage("visual mode: " + (isCameraMode ? "on" : "off"));
    console.log(activeEffect.name + " Visual Mode Toggled: " + (isCameraMode ? "On" : "Off"));
  }
  break;
        case 'h':
          event.preventDefault();
          toggleHelpOverlay();
        break;
        case 'o':
          event.preventDefault();
          shuffleMode = !shuffleMode;
          console.log('Shuffle mode:', shuffleMode);
          if (shuffleMode) {
            startShuffleInterval();
          } else {
            stopShuffleInterval();
          }
          showActionMessage("effect shuffle: " + (shuffleMode ? "on" : "off"));
        break;
        case 'x':
  event.preventDefault();
  console.log('x key pressed: starting augmentation');
  if (!augmentInterval) {
    augmentInterval = setInterval(augmentEffect, 300);
  }
break;
case 'p':
  if (currentMode === 'fileSelect') {
    if (!userPlaylistActive) {
      // Activate the user playlist and add the *current* file once
      userPlaylistActive = true;
      if (audioElement && audioElement.src) {
        let firstUserSong = {
          src: audioElement.src,
          title: selectedFileName,
        };
        userPlaylist.push(firstUserSong);
        currentUserSongIndex = 0;
        console.log('User playlist activated with first song:', selectedFileName);
      } else {
        console.error('No valid audio source when pressing P.');
      }
    } else {
      // If the playlist is already active, do NOT add the current file again
      // Just show a message or do nothing
      console.log('User playlist is already active; pick another file if you want more songs.');
    }
    // Now open the file input so the user can select another file
    document.getElementById('fileInput').click();
  }
  break;
        default:
        if (event.key >= '1' && event.key <= '9') {
          intensityLevel = parseInt(event.key);
          adjustVisualEffectsIntensity();
        }
        break;
      }
    }
        
    function adjustVisualEffectsIntensity() {
      console.log(`Adjusting intensity to ${intensityLevel}`);
      
      const particleSystem = visualElements.find(elem => elem.name === 'CameraParticles');
  if (particleSystem && particleSystem.material && particleSystem.material.uniforms) {
    // For example, let the base effect intensity scale with intensityLevel.
    // You can tweak the factor (0.3 in this case) to achieve the desired response.
    particleSystem.userData.baseEffectIntensity = 1.0 + intensityLevel * 1;
    particleSystem.material.uniforms.effectIntensity.value = particleSystem.userData.baseEffectIntensity;
    
    // Optionally, if you want to adjust additional properties, you can do so here.
    console.log('Updated CameraParticles effectIntensity to', particleSystem.material.uniforms.effectIntensity.value);
  }
      
      // Waves (named 'Waves')
      const waveEffect = visualElements.find(elem => elem.name === 'Waves');
  if (waveEffect && waveEffect.material.uniforms) {
    // Unique idle pattern using seed
    const seed = waveEffect.material.uniforms.uSeed.value;
    const wavesIntensity = 1.0 + (intensityLevel - 1) * 0.15 + seed * 0.005;
    waveEffect.material.uniforms.effectIntensity.value = wavesIntensity;
    waveEffect.material.uniforms.lineThickness.value = 0.01 * intensityLevel + seed * 0.0005;
  }
      
      // 3D Waves (named '3DWaves')
const wave3DEffect = visualElements.find(elem => elem.name === '3DWaves');
if (wave3DEffect && wave3DEffect.material && wave3DEffect.material.uniforms) {
  wave3DEffect.userData = wave3DEffect.userData || {};
  // Adjust the base amplitude, frequency, and speed with intensityLevel
  wave3DEffect.userData.baseAmplitude = 20.0 + intensityLevel * 4.0;
  wave3DEffect.userData.baseFrequency = 0.5 + (intensityLevel * 0.1);
  wave3DEffect.userData.baseSpeed = 1.0 + intensityLevel * 0.1;
}
      
      // Trippy Colors
      const trippyGroup = visualElements.find(e => e.name === "TrippyColors");
  if (trippyGroup && trippyGroup.userData && trippyGroup.userData.material) {
    const mat = trippyGroup.userData.material;
    // Map intensityLevel (1-9) to a suitable range, e.g., 1.0 to 2.8
    mat.uniforms.uEffectIntensity.value = 1.0 + (intensityLevel - 1) * 0.2; 
  }
      
      // Portal
      const portal = visualElements.find(elem => elem.name === 'Portal');
if (portal && portal.material && portal.material.uniforms) {
  // Travel offset base speed
  portal.userData.baseTravelOffset = 0.2 + intensityLevel * 0.02;
  portal.material.uniforms.travelOffset.value = portal.userData.baseTravelOffset;

  // Spin base speed
  portal.userData.baseSpinSpeed = 0.4 + intensityLevel * 0.05;
  portal.material.uniforms.spinSpeed.value = portal.userData.baseSpinSpeed;

  // Warp strength
  portal.userData.baseWarpStrength = 1.0 + intensityLevel * 0.1;
  portal.material.uniforms.warpStrength.value = portal.userData.baseWarpStrength;

  // colorCycle base
  portal.userData.baseColorCycle = intensityLevel * 5.0;
  portal.material.uniforms.colorCycle.value = portal.userData.baseColorCycle;

  // unpredictability
  portal.userData.baseUnpredictability = 0.5 + intensityLevel * 0.05;
  portal.material.uniforms.unpredictability.value = portal.userData.baseUnpredictability;

  // Optionally adjust kaleido segments as well
  // E.g. more intensity => more segments
  portal.material.uniforms.kaleidoSegments.value = 4.0 + intensityLevel;
}
      
      // SpaceshipEffect: adjust its base effect intensity.
      const spaceshipEffect = visualElements.find(e => e.name === "SpaceshipEffect");
  if (spaceshipEffect) {
    // Map intensityLevel (1-9) to a suitable range (e.g., 0.5 to 2.3)
    // Slightly increased sensitivity
    spaceshipEffect.userData.baseEffectIntensity = 0.5 + intensityLevel * 0.2; 
    console.log("SpaceshipEffect baseEffectIntensity set to:", spaceshipEffect.userData.baseEffectIntensity);
  }
      
      // Ocean effect intensity adjustment:
      const oceanAdjust = visualElements.find(elem => elem.name === 'OceanEffect');
  if (oceanAdjust && oceanAdjust.material.uniforms) {
    oceanAdjust.material.uniforms.audioStrength.value   = 100.0 * intensityLevel;
    oceanAdjust.material.uniforms.flowSpeed.value       = 0.5 + 0.5 * intensityLevel;
    oceanAdjust.material.uniforms.effectIntensity.value = 0.5 * intensityLevel;
  }

      
      

      const aurora = visualElements.find(elem => elem.name === 'AuroraEffect');
if (aurora && aurora.material && aurora.material.uniforms) {
  aurora.userData = aurora.userData || {};
  // Scale the effect intensity dramatically with the user-selected intensityLevel
  aurora.userData.baseEffectIntensity = 1.0 + intensityLevel * 0.5;
  aurora.material.uniforms.effectIntensity.value = aurora.userData.baseEffectIntensity;
}

// --- Scribble (Intensity Slider) ---
const scribbleInt = visualElements.find(e => e.name === 'Scribble');
if (scribbleInt && scribbleInt.material.uniforms) {
  const mat = scribbleInt.material;
  mat.uniforms.effectIntensity.value = intensityLevel / 5.0;
  mat.uniforms.lineThickness.value   = 0.005 * intensityLevel;
  mat.uniforms.glowIntensity.value   = 1.0 + intensityLevel * 0.5;
}
const orangeEffect = visualElements.find(e => e.name === 'Orange');
  if (orangeEffect && orangeEffect.material && orangeEffect.material.uniforms) {
    // Scale the base effect intensity with the user-selected intensity level.
    orangeEffect.userData.baseEffectIntensity = 1.0 + intensityLevel * 0.3;
    orangeEffect.material.uniforms.effectIntensity.value = orangeEffect.userData.baseEffectIntensity;
    console.log('Updated Orange effectIntensity to', orangeEffect.material.uniforms.effectIntensity.value);
  }
  
visualElements.forEach(effect => {
    if (effect.userData.customAdjustIntensity) {
      try {
        effect.userData.customAdjustIntensity();
      } catch (e) {
        console.error("Error in custom adjustIntensity:", e);
      }
    }
  });
}
    function augmentEffect() {
  const currentEffect = visualElements[currentStyleIndex];
  if (!currentEffect || !currentEffect.material || !currentEffect.material.uniforms) return;
  
  
  for (let key in currentEffect.material.uniforms) {
    if (key === 'visualMode') continue;
    let uniform = currentEffect.material.uniforms[key];
    if (typeof uniform.value === 'number') {
      // Store the base value if not already stored
      if (currentEffect.userData[`base_${key}`] === undefined) {
        currentEffect.userData[`base_${key}`] = uniform.value;
      }
      let baseValue = currentEffect.userData[`base_${key}`];
      // Choose a random factor for wide variation (you can adjust the range)
      let randomFactor = Math.random() * 9.8 + 0.2;
      // Instead of directly setting uniform.value, store the target value:
      uniform.target = baseValue * randomFactor;
      console.log(`Uniform ${key}: base ${baseValue} -> target ${uniform.target}`);
    }
  }
}
function smoothAugmentationStep() {
  const currentEffect = visualElements[currentStyleIndex];
  if (!currentEffect || !currentEffect.material || !currentEffect.material.uniforms) return;
  const smoothingFactor = 0.1; // Adjust this factor (0.0 to 1.0) for smoother/faster transitions
  for (let key in currentEffect.material.uniforms) {
    let uniform = currentEffect.material.uniforms[key];
    if (typeof uniform.value === 'number' && uniform.target !== undefined) {
      // Interpolate: newValue = current + (target - current) * smoothingFactor
      uniform.value = uniform.value + (uniform.target - uniform.value) * smoothingFactor;
    }
  }
}
function resetAugmentation() {
  const currentEffect = visualElements[currentStyleIndex];
  if (!currentEffect || !currentEffect.material || !currentEffect.material.uniforms) return;
  
  for (let key in currentEffect.material.uniforms) {
    let uniform = currentEffect.material.uniforms[key];
    if (typeof uniform.value === 'number' && currentEffect.userData[`base_${key}`] !== undefined) {
      // Set the target back to the base value
      uniform.target = currentEffect.userData[`base_${key}`];
    }
  }
}
document.body.addEventListener('keyup', onKeyUp, false);

function onKeyUp(event) {
  if (event.key === 'x') {
    console.log('x key released: stopping augmentation');
    if (augmentInterval) {
      clearInterval(augmentInterval);
      augmentInterval = null;
      resetAugmentation();
    }
  }
}
    
function displayInfo() {
  const songInfoEl = document.getElementById('songInfo');
  const modeEl     = document.getElementById('modeIndicator');

  // Show current mode
  if (modeEl) {
    modeEl.textContent = 'mode: ' + currentMode;
    modeEl.style.opacity = 1;
    setTimeout(() => { modeEl.style.opacity = 0; }, 3000);
  }

  // Decide which title to display
  let title = '';
  if (currentMode === 'dsp') {
    const now = MusicKit.getInstance().player.nowPlayingItem;
    title = now?.title || '—';
  } else if (currentMode === 'playlist') {
    title = playlist[currentSongIndex]
      .replace(/^.*[\\\/]/, '')
      .replace(/\.[^/.]+$/, '') || '—';
  } else if (
    currentMode === 'fileSelect' &&
    userPlaylistActive &&
    userPlaylist.length > 1
  ) {
    // **Only** use the playlist branch when you actually have a multi-file playlist**
    title = userPlaylist[currentUserSongIndex]?.title || '—';
  } else {
    // Single-file mode (or anything else) → show the one you picked
    title = selectedFileName || '—';
  }

  // Render it
  songInfoEl.textContent = 'song: ' + title;
  songInfoEl.style.opacity = 1;
  setTimeout(() => { songInfoEl.style.opacity = 0; }, 3000);
}

    function showActionMessage(message) {
  const actionMessage = document.getElementById('actionMessage');
  if (!actionMessage) return;
  actionMessage.textContent = message;
  actionMessage.style.opacity = '1';
  setTimeout(() => {
    actionMessage.style.opacity = '0';
  }, 3000);
}
 
function togglePlayPause() {
  isPlaying = !isPlaying;
  const info = document.getElementById('info');

  // --- DSP mode (Apple Music) ---
  if (currentMode === 'dsp') {
    if (isPlaying) {
      info.style.display = 'none';
      const player = MusicKit.getInstance().player;
      if (player && player.audioElement) {
        const musicEl = player.audioElement;
        musicEl.crossOrigin = 'anonymous';
        if (audioSrc) audioSrc.disconnect();
        audioSrc = audioContext.createMediaElementSource(musicEl);
        audioSrc.connect(analyser);
        analyser.connect(audioContext.destination);
      }
      const playPromise = MusicKit.getInstance().play();
      if (playPromise) playPromise.catch(err => console.warn('MusicKit.play() failed:', err));
      audioContext.resume().catch(err => console.warn('AudioContext.resume() failed:', err));
    } else {
      MusicKit.getInstance().pause();
      audioContext.suspend().catch(err => console.warn('AudioContext.suspend() failed:', err));
      info.style.display = 'block';
      info.style.opacity = '0';
      const isMobile = /Mobi|Android/i.test(navigator.userAgent);
      info.textContent = isMobile ? 'tap to start' : 'press spacebar to start';
      void info.offsetWidth;
      info.style.opacity = '1';
    }
    return;
  }

  // --- Playlist mode (HTMLAudioElement) ---
  if (currentMode === 'playlist') {
    if (isPlaying) {
      info.style.display = 'none';
      if (!audioSrc) {
        audioElement.crossOrigin = 'anonymous';
        audioSrc = audioContext.createMediaElementSource(audioElement);
        audioSrc.connect(analyser);
        analyser.connect(audioContext.destination);
      }
      const playPromise = audioElement.play();
      if (playPromise) playPromise.catch(err => console.warn('audioElement.play() failed:', err));
      audioContext.resume().catch(err => console.warn('AudioContext.resume() failed:', err));
    } else {
      audioElement.pause();
      info.style.display = 'block';
      info.style.opacity = '0';
      const isMobile = /Mobi|Android/i.test(navigator.userAgent);
      info.textContent = isMobile ? 'tap to start' : 'press spacebar to start';
      void info.offsetWidth;
      info.style.opacity = '1';
    }
    return;
  }

  // --- FileSelect mode ---
  if (currentMode === 'fileSelect') {
    if (isPlaying) {
      info.style.display = 'none';
      const playPromise = audioElement.play();
      if (playPromise) playPromise.catch(err => console.warn('audioElement.play() failed:', err));
      audioContext.resume().catch(err => console.warn('AudioContext.resume() failed:', err));
    } else {
      audioElement.pause();
      info.style.display = 'block';
      info.style.opacity = '0';
      const isMobile = /Mobi|Android/i.test(navigator.userAgent);
      info.textContent = isMobile ? 'tap to start' : 'press spacebar to start';
      void info.offsetWidth;
      info.style.opacity = '1';
    }
    return;
  }

  // --- AudioDevice mode ---
  if (currentMode === 'audioDevice') {
    if (isPlaying) {
      audioContext.resume().catch(err => console.warn('AudioContext.resume() failed:', err));
      info.style.display = 'none';
    } else {
      audioContext.suspend().catch(err => console.warn('AudioContext.suspend() failed:', err));
      info.style.display = 'block';
      info.style.opacity = '0';
      const isMobile = /Mobi|Android/i.test(navigator.userAgent);
      info.textContent = isMobile ? 'tap to start' : 'press spacebar to start';
      void info.offsetWidth;
      info.style.opacity = '1';
    }
    return;
  }

  // --- Fallback/default ---
  if (audioContext.state === 'suspended') {
    audioContext.resume().catch(err => console.warn('AudioContext.resume() failed:', err));
  }
  if (!isPlaying) {
    const playPromise = audioElement.play();
    if (playPromise) playPromise.catch(err => console.warn('audioElement.play() failed:', err));
    isPlaying = true;
    info.style.display = 'none';
  } else {
    audioElement.pause();
    info.style.display = 'block';
    info.style.opacity = '0';
    const isMobile = /Mobi|Android/i.test(navigator.userAgent);
    info.textContent = isMobile ? 'tap to start' : 'press spacebar to start';
    void info.offsetWidth;
    info.style.opacity = '1';
    isPlaying = false;
  }
}
    
    function displayMode() {
      const modeIndicator = document.getElementById('modeIndicator');
      modeIndicator.textContent = `mode: ${currentMode}`;
      modeIndicator.style.opacity = 1; // Make the mode indicator visible

      // Fade out the mode indicator after 3 seconds
      setTimeout(() => {
        modeIndicator.style.opacity = 0;
      }, 3000);
    }

    function toggleHelpOverlay() {
      const helpOverlay = document.getElementById('helpOverlay');
  const adBanner = document.getElementById('adBanner');
  if (!helpOverlay) return;
      
      // Check mobile
      const isMobile = /Mobi|Android/i.test(navigator.userAgent);
      if (isMobile) {
        helpOverlay.innerHTML = `
        <h2>Controls</h2>
        <ul>
          <li><b>Single Tap:</b> Play/Pause</li>
          <li><b>Swipe Up/Down:</b> Switch Mode</li>
          <li><b>Swipe Left/Right:</b> Switch Effect Style</li      
          <li><b>Double Tap:</b> Set Intensity</li>
          <li><b>Triple Tap:</b> Next Song</li>
          <li><b>Long Press:</b> Show/Hide Help</li>
          <li><b>Full Version Soon!</li>
        </ul>
        `;
      } else {
        
        helpOverlay.innerHTML = `
        <h2>Controls</h2>
        <ul>
          <li><b>Spacebar:</b> Play/Pause</li>
          <li><b>Arrow Up/Down:</b> Switch Mode</li>
          <li><b>Arrow Left/Right:</b> Switch Effect Style</li>
          <li><b>1–9:</b> Set Effect Intensity Level</li>
          <li><b>N:</b> Next Song</li>
          <li><b>B:</b> Previous Song</li>
          <li><b>M:</b> Toggle Mute</li>
          <li><b>O:</b> Toggle Effect Shuffle Mode</li>
          <li><b>P:</b> Toggle Player Mode</li>
          <li><b>I:</b> Show Info</li>
          <li><b>H:</b> Show/Hide Help</li>
          <li><b>Full Version Soon!</li>
        </ul>
        `;
      }
       // Check current display state by checking if "show" class is present.
       if (helpOverlay.classList.contains('show')) {
    // Hide help overlay by removing the "show" class (this triggers fade-out)
    helpOverlay.classList.remove('show');
    // Also remove "show" class from the ad banner
    if (adBanner) {
      adBanner.classList.remove('show');
      // Wait for the fade-out animation to complete before setting display to none.
      setTimeout(() => { 
        helpOverlay.style.display = 'none';
        adBanner.style.display = 'none';
      }, 500); // This delay should match your CSS animation duration
    }
  } else {
    // Show help overlay by setting display and then adding the "show" class.
    helpOverlay.style.display = 'block';
    if (adBanner) {
      adBanner.style.display = 'block';
    }
    setTimeout(() => {
      helpOverlay.classList.add('show');
      if (adBanner) adBanner.classList.add('show');
    }, 20); // Small delay to allow the browser to register display change
  }
    }
    function toggleCreatorMode() {
  let modal = document.getElementById('creatorModal');
  if (modal) {
      // simply display it and let CSS handle the fade/slide
      modal.style.display = 'block';
    requestAnimationFrame(() => modal.classList.add('show'));
    return;
  }
  // Create the modal container covering the full screen
  modal = document.createElement('div');
  modal.id = 'creatorModal';
  Object.assign(modal.style, {
    position: 'fixed',
    top: '0',
    left: '0',
    width: '100%',
    height: '100%',
    backgroundColor: 'rgba(0,0,0,0.5)',
    zIndex: '10000',
    overflow: 'auto'
  });
  
  // Create the inner content styled like the help overlay
  modal.innerHTML = `
    <div style="background-color: rgba(0, 0, 0, 0.8); color: white; font-family: Arial, sans-serif; border: 2px solid grey; border-radius: 8px; padding: 20px; width: 90%; max-width: 600px; margin: 100px auto;">
      <h2 style="text-align: center; margin-top: 0;">Create Custom Effect</h2>
      <label style="font-weight:bold;">Create Function Code:</label><br>
      <textarea id="creatorCreateCode" rows="10" style="width:100%; background: #333; color: white; border: 1px solid grey; padding: 5px;"></textarea><br><br>
      <label style="font-weight:bold;">Animate Initial Code:</label><br>
      <textarea id="creatorAnimateInitialCode" rows="5" style="width:100%; background: #333; color: white; border: 1px solid grey; padding: 5px;"></textarea><br><br>
      <label style="font-weight:bold;">Animate Reactive Code:</label><br>
      <textarea id="creatorAnimateReactiveCode" rows="5" style="width:100%; background: #333; color: white; border: 1px solid grey; padding: 5px;"></textarea><br><br>
      <label style="font-weight:bold;">Adjust Intensity Code:</label><br>
      <textarea id="creatorAdjustIntensityCode" rows="5" style="width:100%; background: #333; color: white; border: 1px solid grey; padding: 5px;"></textarea><br><br>
      <div style="text-align: center;">\n         <button id="creatorSubmitButton" style="padding: 10px 20px; background-color: rgba(0,0,0,0.8); border: 2px solid grey; border-radius: 8px; color: white; font-family: Arial, sans-serif; font-size: 16px; cursor: pointer;">Submit Effect</button>      <button id="creatorCancelButton" style="padding: 10px 20px; background-color: transparent; border: 2px solid grey; border-radius: 8px; color: white; font-family: Arial, sans-serif; font-size: 16px; cursor: pointer;">Cancel</button>\n      </div>\n    </div>\n  `;
  
  document.body.appendChild(modal);
  modal.style.display = 'block';
  requestAnimationFrame(() => modal.classList.add('show'));
  
  document.getElementById('creatorSubmitButton').addEventListener('click', function(){
    // Get the code from each textarea
    let createCode = document.getElementById('creatorCreateCode').value;
    let animateInitialCode = document.getElementById('creatorAnimateInitialCode').value;
    let animateReactiveCode = document.getElementById('creatorAnimateReactiveCode').value;
    let adjustIntensityCode = document.getElementById('creatorAdjustIntensityCode').value;
    
    try {
      // Create functions using the Function constructor
      let userCreateFunction = new Function(createCode);
      let userAnimateInitialFunction = new Function(animateInitialCode);
      let userAnimateReactiveFunction = new Function(animateReactiveCode);
      let userAdjustIntensityFunction = new Function(adjustIntensityCode);
      
      // Create an object to store the custom effect functions and assign a unique name
      let customEffect = {
         name: "CustomEffect" + (visualElements.length + 1),
         create: userCreateFunction,
         animateInitial: userAnimateInitialFunction,
         animateReactive: userAnimateReactiveFunction,
         adjustIntensity: userAdjustIntensityFunction
      };

      // Execute the create function to create the effect.
      customEffect.create();
      
      // Find the newly created effect in visualElements by its assigned name.
      let newEffect = visualElements.find(elem => elem.name === customEffect.name);
      if (newEffect) {
         // Store the custom update functions on the effect so we can call them later.
         newEffect.userData.customAnimateInitial = customEffect.animateInitial;
         newEffect.userData.customAnimateReactive = customEffect.animateReactive;
         newEffect.userData.customAdjustIntensity = customEffect.adjustIntensity;
      } else {
         console.warn("Custom effect not found in visualElements. Make sure your create code sets the effect's name to: " + customEffect.name);
      }
      
      // Display the loaded message.
      showActionMessage("loaded");
      
      // Hide the modal.
      modal.style.transition = 'opacity 0.5s ease, transform 0.5s ease';
  modal.style.opacity   = '0';
  modal.style.transform = 'translate(-50%, -40%)';
  modal.addEventListener('transitionend', function handler() {
    modal.style.display = 'none';
    modal.removeEventListener('transitionend', handler);
  }, { once: true });
    } catch (e) {
      alert("Error in custom effect code: " + e);
    }
  });
  
  document.getElementById('creatorCancelButton').addEventListener('click', function(){
    const modal = document.getElementById('creatorModal');
  if (!modal) return;
  // remove the class to trigger your fade/slide‐out
  modal.classList.remove('show');
  modal.addEventListener('transitionend', function handler() {
    modal.style.display = 'none';
    modal.removeEventListener('transitionend', handler);
  }, { once: true });
});
}

// Listen for the "c" key to trigger creator mode.
document.body.addEventListener('keydown', function(event) {
  if (event.key === 'c') {
    event.preventDefault();
    toggleCreatorMode();
  }
});
function loadCurrentUserSong() {
  return new Promise((resolve) => {
    if (!userPlaylist[currentUserSongIndex]) {
      console.error('No user song at current index');
      resolve();
      return;
    }
    let currentSong = userPlaylist[currentUserSongIndex];
    const newAudio = new Audio();
    newAudio.src = currentSong.src;
    newAudio.load();
    selectedFileName = currentSong.title;
    newAudio.onloadedmetadata = () => {
      ensureAudioContextResumed().then(() => {
        if (audioSrc) {
          audioSrc.disconnect();
          audioSrc = null;
        }
        audioSrc = audioContext.createMediaElementSource(newAudio);
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 2.0;
        audioSrc.connect(gainNode);
        gainNode.connect(analyser);
        analyser.connect(audioContext.destination);
        audioElement.pause();
        audioElement = newAudio;
        resolve();
      });
    };
  });
}

function playNextUserSong() {
  if (userPlaylist.length < 2) return;
  currentUserSongIndex = (currentUserSongIndex + 1) % userPlaylist.length;
  loadCurrentUserSong().then(() => {
    if (isPlaying) {
      audioElement.play();
    }
  });
}

function playPreviousUserSong() {
  if (userPlaylist.length < 2) return;
  currentUserSongIndex = (currentUserSongIndex - 1 + userPlaylist.length) % userPlaylist.length;
  loadCurrentUserSong().then(() => {
    if (isPlaying) {
      audioElement.play();
    }
  });
}   
    // --- Touch control variables ---
    let touchStartX = 0;
    let touchStartY = 0;
    let touchStartTime = 0;
    let tapCount = 0;
    let tapTimer = null;
    let longPressTimer = null;

    // Pinch & two-finger gesture tracking
    let touchStartTouches = 0;
    let pinchStartDistance = 0;
    const pinchThreshold = 50;        // Minimum change to register a pinch
    let twoFingerHoldTimer = null;
    let twoFingerAugTimer = null;
    
    // Configurable thresholds (in ms and pixels)
    const longPressThreshold = 600;  // Duration (ms) to trigger a long press (help menu)
    const tapMaxDuration = 200;      // Max duration (ms) for a tap
    const tapDelay = 300;            // Time window (ms) to wait for additional taps
    const swipeThreshold = 50;       // Minimum movement (pixels) to be considered a swipe
    
    // Initialize touch event listeners (call this after the DOM loads)
    function initTouchControls() {
      // Attach events to the document's body
      const target = document.body;
      target.addEventListener('touchstart', onTouchStart, { passive: false });
      target.addEventListener('touchmove', onTouchMove, { passive: false });
      target.addEventListener('touchend', onTouchEnd, { passive: false });
      target.addEventListener('touchcancel', onTouchCancel, { passive: false });
    }
    
    function onTouchStart(e) {
      e.preventDefault();
      touchStartTime = Date.now();
      touchStartX = e.touches[0].clientX;
      touchStartY = e.touches[0].clientY;
      touchStartTouches = e.touches.length;
      if (touchStartTouches === 2) {
        // Start pinch and two-finger hold tracking
        const dx = e.touches[0].clientX - e.touches[1].clientX;
        const dy = e.touches[0].clientY - e.touches[1].clientY;
        pinchStartDistance = Math.hypot(dx, dy);
        clearTimeout(longPressTimer);
        // Two-finger hold → Info, then Augment
        twoFingerHoldTimer = setTimeout(() => displayInfo(), longPressThreshold);
        twoFingerAugTimer = setTimeout(() => augmentEffect(), longPressThreshold * 2);
        return;
      }
      // Only consider single-finger touches
      if (e.touches.length > 1) return;
      // Start long press timer
      longPressTimer = setTimeout(() => {
        // Long press detected – show the help menu
        toggleHelpOverlay();
      }, longPressThreshold);
    }
    
    function onTouchMove(e) {
      if (e.touches.length === 2) {
        // Cancel one-finger timers
        clearTimeout(longPressTimer);
        clearTimeout(twoFingerHoldTimer);
        clearTimeout(twoFingerAugTimer);
        // Pinch detection
        const dx = e.touches[0].clientX - e.touches[1].clientX;
        const dy = e.touches[0].clientY - e.touches[1].clientY;
        const dist = Math.hypot(dx, dy);
        if (dist - pinchStartDistance > pinchThreshold) {
          // Pinch out → Game mode
          switchMode('gameMode');  
          pinchStartDistance = dist;
        } else if (pinchStartDistance - dist > pinchThreshold) {
          // Pinch in → Visual mode
          toggleCameraBackground();
          pinchStartDistance = dist;
        }
        return;
      }
      e.preventDefault();
      // Any movement cancels the long press timer
      clearTimeout(longPressTimer);
    }
    
    function onTouchEnd(e) {
      e.preventDefault();
      clearTimeout(longPressTimer);
      clearTimeout(twoFingerHoldTimer);
      clearTimeout(twoFingerAugTimer);
      if (touchStartTouches === 2) {
        // Two-finger drag for next/back
        const touch1 = e.changedTouches[0];
        const touch2 = e.changedTouches[1] || e.changedTouches[0];
        const dx = ((touch1.clientX + touch2.clientX) / 2) - touchStartX;
        const dy = ((touch1.clientY + touch2.clientY) / 2) - touchStartY;
        const distance = Math.hypot(dx, dy);
        if (distance >= swipeThreshold) {
          if (Math.abs(dx) > Math.abs(dy)) {
            // Horizontal two-finger drag
                      // Horizontal two-finger drag → Next/Previous song
          if (dx < 0) {
              // Drag left → Next song
              playNextSongInPlaylist();
            } else {
                           // Drag right → Previous song
                           playPreviousSongInPlaylist();
            }
            updateVisibility();
          } else {
            // Vertical two-finger drag (back)
            if (dy < 0) {
              currentModeIndex = (currentModeIndex + 1) % modes.length;
            } else {
              currentModeIndex = (currentModeIndex - 1 + modes.length) % modes.length;
            }
            switchMode(modes[currentModeIndex]);
          }
          tapCount = 0;
          clearTimeout(tapTimer);
          return;
        }
      }
      const touchEndTime = Date.now();
      let touchEndX = 0, touchEndY = 0;
      if (e.changedTouches.length > 0) {
        touchEndX = e.changedTouches[0].clientX;
        touchEndY = e.changedTouches[0].clientY;
      }
      const dt = touchEndTime - touchStartTime;
      const dx = touchEndX - touchStartX;
      const dy = touchEndY - touchStartY;
      const distance = Math.sqrt(dx * dx + dy * dy);
      
      // When in fileSelect mode on mobile, trigger the file input only once.
      if (currentMode === 'fileSelect' && /Mobi|Android/i.test(navigator.userAgent)) {
        if (!fileSelectTriggered) {
          let fileInput = document.getElementById('fileInput');
          if (fileInput) {
            fileInput.click();
            fileSelectTriggered = true;
            return; // Only return on the first tap to trigger file selection.
            }
          }
          // If fileSelectTriggered is true, do not return so that gestures can be processed.
      }        
      
      // (Existing swipe and tap logic follows here.)
      if (distance >= swipeThreshold) {
        if (Math.abs(dx) > Math.abs(dy)) {
          // Horizontal swipe: delegate to keyboard logic for effects
          onKeyDown({
            key: dx > 0 ? 'ArrowRight' : 'ArrowLeft',
            preventDefault: () => {},
            stopPropagation: () => {}
          });
        } else {
          // Vertical swipe: delegate to keyboard logic for modes
          onKeyDown({
            key: dy < 0 ? 'ArrowUp' : 'ArrowDown',
            preventDefault: () => {},
            stopPropagation: () => {}
          });
        }
        tapCount = 0;
        clearTimeout(tapTimer);
      } else {
        if (dt < tapMaxDuration) {
          tapCount++;
          if (tapTimer) clearTimeout(tapTimer);
          tapTimer = setTimeout(() => {
            if (tapCount === 1) {
              togglePlayPause();
            } else if (tapCount === 2) {
              intensityLevel = (intensityLevel % 9) + 1;
              adjustVisualEffectsIntensity();
            } else if (tapCount === 3) {
              playNextSongInPlaylist();
            }
            else if (tapCount === 4) {
              // Four taps → Mute/unmute music
              audioElement.muted = !audioElement.muted;
              showActionMessage("mute: " + (audioElement.muted ? "on" : "off"));
            }
            tapCount = 0;
          }, tapDelay);
        }
      }
    }
    
    function onTouchCancel(e) {
      clearTimeout(longPressTimer);
      clearTimeout(tapTimer);
      tapCount = 0;
    }
    
    // Call initTouchControls() once the DOM is ready
    document.addEventListener('DOMContentLoaded', initTouchControls);
    
    init();
  </script>
</body>
</html>
